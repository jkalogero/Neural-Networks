{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Lab_1.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgM-C62wlQTm"
      },
      "source": [
        "---\n",
        "#Άσκηση 1. Επιβλεπόμενη Μάθηση: Ταξινόμηση\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTjsQhI7orML"
      },
      "source": [
        "#Στοιχεία Ομάδας\n",
        "<u>Συνεργάτες</u>:\n",
        "\n",
        "Δούλης Κωνσταντίνος 03116175\n",
        "\n",
        "Καλογερόπουλος Ιωάννης 03116117\n",
        "\n",
        "Κατσίκας-Μουρούτσος Γεώργιος 03116132\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik7SPquAmwND"
      },
      "source": [
        "Αρχικά, ενημερώνουμε τις βιβλιοθήκες που θα χρησιμοποιηθούν (έχει προστεθεί στην αρχή του κελιού η magic command %%capture ώστε να μην εμφανίζονται στο stdouput οι πληροφορίες των εγκαταστάσεων, για να είναι πιο ευανάγνωστο):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7_jP0HklpR1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b9f94569-8fe6-4356-dfe2-af00f2a03bff"
      },
      "source": [
        "!pip install --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy --upgrade #upgrade numpy package\n",
        "!pip install pandas --upgrade #--upgrade #upgrade pandas package\n",
        "!pip install -U tensorflow\n",
        "!pip install --upgrade imbalanced-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (20.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.3.1 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Using cached numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.23.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUYHWBBvjb9w"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9L1ZXDKncGu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2c85a80-2a72-47ad-f7dc-d56af7a77291"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")\n",
        "\n",
        "download('http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data', 'crx.data')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuojFZSVqK3y"
      },
      "source": [
        "#Mικρό Dataset: Japanese Credit Screening\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q2QlhnxrYXY"
      },
      "source": [
        "##Πληροφορίες dataset\n",
        "\n",
        "Το dataset που εξετάζουμε παρέχει πληροφορίες σχετικά με άτομα στα οποία χορηγήθηκε ή όχι πίστωση από Ιαπωνική εταιρεία. Τα δεδομένα παράχθηκαν ύστερα από σχετικές ερωτήσεις στους πελάτες τις εταιρείας."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAMbop8Pr0B8"
      },
      "source": [
        "##Περιγραφή χαρακτηριστικών του dataset\n",
        "\n",
        "To dataset διαθέτει <b>690 δείγματα</b>, με το καθένα από αυτά να διαθέτει <b>15 χαρακτηριστικά συν 1 που είναι η κλάση</b>.\n",
        "\n",
        "Το κάθε δείγμα αντιστοιχεί σε μία γραμμή του αρχείου, ενώ η κάθε στήλη σε ένα χαρακτηριστικό του. <b>Η τελευταία στήλη δηλώνει την κλάση που ανήκει το δείγμα</b>. Συγκεκριμένα, το σύμβολο <b>\"+\"</b> δηλώνει ότι η πίστωση <b>εγκρίθηκε</b>, ενώ το σύμβολο <b>\"-\"</b> δηλώνει ότι <b>δεν εγκρίθηκε</b>.\n",
        "Επομένως, η δομή του αρχείου είναι κατάλληλη για να ξεκινήσουμε την προεπεξεργασία του dataset.\n",
        "\n",
        "Για λόγους απορήτου τα attribute names και values έχουν αντικατασταθεί με τυχαία σύμβολα, που δεν παρέχουν κάποια σχετική πληροφορία σχετικά με το τι περιγράφουν.\n",
        "\n",
        "Το είδος των χαρακτηριστικών φαίνεται παρακάτω:\n",
        "\n",
        "| Attribute | Type of Data                                 | Description    |\n",
        "|-----------|----------------------------------------------|----------------|\n",
        "| A1        | b, a.                                        | Male           |\n",
        "| A2        | continuous.                                  | Age            |\n",
        "| A3        | continuous.                                  | Debt           |\n",
        "| A4        | u, y, l, t.                                  | Married        |\n",
        "| A5        | g, p, gg.                                    | BankCustomer   |\n",
        "| A6        | c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff. | EducationLevel |\n",
        "| A7        | v, h, bb, j, n, z, dd, ff, o.                | Ethnicity      |\n",
        "| A8        | continuous.                                  | YearsEmployed  |\n",
        "| A9        | t, f.                                        | PriorDefault   |\n",
        "| A10       | t, f.                                        | Employed       |\n",
        "| A11       | continuous.                                  | CreditScore    |\n",
        "| A12       | t, f.                                        | DriversLicense |\n",
        "| A13       | g, p, s.                                     | Citizen        |\n",
        "| A14       | continuous.                                  | ZipCode        |\n",
        "| A15       | continuous.                                  | Income         |\n",
        "| A16       | +,-                                          | Approved (CLASS ATTRIBUTE)       |\n",
        "\n",
        "\n",
        "\n",
        "* Τα χαρακτηριστικά που έχουν continuous τιμές αποτελουν <b>διατεταγμένα </b>χαρακτηριστικά, ενώ αυτά που έχουν διακριτές τιμές, δηλαδή σύμβολα, <b>μη διατεταγμένα</b>.\n",
        "\n",
        "* Στο dataset <b>δεν</b> υπάρχουν επικεφαλίδες, καθώς ούτε και αρίθμηση γραμμών.\n",
        "\n",
        "* Οι ετικέτες και οι σημασίες τους είναι:\n",
        "    * \"+\": Εγκρίθηκε η πίστωση\n",
        "    * \"-\": Απορρίφθηκε η πίστωση\n",
        "\n",
        "    Οι ετικέτες αυτές βρίσκονται στην τελευταία στήλη, ενώ οι τιμές τους θα πρέπει να μετατραπούν όπως φαίνεται παρακάτω:\n",
        "    * \"+\" -> 1\n",
        "    * \"-\" -> 0\n",
        "\n",
        "* <b>Υπάρχουν απουσιάζουσες τιμές</b>. Συγκεκριμένα, 37 δείγματα (5%) του συνολικού αριθμού δειγμάτων παρουσιάζουν μία ή παραπάνω απώλειες δεδομένων. \n",
        "\n",
        "Όλα τα παραπάνω φαίνονται παρακάτω:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW4faeHk8TKM"
      },
      "source": [
        "##Προεπεξεργασία των δεδομένων\n",
        "Aρχικά διαβάζουμε το αρχείο <b>crx.data</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNOetXVa77M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b192e01-9f9e-4bc2-d5fd-ca441fe07b4d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"crx.data\", header=None)\n",
        "# print the five first samples\n",
        "print(df[:5])\n",
        "print(df.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
            "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
            "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
            "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
            "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
            "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +\n",
            "(690, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdZtApI_9Fab"
      },
      "source": [
        "###Αντιστοίχιση κλάσεων\n",
        "Παρατηρούμε, όπως ειπώθηκε και παραπάνω, ότι οι κλάσεις δηλώνονται στην τελευταία στήλη με τα σύμβολα +/-. \n",
        "\n",
        "Μετατρέπουμε τα \"+\" σε 1 και τα \"-\" σε 0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3M1H7ST9O9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4211ccb2-cac6-405f-c29b-68c6f761209f"
      },
      "source": [
        "# create mapper for each symbol\n",
        "class_mapper = {\"+\": 1, \"-\": 0}\n",
        "# since these symbols occur only on the last column we dont specify the column\n",
        "df = df.replace(class_mapper)\n",
        "print(df[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14  15\n",
            "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0   1\n",
            "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560   1\n",
            "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824   1\n",
            "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3   1\n",
            "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0   1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p35rb4qAuRYR"
      },
      "source": [
        "###Εντοπισμός απουσιάζουσων τιμών χαρακτηριστικών\n",
        "\n",
        "Στη συνέχεια, θα εντοπίσουμε τις απουσιάζουσες τιμές. Αυτές δηλώνονται στο dataset με τον χαρακτήρα \"?\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4snaGwf-KV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e66fac-4dd8-426f-e5a6-ab95f950a424"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# replace \"?\" with np.NaN\n",
        "df.replace('?',np.NaN,inplace=True)\n",
        "\n",
        "# calculate the number of samples with at least one missing attribute\n",
        "# df.isna() is the mask of df where each element is True if is NaN\n",
        "# s is the length of the list of samples that have at least one True(NaN)\n",
        "num_of_incomplete_samples = len([i for i in np.array(df.isna()) if True in i])\n",
        "\n",
        "print(\"The samples of the dataset that have at least one missing attribute are \", num_of_incomplete_samples)\n",
        "print(\"Which means that the \", num_of_incomplete_samples*100/df.shape[0], \"% of the samples have missing values.\", sep=\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The samples of the dataset that have at least one missing attribute are  37\n",
            "Which means that the 5.36231884057971% of the samples have missing values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdHVwDC30eRv"
      },
      "source": [
        "Από τα παραπάνω βλέπουμε ότι αν θέλαμε να αγνοήσουμε τα δείγματα που έχουν missing values θα έπρεπε να \"πετάξουμε\" το 5% των δειγμάτων, αριθμός που <b>θα επηρέαζε αρνητικά τα αποτελέσματα</b>.\n",
        "\n",
        "Προκειμένου να εξετάσουμε αν οι περισσότερες τιμές που λείπουν προέρχονται απο συγκεκριμένα (λίγα) χαρακτηριστικά (και αν αυτά έχουν ίσως και μηδενική διακύμανση, δηλαδή  χαρακτηριστικά με σταθερές τιμές), οπότε θα μπορούσαμε να τα αγνοήσουμε, εκτελούμε:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkPRNBdi32T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edaac03c-753b-4656-93b2-452ce1a0f177"
      },
      "source": [
        "# the list of the number of missing values for each attribute occurs by \n",
        "# summing the elements of the inverse of df, without df's last column.\n",
        "# df's last column is the class attribute and it is alwasy present.\n",
        "incomplete_attrs = [sum(i) for i in np.array(df.isna())[:,:df.shape[1]-1].T]\n",
        "print(\"For each attribute of the dataset, the number of the missing values is\")\n",
        "print(incomplete_attrs)\n",
        "# print(sum(incomplete_attrs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For each attribute of the dataset, the number of the missing values is\n",
            "[12, 12, 0, 6, 6, 9, 9, 0, 0, 0, 0, 0, 0, 13, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fXm2-b_32zj"
      },
      "source": [
        "Βλέπουμε, επομένως, ότι από τα 690 δείγματα το πολύ σε 13 από αυτά ένα χαρακτηριστικό δεν έχει τιμές. Επομένως, δεν έχει νόημα να αγνοήσουμε το χαρακτηριστικό αυτό, ακόμα και αν είναι αυτό με τις περισσότερες ελλείψεις, αφού αυτές είναι πολύ λίγες και θα χάναμε πολύ πληροφορία.\n",
        "\n",
        "Τελικά η πιο συμφέρουσα λύση είναι να αντικαταστήσουμε τα NaN με τιμές που προκύπτουν με βάση τις τιμές των χαρακτηριστικών σε προηγούμενα δείγματα. <u>Συγκεκριμένα, αντικαθιστούμε τα NaN με την τιμή του χαρακτηριστικού που εμφανίζεται πιο συχνά</u>.\n",
        "\n",
        "Την αντικατάσταση των απουσιάζουσων τιμών θα τη χειρίζεται το πρώτο κομμάτι προεπεξεργασίας του Pipeline, που θα οριστεί στη συνέχεια και θα πρόκειται για έναν μετασχηματιστή Imputer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iIfeNp-F20h"
      },
      "source": [
        "Οι κλάσεις βρίσκονται στην τελευταία στήλη του συνόλου δεδομένων. Οπότε για να βρούμε το πλήθος τους και τα ποσοστά δειγμάτων τους επί του συνόλου:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc32MgrVGpPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d76bdc6-e44d-4c11-9c55-d92c89404df0"
      },
      "source": [
        "num_of_rows = df.shape[0]\n",
        "num_of_attrs = df.shape[1] - 1 #remove one element because of the class attribute\n",
        "\n",
        "# get labesl and features\n",
        "labels_df = df.iloc[:, [num_of_attrs]] # τα labels είναι στην τελευταία κολώνα\n",
        "features_df = df.iloc[:, 0:num_of_attrs]  # τα features είναι όλες οι προηγούμενες κολώνες\n",
        "\n",
        "labels = labels_df.values.reshape(num_of_rows,)\n",
        "features = features_df.values\n",
        "# convert to int\n",
        "labels.astype(int)\n",
        "labels = np.array(labels, dtype='int64')\n",
        "# print(labels.shape)\n",
        "\n",
        "# find how many of each class\n",
        "bin_count = np.bincount(labels)\n",
        "print (\"frequencies:\", bin_count)\n",
        "print(\"The percentage of 0's in data: \", bin_count[0]*100/sum(bin_count), \"%.\")\n",
        "print(\"The percentage of 1's in data: \", bin_count[1]*100/sum(bin_count), \"%.\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [383 307]\n",
            "The percentage of 0's in data:  55.507246376811594 %.\n",
            "The percentage of 1's in data:  44.492753623188406 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW0hDxy-LS28"
      },
      "source": [
        "Καταλήγουμε, λοιπόν, ότι τα ποσοστά είναι περίπου 55.5% για την κλάση 0 και 44.5% για την κλάση 1. Επομένως, το dataset είναι <b>ισορροπημένο</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqMTLEANH4ST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b16b5bf-04fc-4364-890b-42591c35fb76"
      },
      "source": [
        "# print(labels[:5])\n",
        "print(features.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(690, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe7knthjExus"
      },
      "source": [
        "###Εντοπισμός κατηγορικών χαρακτηριστικών\n",
        "Το dataset περιλαμβάνει εκτός από χαρακτηριστικά με συνεχείς αριθμητικές τιμές και κατηγορικά χαρακτηριστικά. Από τις πληροφορίες που έχουμε για το dataset, τα χαρακτηριστικά που είναι κατηγορικά είναι αυτά που αντιστοιχούν στις στήλες:\n",
        "\n",
        "    0,3,4,5,6,8,9,11,12\n",
        "\n",
        "Ο χειρισμός των κατηγορικών συμβόλων θα γίνει μετά το χειρισμό των απουσιάζουσων τιμών και πριν το Cross Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yni1P1F6D-89"
      },
      "source": [
        "##Διαχωρισμός του dataset\n",
        "Διαχωρίζουμε το dataset σε train και test set, χρησιμοποιώντας το 80% των δεδομένων για το training και το 20% για το testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hze8obkLEg0K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=78)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOLwbo9dBD4a"
      },
      "source": [
        "train_pd = pd.DataFrame(data=train[:,:],    # values\n",
        "                 index=train[:,0])    # 1st column as index\n",
        "                  \n",
        "test_pd = pd.DataFrame(data=test[:,:],    # values\n",
        "                 index=test[:,0])    # 1st column as index"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrNfyxLaBd8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d988057-e249-4ef0-d073-91b00d2eae57"
      },
      "source": [
        "print(train.shape)\n",
        "print(train_pd.shape)\n",
        "\n",
        "print(test.shape)\n",
        "print(test_pd.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(552, 15)\n",
            "(552, 15)\n",
            "(138, 15)\n",
            "(138, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo0VGdmqlTjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5584bb2-7370-4fb6-99ce-eb3ae0ce8981"
      },
      "source": [
        "from collections import defaultdict\n",
        "# just for checking...\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "check = defaultdict(int)\n",
        "for i in range(0,len(train_labels)):\n",
        "    check['pos_train'] += train_labels[i] == 1\n",
        "    check['neg_train'] += train_labels[i] == 0\n",
        "    \n",
        "\n",
        "# for i in range(0,len(test_labels)):\n",
        "#     check['pos_test'] += test_labels[i] == 1\n",
        "#     check['neg_test'] += test_labels[i] == 0\n",
        "    \n",
        "# print(check)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(552, 15)\n",
            "(138, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Myc4SzW_5CKC"
      },
      "source": [
        "##Κατασκευή Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNwAJkIN_XGK"
      },
      "source": [
        "###Χειρισμός απουσιάζουσων τιμών\n",
        "Όπως καταλήξαμε θα χρησιμοποιηθεί ο μετασχηματιστής Imputer, για τον χειρισμό των απουσιάζουσων τιμών, θέτοντας σε αυτές την πιο συχνή τιμή του χαρακτηριστικού για τα κατηγορικά χαρακτηριστικά και τη μέση τιμή του χαρακτηριστικού για τα αριθμητικά.\n",
        "\n",
        "Αυτό το επιτυγχάνουμε χωρίζοντας το train και test σε δύο πίνακες με τα αριθμηρικά και τα κατηγορικά χαρακτηριστικά αντίστοιχα, αντικαθιστώντας με την κατάλληλη τιμή και στη συνέχεια ξαναενώνοντας τους δύο πίνακες, θέτοντας τη σωστή σειρά στις στήλες."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-EJG3JR_wjD"
      },
      "source": [
        "# create imputer that will replace NaN with the most frequent value\n",
        "imp_num=SimpleImputer(missing_values=np.NaN,strategy=\"mean\")\n",
        "imp_cat=SimpleImputer(missing_values=np.NaN,strategy=\"most_frequent\")\n",
        "\n",
        "# split train data to numerical and non-numerical\n",
        "train_num = train_pd[[1,2,7,10,13,14]]\n",
        "train_cat = train_pd[[0,3,4,5,6,8,9,11,12]]\n",
        "\n",
        "# fit and transform train data by replacing NaN with the most frequent value of the attribute\n",
        "# numerical\n",
        "i_train_num=pd.DataFrame(imp_num.fit_transform(train_num))\n",
        "i_train_num.columns=train_num.columns\n",
        "i_train_num.index=train_num.index\n",
        "\n",
        "# non-numerical\n",
        "i_train_cat=pd.DataFrame(imp_cat.fit_transform(train_cat))\n",
        "i_train_cat.columns=train_cat.columns\n",
        "i_train_cat.index=train_cat.index\n",
        "\n",
        "# concat the two tables\n",
        "i_train = pd.concat([i_train_num, i_train_cat], axis=1, sort=False)\n",
        "# set the right order of columns\n",
        "i_train = i_train[train_pd.columns]\n",
        "\n",
        "# transform the test data using the same model\n",
        "test_num = test_pd[[1,2,7,10,13,14]]\n",
        "test_cat = test_pd[[0,3,4,5,6,8,9,11,12]]\n",
        "\n",
        "i_test_num = pd.DataFrame(imp_num.transform(test_num.values))\n",
        "i_test_num.columns=test_num.columns\n",
        "i_test_num.index=test_num.index\n",
        "i_test_cat = pd.DataFrame(imp_cat.transform(test_cat.values))\n",
        "i_test_cat.columns=test_cat.columns\n",
        "i_test_cat.index=test_cat.index\n",
        "\n",
        "# concat the two tables\n",
        "i_test = pd.concat([i_test_num, i_test_cat], axis=1, sort=False)\n",
        "# set the right order of columns\n",
        "i_test = i_test[test_pd.columns]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtvh5TWcEQnj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b6f54c-adc5-4300-ac65-bcb7a4caaf21"
      },
      "source": [
        "print(train_pd.shape)\n",
        "print(i_train.shape)\n",
        "\n",
        "print(test_pd.shape)\n",
        "print(i_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(552, 15)\n",
            "(552, 15)\n",
            "(138, 15)\n",
            "(138, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuYB4UObEuGh"
      },
      "source": [
        "###Χειρισμός κατηγορικών χαρακτηριστικών\n",
        "\n",
        "Για τον χειρισμό των κατηγορικών χαρακτηριστικών θα μετατρέψουμε τα μη διατεταγμένα χαρακτηριστικά με m τιμές σε m binary χαρακτηριστικά από τα οποία μόνο ένα είναι ενεργό κάθε φορά. Τα μη διατεταγμένα χαρακτηριστικά είναι τα: \n",
        "    0,3,4,5,6,8,9,11,12\n",
        "Επομένως εκτελούμε:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg0Co3aQHerv"
      },
      "source": [
        "# οι κολόνες 0,3,4,5,6,8,9,11,12 έχουν κατηγορικές μεταβλητές. \n",
        "# Using \"get_dummies\" we convert to binary characteristics\n",
        "\n",
        "# converting train data\n",
        "dummies_train = pd.get_dummies(i_train, columns=[0,3,4,5,6,8,9,11,12])\n",
        "\n",
        "\n",
        "# converting test data\n",
        "# convert to dataframe \n",
        "mtdf = pd.DataFrame(i_test)\n",
        "dummies_test = pd.get_dummies(mtdf, columns=[0,3,4,5,6,8,9,11,12])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtXtMrtVQuzN"
      },
      "source": [
        "Σε αυτό το σημείο θα πρέπει να έχουν δημιουργηθεί για κάθε τιμή των χαρακτηριστικών του συνόλου δεδομένων στο train dataset δυαδικά χαρακτηριστικά που δηλώνουν αν έχει ή όχι το δείγμα για το συγκεκριμένο χαρακτηριστικό αυτήν τιμή. Το ίδιο ισχύει και για το σύνολο δεδομένων στο test dataset. Ωστόσο, το δεύτερο είναι πολύ μικρότερο από το πρώτο και ανάλογα το πώς έγινε το split κάποιες τιμές για ορισμένα χαρακτηριστικά μπορεί να μην περιέχονται και στα 2 σύνολα, με αποτέλεσμα διαφορετικά σύνολα στηλών στα train και test. Για να αντιμετωπίσουμε αυτό το ζήτημα βρίσκουμε τις στήλες που εμφανίζονται μόνο στο ένα σύνολο δεδομένων και τις προσθέτουμε στο άλλο θέτοντας τιμή **0**. Αυτό το κάνουμε και για τα δύο σύνολα, αφού αν και λιγότερο πιθανό, μία τιμή ενός χαρακτηριστικού δύναται να περιέχεται στο test dataset και όχι στο train dataset. Ακολουθεί η υλοποίηση των παραπάνω:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1-Z7DCYIX8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2912e43-f393-42be-fc75-a90494370e66"
      },
      "source": [
        "add_to_test = set(dummies_train.columns.values) - set(dummies_test.columns.values)\n",
        "for col in add_to_test:\n",
        "    dummies_test[col] = 0\n",
        "dummies_test = dummies_test[dummies_train.columns]\n",
        "print(dummies_test.shape[1] == dummies_test.shape[1])\n",
        "\n",
        "# MAYBE DO IT FOR TRAIN TO"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT_QqvfRWIOe"
      },
      "source": [
        "Επομένως, με αυτόν τον τρόπο διασφαλίζουμε ότι τα δύο σύνολα έχουν <u>τα ίδια χαρακτηριστικά και με την ίδια σειρά</u>. \n",
        "\n",
        "Τέλος, μετατρέπουμε σε αριθμητικές τιμές:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTIxsYqhWaWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d71246e3-8f16-4c5d-d3b2-eb2157456509"
      },
      "source": [
        "# Μετατρέπουμε σε αριθμητικές τιμές (pd.to_numeric) και σε numpy array (.values)\n",
        "final_train = dummies_train.apply(pd.to_numeric).values\n",
        "print(final_train.shape)\n",
        "# Μετατρέπουμε σε αριθμητικές τιμές (pd.to_numeric) και σε numpy array (.values)\n",
        "final_test = dummies_test.apply(pd.to_numeric).values\n",
        "print(final_test.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(552, 46)\n",
            "(138, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYmrUc66NnUJ"
      },
      "source": [
        "Βλέπουμε, όπως αναμενόταν, ότι το πλήθος των χαρακτηριστικών φαίνεται έχει πλέον αυξηθεί.\n",
        "Στην πραγματικότητα παραμένουν τα ίδια χαρακτηριστικά, ωστόσο για κάθε κατηγορικό χαρακτηριστικό Κ, δημιουργούμε το χαρακτηριστικό έχειΚ_V για κάθε δυνατή τιμή του K, V, το οποίο έχει τιμή 1 μόνο αν το συγκεκριμένο δείγμα έχει την τιμή V για το χαρακτηριστικό αυτό."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmD18iivv6_8"
      },
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def get_transformers(my_list):\n",
        "    \"\"\"\n",
        "    Function that gets a list of all the transformers that can be used\n",
        "    and returns a list of subists, where each sublist is a unique combination\n",
        "    of the transformers.\n",
        "    \"\"\"\n",
        "    sublists = []\n",
        "    for i in range(0, len(my_list)+1):\n",
        "        temp = [list(x) for x in combinations(my_list, i) if not (('scaler' in x and 'min_max_scaler' in x) or ('ros' in x and 'rus' in x))]  #get the combinations with i elements\n",
        "        # scaler and min_max_scaler will not be used in the same pipeline. The same for ros and rus\n",
        "        sublists.extend(temp)    #and add to initial list\n",
        "    return sublists\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5l4kqHEiVaf"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# import the packages for the transformers and classifiers we will use\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει .transform kai ΄όχι ως scale()\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "\n",
        "\n",
        "# dict that maps the classifier with the appropriate syntax of the\n",
        "# gridsearchCV attribute\n",
        "est_mapper_keys = {\n",
        "    'selector': 'selector__threshold',\n",
        "    'pca': 'pca__n_components',\n",
        "    'dummy': 'dummy__strategy',\n",
        "    'kNN': 'kNN__n_neighbors',\n",
        "    'mlp': ['hidden_layer_sizes', 'activation', 'solver', 'max_iter', 'alpha', 'learning_rate'],\n",
        "    'svc': ['pca__n_components', 'svc__kernel', 'svc__C', 'svc__gamma', 'svc__tol', 'svc__loss', 'svc__degree']\n",
        "}\n",
        "\n",
        "# initialize models\n",
        "selector = VarianceThreshold()\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "scaler = StandardScaler()\n",
        "ros = RandomOverSampler()\n",
        "rus = RandomUnderSampler()\n",
        "pca = PCA()\n",
        "dummy = DummyClassifier()\n",
        "gnb = GaussianNB()\n",
        "knn = neighbors.KNeighborsClassifier(n_jobs=-1)\n",
        "mlp = MLPClassifier()\n",
        "svc = SVC()\n",
        "\n",
        "def getEstDict(steps, est_values_mapper):\n",
        "    \"\"\"\n",
        "    Function that returns the dictionary that will be used as argument\n",
        "    for the GridSearchCV.\n",
        "    For every step in the steps of the pipeline it checks whether\n",
        "    there can be any argument for the GridSearchCV function and if there is, \n",
        "    it adds to the dictionary the proper attribute name and its value.\n",
        "    \"\"\"\n",
        "\n",
        "    dict = {}\n",
        "    for step in steps:\n",
        "        if step[0] in est_mapper_keys:\n",
        "            #\n",
        "            if step[0] != 'mlp' and step[0] != 'kNN':\n",
        "                dict[est_mapper_keys[step[0]]] = est_values_mapper[step[0]]\n",
        "            # \n",
        "            else:\n",
        "                for key in est_values_mapper[step[0]]:\n",
        "                    dict[est_mapper_keys[step[0]]] = est_values_mapper[step[0]][key]\n",
        "    \n",
        "    return dict\n",
        "\n",
        "\n",
        "\n",
        "def runEstimators(train, test, train_labels, test_labels, \n",
        "                  my_transformers, my_classifiers, est_values_mapper, \n",
        "                  cv=10, scoring='f1_macro', showResults = False):\n",
        "\n",
        "    \n",
        "\n",
        "    f1_scores = {}\n",
        "    # f1_scores['micro'] = {}\n",
        "    # f1_scores['macro'] = {}\n",
        "    f1_scores['best_estimator'] = {}\n",
        "    f1_scores['fit_time'] = {}\n",
        "    f1_scores['predict_time'] = {}\n",
        "    # f1_scores['report'] = {}\n",
        "    f1_scores['preds'] = {}\n",
        "    \n",
        "    counter = 0\n",
        "    for sequence in get_transformers(my_transformers):\n",
        "        \n",
        "        # add trasformers\n",
        "        steps = []  #initialize\n",
        "        steps = [(trans, my_transformers[trans]) for trans in sequence]\n",
        "        \n",
        "        # add classifier\n",
        "        for classifier in my_classifiers:\n",
        "            counter+=1\n",
        "            # print(classifier)\n",
        "            if len(steps): steps.pop()  #delete previous classifier\n",
        "            steps.append((classifier, my_classifiers[classifier])) #add new classifier\n",
        "            \n",
        "            # create Pipe\n",
        "            pipe = Pipeline(steps=steps, memory = 'tmp')\n",
        "            if cv:\n",
        "                # create gridsearch parameters\n",
        "                estimator_dict = getEstDict(steps, est_values_mapper)\n",
        "                # create Estimator\n",
        "                estimator = GridSearchCV(pipe, estimator_dict, cv=2, scoring=scoring, n_jobs=-1, verbose=10)\n",
        "                fit_start_time = time.time()    #start counting fit time\n",
        "                # fit estimator\n",
        "                estimator.fit(train, train_labels)\n",
        "                f1_scores['fit_time'][classifier+str(counter)] = time.time() - fit_start_time\n",
        "            else:\n",
        "                estimator = pipe.fit(train, train_labels)\n",
        "            \n",
        "            # test on test data\n",
        "            predict_start_time = time.time()    #start counting predict time\n",
        "            preds = estimator.predict(test)\n",
        "            \n",
        "            f1_scores['predict_time'][classifier+str(counter)] = time.time() - predict_start_time\n",
        "            # f1_scores['micro'][classifier+str(counter)] = f1_score(test_labels, preds, average='micro')\n",
        "            # f1_scores['macro'][classifier+str(counter)] = f1_score(test_labels, preds, average='macro')\n",
        "            # f1_scores['report'][classifier+str(counter)] = str(classification_report(test_labels, preds, target_names=[\"rejected\", \"granted\"]))\n",
        "            f1_scores['preds'][classifier+str(counter)] = preds\n",
        "            if cv:\n",
        "                f1_scores['best_estimator'][classifier+str(counter)] =  estimator.best_estimator_\n",
        "                \n",
        "            if showResults:\n",
        "                print(\"The average f1-micro average of the \"+ classifier +\" classifier is: \", f1_score(test_labels, preds, average='micro'))\n",
        "                print(\"The average f1-macro average of the \"+ classifier +\" classifier is: \", f1_score(test_labels, preds, average='macro'))\n",
        "                print(\"The classification report:\")\n",
        "                print(classification_report(test_labels, preds, target_names=[\"rejected\", \"granted\"]))\n",
        "                disp1 = plot_confusion_matrix(estimator, test, test_labels,\n",
        "                                    display_labels=[\"rejected\", \"granted\"],\n",
        "                                    cmap=plt.cm.Blues)\n",
        "                plt.show()\n",
        "                print(\"================================================================================\")\n",
        "        #     break\n",
        "        # break\n",
        "    print(counter)\n",
        "    return f1_scores\n"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ObxRFPVj1mb"
      },
      "source": [
        "# estimator.get_params().keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkpJu5odkVO3"
      },
      "source": [
        "# print(estimator.best_estimator_)\n",
        "# print(estimator.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5mNVBXGdNRE"
      },
      "source": [
        "##Baseline Classification - Ταξινόμηση χωρίς προεπεξεργασία"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQB2ODT4dUbU"
      },
      "source": [
        "Έχοντας υλοποιήσει τα παραπάνω, θα εκπαιδευτούν στο train dataset οι διάφοροι ταξινομητές (Dummy, Gausian Naive Bayes και K-Nearest Neighbors), χωρίς κάποια προεπεξεργασία των δεδομένων, εκτός από τον χειρισμό των απουσιάζουσων τιμών και των κατηγορικών χαρακτηριστικών και με τις default παραμέτρους τους:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7592my4QlkWK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "731f4472-7399-46f2-fb0e-a68cf94de09b"
      },
      "source": [
        "# dict that maps the classifier with its model\n",
        "classifiers = {\n",
        "    'dummy': dummy,\n",
        "    'gnb': gnb,\n",
        "    'kNN': knn\n",
        "\n",
        "}\n",
        "\n",
        "f1_scores_default = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels, my_transformers={}, my_classifiers=classifiers, est_values_mapper={}, cv=None, showResults=True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "The average f1-micro average of the dummy classifier is:  0.4927536231884058\n",
            "The average f1-macro average of the dummy classifier is:  0.49007601351351354\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.56      0.50      0.53        78\n",
            "     granted       0.43      0.48      0.45        60\n",
            "\n",
            "    accuracy                           0.49       138\n",
            "   macro avg       0.49      0.49      0.49       138\n",
            "weighted avg       0.50      0.49      0.49       138\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "The average f1-micro average of the gnb classifier is:  0.8333333333333334\n",
            "The average f1-macro average of the gnb classifier is:  0.8266994266994266\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.82      0.91      0.86        78\n",
            "     granted       0.86      0.73      0.79        60\n",
            "\n",
            "    accuracy                           0.83       138\n",
            "   macro avg       0.84      0.82      0.83       138\n",
            "weighted avg       0.84      0.83      0.83       138\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "The average f1-micro average of the kNN classifier is:  0.7028985507246377\n",
            "The average f1-macro average of the kNN classifier is:  0.6871094398053421\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.70      0.82      0.76        78\n",
            "     granted       0.70      0.55      0.62        60\n",
            "\n",
            "    accuracy                           0.70       138\n",
            "   macro avg       0.70      0.69      0.69       138\n",
            "weighted avg       0.70      0.70      0.70       138\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeE5j1aUNA0P"
      },
      "source": [
        "Στη συνέχεια, έχοντας αποθηκεύσει τις τιμές των μετρικών F1-micro average και F1-macro average, τις αναπαριστούμε γραφικά:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3lXy5jkqduh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "1e1e9d3e-7ac5-4d6f-8902-e509080d383d"
      },
      "source": [
        "# plot for f1-macro average\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "clfs = f1_scores_default['preds'].keys()\n",
        "f1_macro_scores = [f1_score(test_labels, pred, average='macro') for pred in f1_scores_default['preds'].values()]\n",
        "ax.bar(clfs,f1_macro_scores, color='cyan', width=0.3)\n",
        "plt.title(\"F1 Macro Average\")\n",
        "plt.xlabel(\"Classifiers\")\n",
        "plt.ylabel(\"F1 Macro Score\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# plot for f1-micro average\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "clfs = f1_scores_default['preds'].keys()\n",
        "f1_micro_scores = [f1_score(test_labels, pred, average='micro') for pred in f1_scores_default['preds'].values()]\n",
        "ax.bar(clfs,f1_micro_scores, color='b', width=0.3)\n",
        "plt.title(\"F1 Micro Average\")\n",
        "plt.xlabel(\"Classifiers\")\n",
        "plt.ylabel(\"F1 Micro Score\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAFdCAYAAAAwtwU9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwlZX3v8c+XQYSgAgYzRoYAmjEGN9AGYnAZVASMAioqmIh41XHDuGECMZcQ1OSqo+YacRkNLnEZiRAcdSIapeOuMywuAxecIMqgRkQWG9n53T9OtRya7p4zTFfX6e7P+/U6L0899VTVr8eH/vZTp05VqgpJktSdrbouQJKkhc4wliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYuouSXJrk+iRjfa/7NetWJrkoyW1JjtnEfj6UpJIcNqH9HU37tNvPliTHNPU8u+tapPnGMJa2zFOr6h59r5827d8FXgacO+B+LgaOHl9IsjXwLOC/Z7Ta2/d9VzwP+BV9dc6kLahLmvMMY6kFVXVKVX0JuGHATT4DPDrJTs3ywcD3gJ+Pd0jygCRfTnJlkl8m+ViSHfvW75rkjCRXNH3e1bQfk+TrzUz7SuCkJDsk+UjT98dJ/jbJlL8PkuwGPA5YDhyU5L5N+3uSrJjQ99NJXtO8v1+S05vj/CjJX/b1OynJp5J8NMm1wDFJ9k3yzSRXJ/lZkncl2aZvmyc1ZxyuSfLuJP+V5IV96/9XkguTXJXkrKZuaegZxtJwuAH4NHBks3w08JEJfQL8I3A/4I+BXYGTAJIsAj4L/BjYHdgFWNW37X7AJcBi4E3APwM7APenF7JHA8+fpr6jgXVVdTpwIfDnTfsngGcnSVPHTsCTgFVNuH+G3lmCXYAnAK9KclDffg8DPgXsCHwMuBV4NbAz8Khmm5c1+9656XsC8LvARcCf/vYfp3ea/2+ApwP3Ab7a1CcNPcNY2jJnNrO4q5OcuYX7+ghwdDPbfRxwh/1V1Yaq+mJV3VhVVwBvb/oB7EsvpF9XVddV1Q1V9bW+zX9aVf9cVbcAN9EL/ROq6tdVdSnwNuC509R2NPDx5v3Huf1U9VeBAh7TLB8BfLM5Xb8PcJ+qOrmqbqqqS4D3c/sfHDR9z6yq26rq+qo6p6q+VVW3NHW9r+9nfDKwvqrOaH6Od9J35gB4CfCPVXVhs/4fgL2cHWsuMIylLXN4Ve3YvA7fkh014Xkf4PXAZ6vq+v71SRYnWZXk8ua07kfpzSChN0v+cRNCk7ms7/3OwN3ozaLH/Zje7PVOkuwP7MHtM+2PAw9Nslf1njSzCjiqWfccejNcgN2A+/X9sXI1vZnr4inqIskDk3w2yc+bn/Ef+n7G+/X3b469sW/z3YD/23esX9E7mzDpzyUNE8NYGi4fBV7LnU9RQy+YCnhoVd0L+At6YQO9kPqDaS6C6n882y+Bm+mF17g/AC6fYtvnNcc5P8nPgW/3tUPvVPARzQx0P+D0vpp+1PfHyo5Vdc+qevIUdQG8B/h/wNLmZ/ybvp/xZ8CS8Y7NqfElfdteBrx4wvG2q6pvTPFzSUPDMJZakGSbJNvSC5K7Jdl2uguk+rwTOBD4yiTr7gmMAdck2QV4Xd+679ALq/+TZPvmePtPdoCquhU4DXhTkns2Ifoaen8ITPw5tqV3VfdyYK++1yuA5yTZuqrOoxfwHwDOqqqr+2r6dZK/TrJdkkVJHpJkn2l+/nsC1wJjSR4EvLRv3efozcgPb/7oeDlw37717wVOSPLgpvYdkjxzmmNJQ8MwltrxBeB6ehcYrWzeP3ZTG1XVr6rqSzX5g8b/HngEcA29YDqjb7tbgacCfwj8hN7p2+m+D/wK4Dp6F3V9jd6p51Mn6Xd4U/tHqurn46+m79b0rvqm2f6J3P658nhNT6EX3j/i9sDeYZq6jqN3qvvX9D5f/mTf/n4JPBN4C3AlsCewDrixWf/vwJvpXTx2LfAD4JBpjiUNjUz+37wkDbfmTMNG4M+r6uyu65G2hDNjSXNGkoOS7Jjk7tz+efK3Oi5L2mKGsaS55FH07kr2S3qn5Q+feNW5NBd5mlqSpI45M5YkqWOGsSRJHZtzT0nZeeeda/fdd++6jM1y3XXXsf3223ddhrRJjlXNFXNxrJ5zzjm/rKr7TLZuzoXx7rvvzrp167ouY7OMjo6ybNmyrsuQNsmxqrliLo7VJD+eap2nqSVJ6phhLElSxwxjSZI6ZhhLktQxw1iSpI4ZxpIkdcwwliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYmgMyS69zZuk4ku7IMJYkqWOGsSRJHTOMJUnqmGEsSVLHWg3jJAcnuSjJhiTHT7L+D5KcneS8JN9L8uQ265EkaRi1FsZJFgGnAIcAewJHJdlzQre/BU6rqr2BI4F3t1WPJEnDqs2Z8b7Ahqq6pKpuAlYBh03oU8C9mvc7AD9tsR5JkobS1i3uexfgsr7ljcB+E/qcBHwhySuA7YEnTrajJMuB5QCLFy9mdHR0pmtt1djY2JyrWcNlxSwdZ8nYGCtmYay2fwTNd/Pt92qbYTyIo4APVdXbkjwK+NckD6mq2/o7VdVKYCXAyMhILVu2bPYr3QKjo6PMtZo1XA6YpeOsGB3luFkYq9X6ETTfzbffq22epr4c2LVveUnT1u8FwGkAVfVNYFtg5xZrkiRp6LQZxmuBpUn2SLINvQu0Vk/o8xPgCQBJ/pheGF/RYk2SJA2d1sK4qm4BjgXOAi6kd9X0+iQnJzm06fZa4EVJvgt8AjimqjyDJUlaUFr9zLiq1gBrJrSd2Pf+AmD/NmuQJGnYeQcuSZI6ZhhLktQxw1iSpI4ZxpIkdcwwliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYkqSOGcaSJHXMMJYkqWOGsSRJHTOMJUnqmGEsSVLHDGNJkjpmGEuS1DHDWJKkjhnGkiR1zDCWJKljhrEkSR0zjCVJ6phhLElSx1oN4yQHJ7koyYYkx0+y/h1Jzm9eFye5us16JEkaRlu3teMki4BTgAOBjcDaJKur6oLxPlX16r7+rwD2bqseSZKGVZsz432BDVV1SVXdBKwCDpum/1HAJ1qsR5KkodRmGO8CXNa3vLFpu5MkuwF7AF9usR5JkoZSa6epN9ORwKeq6tbJViZZDiwHWLx4MaOjo7NY2pYbGxubczVruKyYpeMsGRtjxSyM1faPoPluvv1ebTOMLwd27Vte0rRN5kjg5VPtqKpWAisBRkZGatmyZTNU4uwYHR1lrtWs4XLALB1nxegox83CWK3Wj6D5br79Xm3zNPVaYGmSPZJsQy9wV0/slORBwE7AN1usRZKkodVaGFfVLcCxwFnAhcBpVbU+yclJDu3reiSwqqr8Y1mStCC1+plxVa0B1kxoO3HC8klt1iBJmj2ZpeOsoP2Pb2ZzhugduCRJ6phhLElSxwxjSZI6ZhhLktQxw1iSpI4ZxpIkdcwwliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYkqSOGcaSJHXMMJYkqWOGsSRJHTOMJUnqmGEsSVLHDGNJkjpmGEuS1DHDWJKkjhnGkiR1zDCWJKljhrEkSR1rNYyTHJzkoiQbkhw/RZ9nJbkgyfokH2+zHkmShtHWbe04ySLgFOBAYCOwNsnqqrqgr89S4ARg/6q6KsnvtVWPJEnDqs2Z8b7Ahqq6pKpuAlYBh03o8yLglKq6CqCqftFiPZIkDaU2w3gX4LK+5Y1NW78HAg9M8vUk30pycIv1SJI0lFo7Tb0Zx18KLAOWAF9J8tCqurq/U5LlwHKAxYsXMzo6OstlbpmxsbE5V7OGy4pZOs6SsTFWzMJYbf8I6sp8Gqvt7v2O2gzjy4Fd+5aXNG39NgLfrqqbgR8luZheOK/t71RVK4GVACMjI7Vs2bK2am7F6Ogoc61mDZcDZuk4K0ZHOW4Wxmq1fgR1ZT6N1dkcp22epl4LLE2yR5JtgCOB1RP6nElvVkySnemdtr6kxZokSRo6rYVxVd0CHAucBVwInFZV65OcnOTQpttZwJVJLgDOBl5XVVe2VZMkScOo1c+Mq2oNsGZC24l97wt4TfOSJGlB8g5ckiR1zDCWJKljhrEkSR0zjCVJ6phhLElSxwxjSZI6ZhhLktQxw1iSpI4ZxpIkdcwwliSpY4axJEkdM4wlSeqYYSxJUsc2GcZJfifJ/07y/mZ5aZKntF+aJEkLwyAz4w8CNwKPapYvB97YWkWSJC0wg4TxA6rqLcDNAFX1GyCtViVJ0gIySBjflGQ7oACSPIDeTFmSJM2ArQfo83fA54Fdk3wM2B84ps2iJElaSKYN4yRbATsBTwf+hN7p6VdW1S9noTZJkhaEacO4qm5L8ldVdRrwuVmqSZKkBWWQz4z/M8lxSXZNcu/xV+uVSZK0QAzymfGzm/99eV9bAfef+XIkSVp4NhnGVbXHbBQiSdJCtckwTnI34KXAY5umUeB9VXVzi3VJkrRgDPKZ8XuARwLvbl6PbNo2KcnBSS5KsiHJ8ZOsPybJFUnOb14v3JziJUmaDwb5zHifqnp43/KXk3x3UxslWQScAhwIbATWJlldVRdM6PrJqjp24IolSZpnBpkZ39rcdQuAJPcHbh1gu32BDVV1SVXdBKwCDrtrZUqSNH8NMjN+HXB2kkvo3fRjN+D5A2y3C3BZ3/JGYL9J+j0jyWOBi4FXV9Vlk/SRJGneGuRq6i8lWQr8UdN0UVXN1L2pPwN8oqpuTPJi4MPA4yd2SrIcWA6wePFiRkdHZ+jws2NsbGzO1azhsmKWjrNkbIwVszBW2z+CujKfxmq7e7+jVNX0HZKXAx+rqqub5Z2Ao6rq3ZvY7lHASVV1ULN8AkBV/eMU/RcBv6qqHabb78jISK1bt27amofN6Ogoy5Yt67oMzWGz9Zi0FaOjHDcLY3X63zqay+bTWJ3pcZrknKoamWzdIJ8Zv2g8iAGq6irgRQNstxZYmmSPJNsARwKrJxT2+32LhwIXDrBfSZLmlUHCeFGS3/6x08xgt9nURlV1C3AscBa9kD2tqtYnOTnJoU23v0yyvrk6+y/p4GlQmYXXObN0HEnS3DTIBVyfBz6Z5H3N8oubtk2qqjXAmgltJ/a9PwE4YbBSJUmanwYJ47+md/HUS5vlLwIfaK0iSZIWmEGupr4NeG+SU4EHA5dX1SDfM5YkSQOY8jPjJO9N8uDm/Q7A+cBHgPOSHDVL9UmSNO9NdwHXY6pqffP++cDFVfVQevem/qvWK5MkaYGYLoxv6nt/IHAmQFX9vNWKJElaYKYL46uTPCXJ3sD+NFdQJ9ka2G42ipMkaSGY7gKuFwPvBO4LvKpvRvwE4HNtFyZJ0kIxZRhX1cXAwZO0n0XvRh6SJGkGDHIHLkmS1CLDWJKkjhnGkiR1bJNhnGSHJO9Isq55va25CYgkSZoBg8yMTwWuBZ7VvK4FPthmUZIkLSSDPCjiAVX1jL7lv09yflsFSZK00AwyM74+yaPHF5LsD1zfXkmSJC0sg8yMXwJ8pO9z4quA57VXkiRJC8u0YZxkEfDcqnp4knsBVNW1s1KZJEkLxLRhXFW3jp+iNoQlSWrHIKepz0uyGvg34Lrxxqo6o7WqJElaQAYJ422BK4HH97UVYBhLkjQDNhnGVfX82ShEkqSFapA7cH04yY59yzslObXdsiRJWjgG+Z7xw6rq6vGFqroK2Lu9kiRJWlgGCeOtkuw0vpDk3gz2WbMkSRrAIGH8NuCbSd6Q5I3AN4C3DLLzJAcnuSjJhiTHT9PvGUkqychgZUuSNH8McgHXR5KcAxzQND29qi7Y1HbNDUNOAQ4ENgJrk6yeuG2SewKvBL69ucVLkjQfDPQ846paD5wGrAbGkvzBAJvtC2yoqkuq6iZgFXDYJP3eALwZuGGwkiVJml8GuZr60CQ/BH4E/BdwKfAfA+x7F+CyvuWNTVv/vh8B7FpVnxu0YEmS5ptBLsR6A/AnwH9W1d5JDgD+YksPnGQr4O3AMQP0XQ4sB1i8eDGjo6NbevjfWjFje5rakrExVsxgzVNp/wjqymyMU3CsasvNp7Ha7t7vaJAwvrmqrkyyVZKtqursJP80wHaXA7v2LS9p2sbdE3gIMJoE4L7A6iSHVtW6/h1V1UpgJcDIyEgtW7ZsgMMP5oBNd9liK0ZHOW4Ga55KtX4EdWU2xik4VrXl5tNYnc1xOkgYX53kHsBXgI8l+QV996iexlpgaZI96IXwkcBzxldW1TXAzuPLSUaB4yYGsSRJ890gF3AdBlwPvBr4PPDfwFM3tVFV3QIcC5wFXAicVlXrk5yc5NC7XrIkSfPLIF9t6p8Ff3hzdl5Va4A1E9pOnKLvss3ZtyRJ88WUYZzk19zxlHma5QBVVfdquTZJkhaE6WbGX6J3UdUZwKqq+snslCRJ0sIy5WfGVXU4cBBwBfD+JP+V5GXNvaklSdIMmfYCrqq6pqo+CBwCvA84mQG+FyxJkgY37QVcSf4UOAp4DPA14GlV9dXZKEySpIViugu4LgWupndP6eXALU37IwCq6txZqE+SpHlvupnxpfSunj4IeBK9q6jHFfD49sqSJGnhmDKM/d6vJEmzY6BHKEqSpPYYxpIkdcwwliSpY3cpjJM8aKYLkSRpobqrM+MvzGgVkiQtYNN9z/idU60CdmynHEmSFp7pvmf8fOC1wI2TrDuqnXIkSVp4pgvjtcAPquobE1ckOam1iiRJWmCmC+MjgBsmW1FVe7RTjiRJC890F3Ddo6p+M2uVSJK0QE0XxmeOv0ly+izUIknSgjRdGPc/GOL+bRciSdJCNV0Y1xTvJUnSDJruAq6HJ7mW3gx5u+Y9zXJV1b1ar06SpAVgukcoLprNQiRJWqh8UIQkSR0zjCVJ6lirYZzk4CQXJdmQ5PhJ1r8kyfeTnJ/ka0n2bLMeSZKGUWthnGQRcApwCLAncNQkYfvxqnpoVe0FvAV4e1v1SJI0rNqcGe8LbKiqS6rqJmAVcFh/h6q6tm9xe/wKlSRpAZruq01bahfgsr7ljcB+EzsleTnwGmAb4PGT7SjJcmA5wOLFixkdHZ2xIlfM2J6mtmRsjBUzWPNU2j+CujIb4xQcq9py82mstrv3O0pVO5PRJEcAB1fVC5vl5wL7VdWxU/R/DnBQVT1vuv2OjIzUunXrZq7OGdvT1FaMjnLcsmWtH8fTCvPXbIxTcKxqy82nsTrT4zTJOVU1Mtm6Nk9TXw7s2re8pGmbyirg8BbrkSRpKLUZxmuBpUn2SLINcCSwur9DkqV9i38G/LDFeiRJGkqtfWZcVbckORY4C1gEnFpV65OcDKyrqtXAsUmeCNwMXAVMe4pakqT5qM0LuKiqNcCaCW0n9r1/ZZvHlyRpLvAOXJIkdcwwliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYkqSOGcaSJHXMMJYkqWOGsSRJHTOMJUnqmGEsSVLHDGNJkjpmGEuS1DHDWJKkjhnGkiR1zDCWJKljhrEkSR0zjCVJ6phhLElSxwxjSZI6ZhhLktQxw1iSpI61GsZJDk5yUZINSY6fZP1rklyQ5HtJvpRktzbrkSRpGLUWxkkWAacAhwB7Akcl2XNCt/OAkap6GPAp4C1t1SNJ0rBqc2a8L7Chqi6pqpuAVcBh/R2q6uyq+k2z+C1gSYv1SJI0lLZucd+7AJf1LW8E9pum/wuA/5hsRZLlwHKAxYsXMzo6OkMlwooZ29PUloyNsWIGa55K+0dQV2ZjnIJjVVtuPo3Vdvd+R22G8cCS/AUwAjxusvVVtRJYCTAyMlLLli2bsWMfMGN7mtqK0VGOm8Gap1KtH0FdmY1xCo5Vbbn5NFZnc5y2GcaXA7v2LS9p2u4gyROB1wOPq6obW6xHkqSh1OZnxmuBpUn2SLINcCSwur9Dkr2B9wGHVtUvWqxFkqSh1VoYV9UtwLHAWcCFwGlVtT7JyUkObbq9FbgH8G9Jzk+yeordSZI0b7X6mXFVrQHWTGg7se/9E9s8viRJc4F34JIkqWOGsSRJHTOMJUnqmGEsSVLHDGNJkjpmGEuS1DHDWJKkjhnGkiR1zDCWJKljhrEkSR0zjCVJ6phhLElSxwxjSZI6ZhhLktQxw1iSpI4ZxpIkdcwwliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYkqSOGcaSJHWs1TBOcnCSi5JsSHL8JOsfm+TcJLckOaLNWiRJGlathXGSRcApwCHAnsBRSfac0O0nwDHAx9uqQ5KkYbd1i/veF9hQVZcAJFkFHAZcMN6hqi5t1t3WYh2SJA21Nk9T7wJc1re8sWmTJEl92pwZz5gky4HlAIsXL2Z0dHTG9r1ixvY0tSVjY6yYwZqn0v4R1JXZGKfgWNWWm09jtd2931GbYXw5sGvf8pKmbbNV1UpgJcDIyEgtW7Zsi4sbd8CM7WlqK0ZHOW4Ga55KtX4EdWU2xik4VrXl5tNYnc1x2uZp6rXA0iR7JNkGOBJY3eLxJEmak1oL46q6BTgWOAu4EDitqtYnOTnJoQBJ9kmyEXgm8L4k69uqR5KkYdXqZ8ZVtQZYM6HtxL73a+mdvpYkacHyDlySJHXMMJYkqWOGsSRJHTOMJUnqmGEsSVLHDGNJkjpmGEuS1DHDWJKkjhnGkiR1zDCWJKljhrEkSR0zjCVJ6phhLElSxwxjSZI6ZhhLktQxw1iSpI4ZxpIkdcwwliSpY4axJEkdM4wlSeqYYSxJUscMY0mSOmYYS5LUMcNYkqSOtRrGSQ5OclGSDUmOn2T93ZN8sln/7SS7t1mPJEnDqLUwTrIIOAU4BNgTOCrJnhO6vQC4qqr+EHgH8Oa26pEkaVi1OTPeF9hQVZdU1U3AKuCwCX0OAz7cvP8U8IQkabEmSZKGTpthvAtwWd/yxqZt0j5VdQtwDfC7LdYkSdLQ2brrAgaRZDmwvFkcS3JRl/VsruNgZ+CXbR/HUwraUo5VzRWzMVZbGKe7TbWizTC+HNi1b3lJ0zZZn41JtgZ2AK6cuKOqWgmsbKnO1iVZV1UjXdchbYpjVXPFfBurbZ6mXgssTbJHkm2AI4HVE/qsBp7XvD8C+HJVVYs1SZI0dFqbGVfVLUmOBc4CFgGnVtX6JCcD66pqNfAvwL8m2QD8il5gS5K0oMSJaPuSLG9OtUtDzbGquWK+jVXDWJKkjnk7TEmSOmYYb0KSk5IcNwR1fD7J1Uk+23Utmr+SHJPkXZO075rk7CQXJFmf5JVd1Kf5KcnuSX4woW1Zkkry1L62zyZZ1rwfTbKub91IktHm/b5Jzm9e303ytNn5Se46w3jueCvw3K6L0IJ1C/DaqtoT+BPg5ZPc3laaaRuB10+z/veSHDJJ+w+AkaraCzgYeF/z9dmhZRhPIsnrk1yc5GvAHzVto0lGmvc7J7m0eX9MkjOTfDHJpUmOTfKaJOcl+VaSe/dt/44k65JcmGSfJGck+WGSNzZ9Tk7yqr463jQ+A6mqLwG/ntV/CM0LSf5388CWryX5RJLjmvH45iTfacb6Y/o22bVZ/8MkfwdQVT+rqnOb978GLuTOd9STtliS+yc5D9gH+C5wTZIDp+j+ViYJ66r6TXNXR4BtgaG/OMowniDJI+l9xWov4Mn0BsSmPAR4etP3TcBvqmpv4JvA0X39bmq+pP5e4NPAy5ttj0nyu8Cp4/2TbNXU8dEZ+LG0QCXZB3gG8HB6D23pv0nC1lW1L/Aq4O/62vdttnkY8MzxP0L79rk7sDfw7dYK14KU5I+A04Fj6N2rAnq/U/92ik2+CdyU5IBJ9rVfkvXA94GX9IXzUDKM7+wxwL83f1ldy51vVDKZs6vq11V1Bb37a3+maf8+sHtfv9V97eub2caNwCXArlV1KXBlkr2BJwHnVdWd7kgmbYb9gU9X1Q3NjPYzfevOaP73HO44Tr9YVVdW1fVNn0ePr0hyD3q/LF/V/PchzZT70Juk/HlVfXe8saq+ApDk0VNs90YmCeuq+nZVPZjeJOmEJNvOfMkzxzAe3C3c/u818f/UG/ve39a3fBt3vLHKjZP0mdjvA/T+Knw+vZmy1JbxMXgrdxynE0/pFUCSu9EL4o9V1RlIM+sa4Cf0/fHXZ8rZcVV9GdiO3rUMk62/EBijdxZyaBnGd/YV4PAk2yW5JzB+Jd+lwCOb90e0ePx/p3fBwT707l4mbYmvA09Nsm0zq33KANscmOTeSbYDDge+3jza9F+AC6vq7S3Wq4XrJuBpwNFJntO/oqq+AOxE76OTybwR+KvxheY2zFs373cDHkTvd/jQMownaC5S+SS9Cwf+g9s/t1gBvLS5sGDnFo9/E3A2cFpV3TrenuSrwL/Re+bzxiQHtVWD5o+qWkvv45Hv0RvP36c3A5nOd+jNgL8HnF5V6+id7n4u8Pi+r4w8ub3KtRBV1XX0/mB8NXCvCavfxB0fPtS/3Rrgir6mRwPfTXI+vQnOy6qq9aeRbQnvwDVkmgu3zgWeWVU/7LoezX1J7lFVY0l+h96Zn+XjV0ZLGg7OjIdI873NDcCXDGLNoJXNDOFcejNdg1gaMs6MJUnqmDNjSZI6ZhhLktQxw1iSpI4ZxtIckuS+SVYl+e8k5yRZk+SBE594s4XHODnJE5v3j2me0nR+kl2SfGqmjiPpdl7AJc0RzY03vgF8uKre27Q9nN73Md9TVTN+h6Ek7wW+VlWbfY/0JFsP+/2ApWHhzFiaOw4Abh4PYoDmHr6XjS83z4X9apJzm9efNu2/n+QrzQz3B82Md1GSDzXL30/y6qbvh5IckeSFwLOANyT5WPqeOdts+9Yka5N8L8mLm/ZlzfFXAxck2T7J59J7puwPkjx71v61pDlkqJ/vKOkOHkLvoQ7T+QVwYFXdkGQp8Al6T2p6DnBWVb0pySLgd+g9mWyX8Rl1kh37d1RVH2huzv/ZqvpU87SmcS8ArqmqfZLcnd4tM7/QrHsE8JCq+lGSZwA/rao/a46xw13+6aV5zDCW5pe7Ae9Kshe9B0A8sGlfC5zaPOzhzKo6P8klwP2T/DPwOeALk+5xck8CHpZk/D7tOwBL6QbM+igAAAFLSURBVN1f+DtV9aOm/fvA25K8mV6of3VLfjhpvvI0tTR3rOf2h5VM5dXA/9B7fvEIsA389jF0jwUuBz6U5OiquqrpNwq8hN4TwwYV4BVVtVfz2qO5mT/AdeOdqupiejPl7wNvTHLiZhxDWjAMY2nu+DJw9yTLxxuSPIw73jx/B+BnVXUbvQc7LGr67Qb8T1W9n17oPiLJzsBWVXU6vcfTPWIzajmL3oNT7tbs/4FJtp/YKcn9gN80F4C9dTOPIS0YnqaW5oiqqiRPA/4pyV8DN9B7LNyr+rq9Gzg9ydHA57l9lroMeF2Sm+k92/VoYBfgg83DSQBO2IxyPgDsDpzbXOV9Bb3HLU70UOCtSW4DbgZeuhnHkBYMv9okSVLHPE0tSVLHDGNJkjpmGEuS1DHDWJKkjhnGkiR1zDCWJKljhrEkSR0zjCVJ6tj/B13vWsqUQxxIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtOHr7PXNPxv"
      },
      "source": [
        "###Σχολιασμός αποτελεσμάτων\n",
        "\n",
        "Για την απόδοση των τριών ταξινομητών στα δεδομένα εισόδου έχουμε στη διάθεσή μας τις μετρικές:\n",
        "\n",
        "* **Precision**: Δηλώνει για κάθε κλάση την ακρίβεια των positive προβλέψεων, δηλαδή κατά πόσο ήταν θετικά αυτά που το μοντέλο δήλωσε ως θετικά. Προκύπτει από τον τύπο: **TP/ (TP + FP)**. Αν εφαρμόσουμε τον τύπο στα κατάλληλα δεδομένα των πινάκων σύγχυσης προκύπτουν οι τιμές που εφμανίζονται στο πεδίο  Precision του classification report για την αντίστοιχη κλάση. \n",
        "\n",
        "\n",
        "* **Recall**: Δηλώνει τι ποσοστό από τα positives για την κάθε κλάση προβλέψαμε σωστά. Προκύπτει από τον τύπο: TP /(TP + FN). Αν εφαρμόσουμε τον τύπο στα κατάλληλα δεδομένα των πινάκων σύγχυσης προκύπτουν οι τιμές που εφμανίζονται στο πεδίο  Recall του classification report για την αντίστοιχη κλάση. \n",
        "\n",
        "\n",
        "* **f1 -score**: Δηλώνει τι ποσοστό των θετικών προβλέψεων, για κάθε κλάση, ήταν σωστά. Προκύπτει από τον τύπο :\n",
        "\n",
        "    F1 Score = 2*(Recall * Precision) / (Recall + Precision)    \n",
        "και αν εφαρμόσουμε τις τιμές που προέκψαν προηγουμένως καταλήγουμε στα ίδια αποτελέσματα που υπάρχουν στo classification report, για την αντίστοιχη κλάση.\n",
        "\n",
        "Μελετώντας τις τιμές για τους τρεις classifiers:\n",
        "\n",
        "* Για τον **dummy**: Τα αποτελέσματα δεν ήταν ικανοποιητικά. Η μέθοδος που χρησιμοποιείται από default στον dummy classifier ονομάζεται \"stratified\" και για την αντιστοίχιση των κλάσεων λαμβάνει υπόψιν μόνο τη διατήρηση της ίδιας κατανομής των κλάσεων με αυτή στο train data. Σε κάθε επανάληψη του predict τα αποτελέσματα παρουσιάζουν μεταβολές, ωστόσο σε κάθε περίπτωση οι όλοι δείκτες κινούνται σε αναμενόμενες τιμές. Συγκεκριμένα, είναι λογικό να προβλέπει σταθερά περισσότερα *rejected*, δεδομένου ότι στο αρχικό dataset η κατανομή rejected-granted ήταν περίπου 55%- 45% και με ένα τυχαίο split η κατανομή στο train dataset θα είναι περίπου η ίδια. \n",
        "\n",
        "* Για τον **Naive Gaussain Bayes**: Συγκέτρωσε πολλά δείγματα στην κύρια διαγώνιο του confusion matrix.\n",
        "\n",
        "* Για τον **k-NN**: Τα αποτελέσματά του ήταν καλύτερα από τον \"dummy\", αλλά χειρότερα από τον gnb. Σημείωσε μετριο precision και σχετικά καλό Recall για το rejected, αλλά κακό για το Granted. Μια πιθανή εξήγηση σε αυτό θα ήταν ότι μπορεί να υπάρχουν συγκεκριμένα κριτήρια απόρριψης για την πίστωση, οπότε τα διανύσματα των δειγμάτων θα ήταν κοντινά. Αντίθετα, για την έγκριση πίστωσης μπορεί να είναι περισσότεροι οι παράγοντες και τα διανύσματα των δειγμάτων πολύ διαφορετικά. Επομένως, με μεγαλύτερο k, μπορεί να είχαμε μεγαλύτερο Recall για την κλάση granted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLoHK9vJsY83"
      },
      "source": [
        "##Βελτιστοποίηση ταξινομητών\n",
        "\n",
        "Ασχολούμαστε με τον κάθε ταξινομητή ξεχωριστά:\n",
        "\n",
        "\n",
        "Αρχικά βρίσκουμε το πλήθος των πιθανών συνδυασμών όλων των ταξινομητών (με τη σωστή διάταξη) και στη συνέχεια για κάθε συνδυασμό εφαρμόζουμε Cross Validation με τις αντίστοιχες τιμές των υπερπαραμέτρων. Στο τέλος του κάθε Cross Validation, αποθηκεύουμε, μεταξύ άλλων, τις τιμές f1-micro και f1-macro. Έτσι, αφού ολοκληρωθούν όλα τα Cross Validations, έχουμε στη διάθεσή μας όλες τις μετρικές που μας απασχολούν. Ταξινομόντας με βάση την μετρική που θέλουμε βρίσκουμε τον βέλτιστο συνολικά ταξινομητή, με κανένα, λίγους ή περισσότερους μετασχηματιστές πριν από τον εκτιμητή."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfkXzpQAaMbM"
      },
      "source": [
        "Εκτελούμε τις παρακάτω εντολές για να βρούμε τη διακύμανση στις τιμές των διαφόρων χαρακτηριστικών:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POOH7D00aDGs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f07b1d0-ca65-440a-827b-a1b5708d265b"
      },
      "source": [
        "train_variance = final_train.var(axis=0)\n",
        "print(train_variance)\n",
        "print(np.max(train_variance))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.36214048e+02 2.50808996e+01 1.13895028e+01 2.54195514e+01\n",
            " 3.08196317e+04 1.31891623e+07 2.09564036e-01 2.09564036e-01\n",
            " 1.80831233e-03 1.76157845e-01 1.75170001e-01 1.76157845e-01\n",
            " 1.80831233e-03 1.75170001e-01 7.18303665e-02 1.69105099e-01\n",
            " 5.46103760e-02 3.99305556e-02 3.65961720e-02 6.56604442e-02\n",
            " 8.08883375e-02 1.60385161e-02 6.72127704e-02 5.62086484e-02\n",
            " 9.54598561e-02 3.61006091e-03 8.23750263e-02 5.62086484e-02\n",
            " 8.08883375e-02 1.07514178e-02 7.33564377e-02 1.61730729e-01\n",
            " 1.25203476e-02 5.40524575e-03 1.80831233e-03 2.42438563e-01\n",
            " 1.07514178e-02 2.49051539e-01 2.49051539e-01 2.45746692e-01\n",
            " 2.45746692e-01 2.47948829e-01 2.47948829e-01 8.53287125e-02\n",
            " 8.97592418e-03 7.78952689e-02]\n",
            "13189162.332936227\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTD6qczYeoP2"
      },
      "source": [
        "###Mετρική απόδοσης: **f1-macro**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfUzT2bL0heM"
      },
      "source": [
        "def getResults(scores, opt_est, test, test_labels, class0, class1):\n",
        "    print(\"\\n=========================================================================\\nRESULTS\")\n",
        "    best_estimator = scores['best_estimator'][opt_est]\n",
        "    print(\"Best estimator is: \", best_estimator)\n",
        "    # confusion matrix\n",
        "    disp1 = plot_confusion_matrix(best_estimator, test, test_labels,\n",
        "                                        display_labels=[class0, class1],\n",
        "                                        cmap=plt.cm.Blues)\n",
        "    plt.show()\n",
        "\n",
        "    # print results\n",
        "    print(\"The average f1-micro average is: \", f1_score(test_labels, scores['preds'][opt_est], average='macro'))\n",
        "    print(\"The average f1-macro average is: \", f1_score(test_labels, scores['preds'][opt_est], average='micro'))\n",
        "    print(\"Classification report:\\n\", classification_report(test_labels, scores['preds'][opt_est], target_names=[class0, class1]))\n",
        "    print(\"Fit time: \", scores['fit_time'][opt_est])\n",
        "    print(\"Predict time: \", scores['predict_time'][opt_est])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYeTjRtIs3vw"
      },
      "source": [
        "####Dummy Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7dQhnfltaC1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0b329952-a192-4d59-ffc4-7e02a924147f"
      },
      "source": [
        "import operator\n",
        "\n",
        "# dict that maps the transformer with its model\n",
        "transformers = {'selector': selector,\n",
        "         'scaler': scaler,\n",
        "         'min_max_scaler': min_max_scaler,\n",
        "         'ros': ros,\n",
        "         'rus': rus,\n",
        "         'pca': pca\n",
        "        }\n",
        "\n",
        "# dict that maps the transformer/classifier with the values of its arguments\n",
        "est_values_mapper = {\n",
        "    'selector': [0, 1000, 10000, 1000000],\n",
        "    'pca': [10, 20, 30, 40, 50, 60],\n",
        "    'dummy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'],\n",
        "}\n",
        "\n",
        "\n",
        "f1_scores = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels, \n",
        "                          my_transformers=transformers, my_classifiers={'dummy': dummy}, est_values_mapper=est_values_mapper)\n",
        "\n",
        "\n",
        "# compute f1-macro\n",
        "dummy_macro = {k: f1_score(test_labels, v, average='macro') for k,v in f1_scores['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_est_dummy_macro = max(dummy_macro.items(), key=operator.itemgetter(1))[0]\n",
        "getResults(f1_scores, opt_est_dummy_macro, final_test, test_labels, \"rejected\", \"granted\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0082s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0143s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0095s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0134s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0082s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0128s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0080s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0132s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0091s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0145s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0083s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0134s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0279s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0296s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0399s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0115s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0115s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0401s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0763s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done  37 out of  40 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0126s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0310s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0529s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0122s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0308s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0557s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0104s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0289s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0637s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0140s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0228s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0184s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0257s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0146s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0263s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0126s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0126s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0103s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0307s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0145s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0338s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0127s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0504s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0129s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0223s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0164s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0406s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0511s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0133s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0449s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0544s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0164s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0388s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0606s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0154s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0347s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0596s.) Setting batch_size=8.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0150s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0371s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0514s.) Setting batch_size=8.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0153s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0298s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0533s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0156s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0419s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('ros', RandomOverSampler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0553s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0175s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0324s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0939s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0165s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0328s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0158s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0401s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('ros', RandomOverSampler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0218s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0330s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0166s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0349s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0219s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0473s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0773s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0178s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0542s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0697s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0156s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0418s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0928s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0199s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0449s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0689s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('dummy', DummyClassifier(strategy='stratified'))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.5771649733913885\n",
            "The average f1-macro average is:  0.5869565217391305\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.63      0.65      0.64        78\n",
            "     granted       0.53      0.50      0.51        60\n",
            "\n",
            "    accuracy                           0.59       138\n",
            "   macro avg       0.58      0.58      0.58       138\n",
            "weighted avg       0.58      0.59      0.59       138\n",
            "\n",
            "Fit time:  1.4994332790374756\n",
            "Predict time:  0.002699613571166992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgzHSsCIe5EF"
      },
      "source": [
        "####Gaussian Naive Bayes Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH4pUSk9wWqW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ad3f7fd-1a0c-4206-9310-d13eab411b79"
      },
      "source": [
        "f1_scores_gnb = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels,\n",
        "                              my_transformers=transformers, my_classifiers={'gnb': gnb}, est_values_mapper=est_values_mapper)\n",
        "\n",
        "\n",
        "# compute f1-macro\n",
        "gnb_macro = {k: f1_score(test_labels, v, average='macro') for k,v in f1_scores_gnb['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_est_gnb_macro = max(gnb_macro.items(), key=operator.itemgetter(1))[0]\n",
        "getResults(f1_scores_gnb, opt_est_gnb_macro, final_test, test_labels, \"rejected\", \"granted\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0144s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0061s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0061s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0088s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0091s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0082s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0083s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0120s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0145s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0139s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0129s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0143s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0126s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0115s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0121s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0133s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0147s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0130s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0118s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0118s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0163s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0209s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0157s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0159s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0179s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0159s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('ros', RandomOverSampler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0182s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0161s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0142s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0171s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('ros', RandomOverSampler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0180s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0159s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0196s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0220s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0191s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0192s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.834712543554007\n",
            "The average f1-macro average is:  0.8405797101449275\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.83      0.91      0.87        78\n",
            "     granted       0.87      0.75      0.80        60\n",
            "\n",
            "    accuracy                           0.84       138\n",
            "   macro avg       0.85      0.83      0.83       138\n",
            "weighted avg       0.84      0.84      0.84       138\n",
            "\n",
            "Fit time:  0.024292469024658203\n",
            "Predict time:  0.00189208984375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lj6UMINfD9T"
      },
      "source": [
        "####k-Nearest Neighbors  Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLENKO19dyO0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95b033a6-2b9f-4dc6-c02f-e4156d4faa26"
      },
      "source": [
        "est_values_mapper_opt_knn = {\n",
        "    'selector': [0, 1000, 10000, 1000000],\n",
        "    'pca': [10, 20, 30, 40, 50, 60],\n",
        "    'kNN': {\n",
        "        \"kNN\":[i for i in range(1, 51, 2)]\n",
        "    }\n",
        "}\n",
        "\n",
        "f1_scores_knn = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels,\n",
        "                              my_transformers=transformers, my_classifiers={'kNN': knn}, \n",
        "                              est_values_mapper=est_values_mapper_opt_knn)\n",
        "\n",
        "# compute f1-macro\n",
        "knn_macro = {k: f1_score(test_labels, v, average='macro') for k,v in f1_scores_knn['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_est_knn_macro = max(knn_macro.items(), key=operator.itemgetter(1))[0]\n",
        "getResults(f1_scores_knn, opt_est_knn_macro, final_test, test_labels, \"rejected\", \"granted\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1254s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1249s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1323s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1276s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1371s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1283s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1503s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1317s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1202s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1312s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1332s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1283s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1355s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1340s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1307s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1343s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1280s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1311s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1296s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1373s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1341s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1362s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1365s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1360s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1295s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1381s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1342s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1340s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1431s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1341s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1361s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1338s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.4s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.6s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.6s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.3s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.9s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.4s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1408s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1391s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1392s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1, n_neighbors=33))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.8512931034482759\n",
            "The average f1-macro average is:  0.855072463768116\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.85      0.90      0.88        78\n",
            "     granted       0.86      0.80      0.83        60\n",
            "\n",
            "    accuracy                           0.86       138\n",
            "   macro avg       0.86      0.85      0.85       138\n",
            "weighted avg       0.86      0.86      0.85       138\n",
            "\n",
            "Fit time:  3.137834072113037\n",
            "Predict time:  0.10871028900146484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiM5ViNO4pTp"
      },
      "source": [
        "ΧΡΟΝΟΙ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHkGm1Pk4qto"
      },
      "source": [
        "def printRunTimes(dummy_scores, gnb_scores, knn_scores, dummy_opt, gnb_opt, knn_opt):\n",
        "\n",
        "    values = [[dummy_scores['fit_time'][dummy_opt], gnb_scores['fit_time'][gnb_opt], knn_scores['fit_time'][knn_opt]],\n",
        "              [dummy_scores['predict_time'][dummy_opt], gnb_scores['predict_time'][gnb_opt], knn_scores['predict_time'][knn_opt]]]\n",
        "\n",
        "    tmp = [sum(i) for i in np.array(values).T]\n",
        "\n",
        "    values.append(tmp)\n",
        "\n",
        "    cols = ['Dummy', 'GNB', 'KNN']\n",
        "    df = pd.DataFrame(values, columns=cols, index=['Fit Time', 'Predict Time', 'Total Time'])\n",
        "    print(df)\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYr3gGzIDYva",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31046df-92af-4900-99ff-d152635767d2"
      },
      "source": [
        "printRunTimes(f1_scores, f1_scores_gnb, f1_scores_knn, opt_est_dummy_macro, opt_est_gnb_macro, opt_est_knn_macro)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Dummy       GNB       KNN\n",
            "Fit Time      1.499433  0.024292  3.137834\n",
            "Predict Time  0.002700  0.001892  0.108710\n",
            "Total Time    1.502133  0.026185  3.246544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7EyPyd8308"
      },
      "source": [
        "barplot for every classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K37aXy9j87oF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "38e1ec47-20cf-4525-c3e5-53a28ad31770"
      },
      "source": [
        "# plot for f1-macro average\n",
        "def plotMetrics(dummy_metric, gnb_metric, knn_metric, dummy_opt, gnb_opt, knn_opt, metric):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_axes([0,0,1,1])\n",
        "    clfs = ['dummy', 'gnb', 'knn']\n",
        "    f1_metric_scores = [\n",
        "                    dummy_metric[dummy_opt],\n",
        "                    gnb_metric[gnb_opt],\n",
        "                    knn_metric[knn_opt]\n",
        "    ]\n",
        "    \n",
        "    ax.bar(clfs,f1_metric_scores, color='cyan', width=0.3)\n",
        "    plt.title(\"F1 \"+metric+\" Average\")\n",
        "    plt.xlabel(\"Classifiers\")\n",
        "    plt.ylabel(\"F1 \"+metric+\" Score\")\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plotMetrics(dummy_macro, gnb_macro, knn_macro, opt_est_dummy_macro, opt_est_gnb_macro, opt_est_knn_macro, \"Macro\")"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeQeQiHsHgjr"
      },
      "source": [
        "μεταβολή της επίδοσης των ταξινομητών πριν και μετά τη βελτιστοποίησή τους.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24tFozITHjB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f643d44f-edf6-4413-ee03-37658badef3c"
      },
      "source": [
        "def printPerformanceProgress(default_scores, dummy_metric, gnb_metric, knn_metric, dummy_opt, gnb_opt, knn_opt):\n",
        "\n",
        "    values = [\n",
        "              default_scores,\n",
        "              [dummy_metric[dummy_opt],gnb_metric[gnb_opt],knn_metric[knn_opt]]\n",
        "              ]\n",
        "\n",
        "\n",
        "    cols = ['Dummy', 'GNB', 'KNN']\n",
        "    df = pd.DataFrame(values, columns=cols, index=['Default', 'Optimized'])\n",
        "    print(df)\n",
        "\n",
        "\n",
        "printPerformanceProgress(f1_macro_scores, dummy_macro, gnb_macro, knn_macro, opt_est_dummy_macro, opt_est_gnb_macro, opt_est_knn_macro)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Dummy       GNB       KNN\n",
            "Default    0.490076  0.826699  0.687109\n",
            "Optimized  0.577165  0.834713  0.851293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_43IYCIWDc2T"
      },
      "source": [
        "###Σχολιασμός αποτελεσμάτων\n",
        "\n",
        "Μελετώντας τα αποτελέσματα από την βελτιστοποίηση των ταξινομητών καταλήγουμε για τους τρεις ταξινομητές:\n",
        "\n",
        "* Για τον **Dummy**: Ο καλύτερος συνδυασμός μετασχηματιστών φάνηκε ο VarianceThreshold(threshold=10000), ενώ η στρατηγική του DummyClassifier η *uniform*. Χρησιμοποιώντας τον μετασχηματιστή VarianceThreshold με κατώφλι 10000 επιλέγονται τα χαρακτηριστικά με διακύμανση μεγαλύτερη από 10000. Έτσι, λαμβάνονται υπόψιν μόνο 2 χαρακτηριστικά: **ZipCode** και **Income**, παρόλο που ο dummy δεν λαμβάνει πραγματικά υπόψιν κανένα χαρακτηριστικό. Χρησιμοποιώντας ως στατηγική του dummy classifier την *uniform* ταξινομεί τα δείγματα με ομοιόμορφη κατανομή. Αυτό μεταφράζεται ως 50% - 50%, το οποίο στην πράξη είχε ως αποτέλεσμα την πρόβλεψη 73 δειγμάτων ως rejected και 65 ως granted. METRICS\n",
        "\n",
        "\n",
        "* Για τον **Gaussian Naive Bayes**: Δεν παρατηρήθηκε βελτίωση, μέσω της διαδικασίας βελτιστοποίησης, αφού η χρήση κάποιου μετασχηματιστή δεν οδήγησε σε βελτίωση της μετρικής, ενώ o GaussianNB() δεν δέχεται κάποιες υπερπαραμέτρους.\n",
        "\n",
        "* Για τον **k-Nearest Neighbors**: Παρατηρήθηκε η μεγαλύτερη βελτίωση της μετρικής."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHC8hOq7_FfM"
      },
      "source": [
        "###Μετρική απόδοσης **f1-micro**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRk4IlHDfOyy"
      },
      "source": [
        "####Dummy Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0DYeRc-_a-K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dada8534-bea8-4a45-8ceb-aa8f2aa2a14c"
      },
      "source": [
        "f1_scores_micro = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels,\n",
        "                                my_transformers=transformers, my_classifiers={'dummy': dummy}, \n",
        "                                est_values_mapper=est_values_mapper, scoring='f1_micro')\n",
        "\n",
        "\n",
        "# compute f1-micro\n",
        "dummy_micro = {k: f1_score(test_labels, v, average='micro') for k,v in f1_scores_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-micro\n",
        "opt_est_dummy_micro = max(dummy_micro.items(), key=operator.itemgetter(1))[0]\n",
        "getResults(f1_scores_micro, opt_est_dummy_micro, final_test, test_labels, \"rejected\", \"granted\")"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0108s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0171s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0090s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0155s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0081s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0120s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0082s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0162s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0100s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0188s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0086s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0130s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0115s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0191s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0121s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0298s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp', steps=[('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0562s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0139s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0292s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0431s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0147s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0305s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0540s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0115s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0281s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0555s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0124s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0392s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0629s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0131s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0253s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0160s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0259s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0145s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0238s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0146s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0212s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0128s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0349s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0124s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0330s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0137s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0326s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0124s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0246s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0152s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0152s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0570s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0969s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0152s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0451s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0583s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0158s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0396s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0547s.) Setting batch_size=8.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0163s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0379s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0800s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0175s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0424s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0722s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0176s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0432s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0637s.) Setting batch_size=8.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0158s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0396s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('ros', RandomOverSampler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0592s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0180s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0458s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0872s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0179s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0370s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('ros', RandomOverSampler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0209s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0384s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0196s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0547s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0190s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0399s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0195s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0436s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0925s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0345s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0443s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0798s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0186s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0619s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0808s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'dummy__strategy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('dummy', DummyClassifier())])\n",
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0401s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0572s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0743s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    0.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('dummy', DummyClassifier(strategy='most_frequent'))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.3611111111111111\n",
            "The average f1-macro average is:  0.5652173913043478\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.57      1.00      0.72        78\n",
            "     granted       0.00      0.00      0.00        60\n",
            "\n",
            "    accuracy                           0.57       138\n",
            "   macro avg       0.28      0.50      0.36       138\n",
            "weighted avg       0.32      0.57      0.41       138\n",
            "\n",
            "Fit time:  0.05288124084472656\n",
            "Predict time:  0.0020508766174316406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZWcG-JFfW6i"
      },
      "source": [
        "####Gaussian Naive Bayes Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqT7gvNTAoPa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d12b2209-7d81-4db7-a3a9-eabc905576b8"
      },
      "source": [
        "f1_scores_gnb_micro = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels,\n",
        "                                    my_transformers=transformers, my_classifiers={'gnb': gnb}, \n",
        "                                    est_values_mapper=est_values_mapper, scoring='f1_micro')\n",
        "\n",
        "\n",
        "# compute f1-micro\n",
        "gnb_micro = {k: f1_score(test_labels, v, average='micro') for k,v in f1_scores_gnb_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-micro\n",
        "opt_est_gnb_micro = max(gnb_micro.items(), key=operator.itemgetter(1))[0]\n",
        "getResults(f1_scores_gnb_micro, opt_est_gnb_micro, final_test, test_labels, \"rejected\", \"granted\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp', steps=[('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0129s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0101s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0089s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0106s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0099s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0090s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0104s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0196s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0130s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0155s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0211s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0130s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0140s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0181s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0164s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0127s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0154s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0130s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0149s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0126s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0310s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0144s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0177s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0159s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0178s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('ros', RandomOverSampler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0194s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0216s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0154s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0172s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0167s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('ros', RandomOverSampler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0250s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0169s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0185s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0215s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0207s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0203s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    0.1s remaining:    0.1s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n",
            "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()), ('gnb', GaussianNB())])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.834712543554007\n",
            "The average f1-macro average is:  0.8405797101449275\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.83      0.91      0.87        78\n",
            "     granted       0.87      0.75      0.80        60\n",
            "\n",
            "    accuracy                           0.84       138\n",
            "   macro avg       0.85      0.83      0.83       138\n",
            "weighted avg       0.84      0.84      0.84       138\n",
            "\n",
            "Fit time:  0.03037261962890625\n",
            "Predict time:  0.003457784652709961\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf4VsNHQfbfz"
      },
      "source": [
        "####k-Nearest Neighbors  Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3AI3X2zByce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "530c0723-37f5-4218-b245-690b443256f1"
      },
      "source": [
        "est_values_mapper_opt_knn = {\n",
        "    'selector': [0, 1000, 10000, 1000000],\n",
        "    'pca': [10, 20, 30, 40, 50, 60],\n",
        "    'kNN': {\n",
        "        \"kNN\":[i for i in range(1, 51, 2)]\n",
        "    }\n",
        "}\n",
        "\n",
        "f1_scores_knn_micro = runEstimators(train=final_train, test=final_test, train_labels=train_labels, test_labels=test_labels, \n",
        "                                    my_transformers=transformers, my_classifiers={'kNN': knn}, \n",
        "                                    est_values_mapper=est_values_mapper_opt_knn, scoring='f1_micro')\n",
        "\n",
        "# compute f1-micro\n",
        "knn_micro = {k: f1_score(test_labels, v, average='micro') for k,v in f1_scores_knn_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-micro\n",
        "opt_est_knn_micro = max(knn_micro.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(f1_scores_knn_micro, opt_est_knn_micro, final_test, test_labels, \"rejected\", \"granted\")"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1295s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1244s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1255s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1196s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1315s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp', steps=[('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1313s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1581s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1202s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1317s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1247s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.6s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.8s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.4s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.8s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1317s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1316s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1340s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1349s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1352s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1331s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1338s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1259s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1295s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1377s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1307s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.5s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.0s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   11.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1357s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.7s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    7.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1406s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.3s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1357s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.2s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1311s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1379s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1452s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.3s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.1s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1306s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1295s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1354s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1322s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1330s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()), ('scaler', StandardScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1394s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.5s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.5s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('ros', RandomOverSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1383s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.1s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.8s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.3s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "{'selector__threshold': [0, 1000, 10000, 1000000], 'kNN__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]}\n",
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold()),\n",
            "                ('min_max_scaler', MinMaxScaler()),\n",
            "                ('rus', RandomUnderSampler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1))])\n",
            "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1367s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.4s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    5.4s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    6.8s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
            "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CREATE PIPELINE\n",
            "<class 'numpy.float64'>\n",
            "<class 'numpy.ndarray'>\n",
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('kNN', KNeighborsClassifier(n_jobs=-1, n_neighbors=29))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.8639649507119387\n",
            "The average f1-macro average is:  0.8695652173913043\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.84      0.95      0.89        78\n",
            "     granted       0.92      0.77      0.84        60\n",
            "\n",
            "    accuracy                           0.87       138\n",
            "   macro avg       0.88      0.86      0.86       138\n",
            "weighted avg       0.88      0.87      0.87       138\n",
            "\n",
            "Fit time:  3.008362054824829\n",
            "Predict time:  0.10908198356628418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hq1vmKQ0EqfJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b78b07-d1b9-4c97-e5a0-07c264f2b0ca"
      },
      "source": [
        "printRunTimes(f1_scores_micro, f1_scores_gnb_micro, f1_scores_knn_micro, \n",
        "              opt_est_dummy_micro, opt_est_gnb_micro, opt_est_knn_micro)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 Dummy       GNB       KNN\n",
            "Fit Time      0.052881  0.030373  3.008362\n",
            "Predict Time  0.002051  0.003458  0.109082\n",
            "Total Time    0.054932  0.033830  3.117444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V95MaB9GP7J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "8090f196-8e7e-4eb0-fb33-dddcb025d788"
      },
      "source": [
        "plotMetrics(dummy_micro, gnb_micro, knn_micro,\n",
        "            opt_est_dummy_micro, opt_est_gnb_micro, opt_est_knn_micro, \"micro\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knXJgKi3LgSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7135b349-75ae-49e1-9d66-c6bb73044483"
      },
      "source": [
        "printPerformanceProgress(f1_micro_scores, dummy_micro, gnb_micro, knn_micro,\n",
        "                         opt_est_dummy_micro, opt_est_gnb_micro, opt_est_knn_micro)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Dummy       GNB       KNN\n",
            "Default    0.492754  0.833333  0.702899\n",
            "Optimized  0.565217  0.840580  0.869565\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72m04xpxEDJW"
      },
      "source": [
        "###Σχολιασμός αποτελεσμάτων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E93Uww5vMf_9"
      },
      "source": [
        "#Μεγάλο Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_UcSR06YtXm"
      },
      "source": [
        "Αρχικά κατεβάζουμε το συμπιεσμένο αρχείο, το αποθηκεύουμε ως data.zip και στη συνέχεια το αποσυμπιέζουμε, οπότε παράγονται 5 αρχείο τύπου .arff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UTSjkZzGS01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "936ea3a1-ee99-47c4-bf24-ad68645ba384"
      },
      "source": [
        "download(\"http://archive.ics.uci.edu/ml/machine-learning-databases/00365/data.zip\", 'data.zip')\n",
        "!unzip data.zip"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace 1year.arff? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: 1year.arff              \n",
            "  inflating: 2year.arff              \n",
            "  inflating: 3year.arff              \n",
            "  inflating: 4year.arff              \n",
            "  inflating: 5year.arff              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VT06Xa8Y7c1"
      },
      "source": [
        "Για να μετατρέψουμε τα αρχεία σε .csv, αρκεί να κρατήσουμε μόνο τις γραμμές που δεν ξεκινάνε με “%”, “@” και δεν είναι κενές.\n",
        "Επομένως, για καθένα από τα .arff αρχεία εκτελούμε την εντολή:\n",
        "```\n",
        "cat ${file} | grep -ve \"^@\\|^%\" | grep -v \"^[[:space:]]*$\" >> data.csv\n",
        "```\n",
        "Η εντολή αυτή θα τυπώσει μόνο τις επιθυμητές γραμμές και θα ανακατευθύνει το αποτέλεσμα στο αρχείο data.csv, προσθέτοντάς το στο τέλος του.\n",
        "\n",
        "Για να πραγματοποιήσουμε αυτήν τη διαδικασία για όλα τα .arff εκτελούμε τα παρακάτω:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL6_s3nxQjZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96af67de-c390-4751-d48a-070889920fb0"
      },
      "source": [
        "%%shell\n",
        "truncate -s 0 data.csv  #create or empty the data.csv file\n",
        "for file in ./*.arff    #for every .arff file in the current directory\n",
        "do\n",
        "    echo ${file}        #print file name for checking the progress purposes\n",
        "    cat ${file} | grep -ve \"^@\\|^%\" | grep -v \"^[[:space:]]*$\" >> data.csv  #print the lines with the samples in the end of data.csv file\n",
        "done\n",
        "wc -l data.csv          #check the length of the final file"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./1year.arff\n",
            "./2year.arff\n",
            "./3year.arff\n",
            "./4year.arff\n",
            "./5year.arff\n",
            "43405 data.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7GN32b9XOkW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "outputId": "4469c79b-0787-4fef-89ff-c0f8699b52bf"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "big_df = pd.read_csv(\"data.csv\", header=None)\n",
        "# print df\n",
        "big_df"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1,2,5,6,8,9,10,12,13,17,18,19,21,22,24,28,29,30,34,35,37,38,41,42,43,47,48,50,54,55,56,57,58,61) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.20055</td>\n",
              "      <td>0.37951</td>\n",
              "      <td>0.39641</td>\n",
              "      <td>2.0472</td>\n",
              "      <td>32.351</td>\n",
              "      <td>0.38825</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>1.3305</td>\n",
              "      <td>1.1389</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>0.6598</td>\n",
              "      <td>0.1666</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>497.42</td>\n",
              "      <td>0.73378</td>\n",
              "      <td>2.6349</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>0.14942</td>\n",
              "      <td>43.37</td>\n",
              "      <td>1.2479</td>\n",
              "      <td>0.21402</td>\n",
              "      <td>0.11998</td>\n",
              "      <td>0.47706</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.60411</td>\n",
              "      <td>1.4582</td>\n",
              "      <td>1.7615</td>\n",
              "      <td>5.9443</td>\n",
              "      <td>0.11788</td>\n",
              "      <td>0.14942</td>\n",
              "      <td>94.14</td>\n",
              "      <td>3.8772</td>\n",
              "      <td>0.56393</td>\n",
              "      <td>0.21402</td>\n",
              "      <td>1.741</td>\n",
              "      <td>593.27</td>\n",
              "      <td>0.50591</td>\n",
              "      <td>0.12804</td>\n",
              "      <td>0.66295</td>\n",
              "      <td>0.051402</td>\n",
              "      <td>0.12804</td>\n",
              "      <td>114.42</td>\n",
              "      <td>71.05</td>\n",
              "      <td>1.0097</td>\n",
              "      <td>1.5225</td>\n",
              "      <td>49.394</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>0.11085</td>\n",
              "      <td>2.042</td>\n",
              "      <td>0.37854</td>\n",
              "      <td>0.25792</td>\n",
              "      <td>2.2437</td>\n",
              "      <td>2.248</td>\n",
              "      <td>348690</td>\n",
              "      <td>0.12196</td>\n",
              "      <td>0.39718</td>\n",
              "      <td>0.87804</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>8.416</td>\n",
              "      <td>5.1372</td>\n",
              "      <td>82.658</td>\n",
              "      <td>4.4158</td>\n",
              "      <td>7.4277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.20912</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.47225</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>14.786</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25834</td>\n",
              "      <td>0.99601</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>0.26114</td>\n",
              "      <td>0.5168</td>\n",
              "      <td>0.15835</td>\n",
              "      <td>0.25834</td>\n",
              "      <td>677.96</td>\n",
              "      <td>0.53838</td>\n",
              "      <td>2.0005</td>\n",
              "      <td>0.25834</td>\n",
              "      <td>0.152</td>\n",
              "      <td>87.981</td>\n",
              "      <td>1.4293</td>\n",
              "      <td>0.24806</td>\n",
              "      <td>0.12304</td>\n",
              "      <td>?</td>\n",
              "      <td>0.39542</td>\n",
              "      <td>0.43992</td>\n",
              "      <td>88.444</td>\n",
              "      <td>16.946</td>\n",
              "      <td>3.6884</td>\n",
              "      <td>0.26969</td>\n",
              "      <td>0.152</td>\n",
              "      <td>122.17</td>\n",
              "      <td>2.9876</td>\n",
              "      <td>2.9876</td>\n",
              "      <td>0.20616</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>?</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>0.1213</td>\n",
              "      <td>0.086422</td>\n",
              "      <td>0.064371</td>\n",
              "      <td>0.14595</td>\n",
              "      <td>199.49</td>\n",
              "      <td>111.51</td>\n",
              "      <td>0.51045</td>\n",
              "      <td>1.1252</td>\n",
              "      <td>100.13</td>\n",
              "      <td>0.23727</td>\n",
              "      <td>0.13961</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.33472</td>\n",
              "      <td>17.866</td>\n",
              "      <td>17.866</td>\n",
              "      <td>2304.6</td>\n",
              "      <td>0.1213</td>\n",
              "      <td>0.42002</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0</td>\n",
              "      <td>4.1486</td>\n",
              "      <td>3.2732</td>\n",
              "      <td>107.35</td>\n",
              "      <td>3.4</td>\n",
              "      <td>60.987</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.24866</td>\n",
              "      <td>0.69592</td>\n",
              "      <td>0.26713</td>\n",
              "      <td>1.5548</td>\n",
              "      <td>-1.1523</td>\n",
              "      <td>0</td>\n",
              "      <td>0.30906</td>\n",
              "      <td>0.43695</td>\n",
              "      <td>1.309</td>\n",
              "      <td>0.30408</td>\n",
              "      <td>0.31258</td>\n",
              "      <td>0.64184</td>\n",
              "      <td>0.24435</td>\n",
              "      <td>0.30906</td>\n",
              "      <td>794.16</td>\n",
              "      <td>0.45961</td>\n",
              "      <td>1.4369</td>\n",
              "      <td>0.30906</td>\n",
              "      <td>0.2361</td>\n",
              "      <td>73.133</td>\n",
              "      <td>1.4283</td>\n",
              "      <td>0.3026</td>\n",
              "      <td>0.18996</td>\n",
              "      <td>?</td>\n",
              "      <td>0.28932</td>\n",
              "      <td>0.37282</td>\n",
              "      <td>86.011</td>\n",
              "      <td>1.0627</td>\n",
              "      <td>4.3749</td>\n",
              "      <td>0.41929</td>\n",
              "      <td>0.23815</td>\n",
              "      <td>176.93</td>\n",
              "      <td>2.063</td>\n",
              "      <td>1.4274</td>\n",
              "      <td>0.31565</td>\n",
              "      <td>1.309</td>\n",
              "      <td>2.3019</td>\n",
              "      <td>0.51537</td>\n",
              "      <td>0.24114</td>\n",
              "      <td>0.32202</td>\n",
              "      <td>0.07402</td>\n",
              "      <td>0.23117</td>\n",
              "      <td>165.51</td>\n",
              "      <td>92.381</td>\n",
              "      <td>0.94807</td>\n",
              "      <td>1.0101</td>\n",
              "      <td>96.372</td>\n",
              "      <td>0.29181</td>\n",
              "      <td>0.22293</td>\n",
              "      <td>1.0758</td>\n",
              "      <td>0.48152</td>\n",
              "      <td>0.48474</td>\n",
              "      <td>1.2098</td>\n",
              "      <td>2.0504</td>\n",
              "      <td>6332.7</td>\n",
              "      <td>0.24114</td>\n",
              "      <td>0.81774</td>\n",
              "      <td>0.76599</td>\n",
              "      <td>0.69484</td>\n",
              "      <td>4.9909</td>\n",
              "      <td>3.951</td>\n",
              "      <td>134.27</td>\n",
              "      <td>2.7185</td>\n",
              "      <td>5.2078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.081483</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.45879</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>51.952</td>\n",
              "      <td>0.14988</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>1.8661</td>\n",
              "      <td>1.0571</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>0.30163</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>917.01</td>\n",
              "      <td>0.39803</td>\n",
              "      <td>3.2537</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>0.071428</td>\n",
              "      <td>79.788</td>\n",
              "      <td>1.5069</td>\n",
              "      <td>0.1155</td>\n",
              "      <td>0.062782</td>\n",
              "      <td>0.17193</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.36152</td>\n",
              "      <td>0.94076</td>\n",
              "      <td>1.9618</td>\n",
              "      <td>4.6511</td>\n",
              "      <td>0.14343</td>\n",
              "      <td>0.071428</td>\n",
              "      <td>91.37</td>\n",
              "      <td>3.9948</td>\n",
              "      <td>0.37581</td>\n",
              "      <td>0.1155</td>\n",
              "      <td>1.3562</td>\n",
              "      <td>?</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.088995</td>\n",
              "      <td>0.40139</td>\n",
              "      <td>0.069622</td>\n",
              "      <td>0.088995</td>\n",
              "      <td>180.77</td>\n",
              "      <td>100.98</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>1.5696</td>\n",
              "      <td>84.344</td>\n",
              "      <td>0.085874</td>\n",
              "      <td>0.066165</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.25033</td>\n",
              "      <td>2.4524</td>\n",
              "      <td>2.4524</td>\n",
              "      <td>20545</td>\n",
              "      <td>0.054015</td>\n",
              "      <td>0.14207</td>\n",
              "      <td>0.94598</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5746</td>\n",
              "      <td>3.6147</td>\n",
              "      <td>86.435</td>\n",
              "      <td>4.2228</td>\n",
              "      <td>5.5497</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.61323</td>\n",
              "      <td>0.2296</td>\n",
              "      <td>1.4063</td>\n",
              "      <td>-7.3128</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.6307</td>\n",
              "      <td>1.1559</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.33147</td>\n",
              "      <td>0.12182</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>1133.2</td>\n",
              "      <td>0.32211</td>\n",
              "      <td>1.6307</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.11553</td>\n",
              "      <td>57.045</td>\n",
              "      <td>?</td>\n",
              "      <td>0.19832</td>\n",
              "      <td>0.11553</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>0.32211</td>\n",
              "      <td>1.4138</td>\n",
              "      <td>1.1184</td>\n",
              "      <td>4.1424</td>\n",
              "      <td>0.27884</td>\n",
              "      <td>0.11553</td>\n",
              "      <td>147.04</td>\n",
              "      <td>2.4823</td>\n",
              "      <td>0.3234</td>\n",
              "      <td>0.19832</td>\n",
              "      <td>1.6278</td>\n",
              "      <td>11.247</td>\n",
              "      <td>0.43489</td>\n",
              "      <td>0.12231</td>\n",
              "      <td>0.29304</td>\n",
              "      <td>0.09668</td>\n",
              "      <td>0.12231</td>\n",
              "      <td>141.62</td>\n",
              "      <td>84.574</td>\n",
              "      <td>0.73919</td>\n",
              "      <td>0.95787</td>\n",
              "      <td>65.936</td>\n",
              "      <td>0.18811</td>\n",
              "      <td>0.11601</td>\n",
              "      <td>1.2959</td>\n",
              "      <td>0.56511</td>\n",
              "      <td>0.40285</td>\n",
              "      <td>1.8839</td>\n",
              "      <td>2.1184</td>\n",
              "      <td>3186.6</td>\n",
              "      <td>0.13485</td>\n",
              "      <td>0.48431</td>\n",
              "      <td>0.86515</td>\n",
              "      <td>0.12444</td>\n",
              "      <td>6.3985</td>\n",
              "      <td>4.3158</td>\n",
              "      <td>127.21</td>\n",
              "      <td>2.8692</td>\n",
              "      <td>7.898</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43400</th>\n",
              "      <td>0.012898</td>\n",
              "      <td>0.70621</td>\n",
              "      <td>0.038857</td>\n",
              "      <td>1.1722</td>\n",
              "      <td>-18.907</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>0.416</td>\n",
              "      <td>1.6768</td>\n",
              "      <td>0.29379</td>\n",
              "      <td>0.041583</td>\n",
              "      <td>0.061959</td>\n",
              "      <td>0.023622</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>6507.6</td>\n",
              "      <td>0.056089</td>\n",
              "      <td>1.416</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>0.008338</td>\n",
              "      <td>27.092</td>\n",
              "      <td>1.033</td>\n",
              "      <td>0.040401</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.90184</td>\n",
              "      <td>0.083706</td>\n",
              "      <td>0.054556</td>\n",
              "      <td>1.4637</td>\n",
              "      <td>0.052831</td>\n",
              "      <td>4.9667</td>\n",
              "      <td>0.41853</td>\n",
              "      <td>0.024762</td>\n",
              "      <td>50.128</td>\n",
              "      <td>7.4</td>\n",
              "      <td>2.3644</td>\n",
              "      <td>0.033819</td>\n",
              "      <td>1.6768</td>\n",
              "      <td>0.3785</td>\n",
              "      <td>0.66377</td>\n",
              "      <td>0.020169</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>0.35651</td>\n",
              "      <td>0.024093</td>\n",
              "      <td>56.452</td>\n",
              "      <td>29.36</td>\n",
              "      <td>0.10363</td>\n",
              "      <td>0.62061</td>\n",
              "      <td>27.207</td>\n",
              "      <td>0.014771</td>\n",
              "      <td>0.008809</td>\n",
              "      <td>0.37454</td>\n",
              "      <td>0.22564</td>\n",
              "      <td>0.13514</td>\n",
              "      <td>0.39944</td>\n",
              "      <td>0.90248</td>\n",
              "      <td>3599.1</td>\n",
              "      <td>0.020169</td>\n",
              "      <td>0.043904</td>\n",
              "      <td>1.0122</td>\n",
              "      <td>1.2594</td>\n",
              "      <td>13.472</td>\n",
              "      <td>12.432</td>\n",
              "      <td>49.117</td>\n",
              "      <td>7.4313</td>\n",
              "      <td>2.2799</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43401</th>\n",
              "      <td>-0.57805</td>\n",
              "      <td>0.96702</td>\n",
              "      <td>-0.80085</td>\n",
              "      <td>0.16576</td>\n",
              "      <td>-67.365</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.40334</td>\n",
              "      <td>0.93979</td>\n",
              "      <td>-0.39004</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.60216</td>\n",
              "      <td>-0.11022</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-742.28</td>\n",
              "      <td>-0.49173</td>\n",
              "      <td>1.0341</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.13399</td>\n",
              "      <td>3.2965</td>\n",
              "      <td>0.6477</td>\n",
              "      <td>-0.53492</td>\n",
              "      <td>-0.13399</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.39004</td>\n",
              "      <td>-0.49173</td>\n",
              "      <td>?</td>\n",
              "      <td>-0.9524</td>\n",
              "      <td>4.0622</td>\n",
              "      <td>0.21864</td>\n",
              "      <td>-0.13399</td>\n",
              "      <td>76.33</td>\n",
              "      <td>4.7819</td>\n",
              "      <td>-0.55316</td>\n",
              "      <td>-0.53492</td>\n",
              "      <td>4.3912</td>\n",
              "      <td>17.036</td>\n",
              "      <td>-0.38299</td>\n",
              "      <td>-0.12399</td>\n",
              "      <td>0.024771</td>\n",
              "      <td>-0.073529</td>\n",
              "      <td>-0.12399</td>\n",
              "      <td>11.451</td>\n",
              "      <td>8.1548</td>\n",
              "      <td>-14.836</td>\n",
              "      <td>0.12517</td>\n",
              "      <td>3.098</td>\n",
              "      <td>-0.63746</td>\n",
              "      <td>-0.14776</td>\n",
              "      <td>0.16455</td>\n",
              "      <td>0.95997</td>\n",
              "      <td>0.20912</td>\n",
              "      <td>-0.46385</td>\n",
              "      <td>-0.45546</td>\n",
              "      <td>-9242.1</td>\n",
              "      <td>-0.064073</td>\n",
              "      <td>1.482</td>\n",
              "      <td>1.0641</td>\n",
              "      <td>-0.018084</td>\n",
              "      <td>110.72</td>\n",
              "      <td>44.759</td>\n",
              "      <td>81.22</td>\n",
              "      <td>4.494</td>\n",
              "      <td>5.1305</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43402</th>\n",
              "      <td>-0.17905</td>\n",
              "      <td>1.2553</td>\n",
              "      <td>-0.27599</td>\n",
              "      <td>0.74554</td>\n",
              "      <td>-120.44</td>\n",
              "      <td>-0.17905</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.26018</td>\n",
              "      <td>1.1749</td>\n",
              "      <td>-0.32659</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.14284</td>\n",
              "      <td>-0.07294</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-3298.2</td>\n",
              "      <td>-0.11067</td>\n",
              "      <td>0.79665</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.08135</td>\n",
              "      <td>37.046</td>\n",
              "      <td>0.83104</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>-0.094015</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.32659</td>\n",
              "      <td>-0.12988</td>\n",
              "      <td>?</td>\n",
              "      <td>-1.4423</td>\n",
              "      <td>5.3244</td>\n",
              "      <td>0.65813</td>\n",
              "      <td>-0.08135</td>\n",
              "      <td>244.23</td>\n",
              "      <td>1.4945</td>\n",
              "      <td>0.14077</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.9515</td>\n",
              "      <td>3.6065</td>\n",
              "      <td>-0.15597</td>\n",
              "      <td>0.09278</td>\n",
              "      <td>0.064095</td>\n",
              "      <td>0.21414</td>\n",
              "      <td>0.09278</td>\n",
              "      <td>141.65</td>\n",
              "      <td>104.61</td>\n",
              "      <td>-0.9263</td>\n",
              "      <td>0.56733</td>\n",
              "      <td>43.526</td>\n",
              "      <td>0.16068</td>\n",
              "      <td>0.08437</td>\n",
              "      <td>0.64421</td>\n",
              "      <td>1.0846</td>\n",
              "      <td>0.66913</td>\n",
              "      <td>-1.7067</td>\n",
              "      <td>-0.81508</td>\n",
              "      <td>-58253</td>\n",
              "      <td>0.14888</td>\n",
              "      <td>0.54824</td>\n",
              "      <td>0.85112</td>\n",
              "      <td>-0.52243</td>\n",
              "      <td>9.8526</td>\n",
              "      <td>3.4892</td>\n",
              "      <td>207.87</td>\n",
              "      <td>1.7559</td>\n",
              "      <td>9.9527</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43403</th>\n",
              "      <td>-0.10886</td>\n",
              "      <td>0.74394</td>\n",
              "      <td>0.015449</td>\n",
              "      <td>1.0878</td>\n",
              "      <td>-17.003</td>\n",
              "      <td>-0.10886</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>0.12531</td>\n",
              "      <td>0.84516</td>\n",
              "      <td>0.093224</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>-0.62038</td>\n",
              "      <td>-0.065652</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>-5352.1</td>\n",
              "      <td>-0.068197</td>\n",
              "      <td>1.3442</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>-0.14128</td>\n",
              "      <td>26.285</td>\n",
              "      <td>1.121</td>\n",
              "      <td>-0.09995</td>\n",
              "      <td>-0.14086</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>0.093224</td>\n",
              "      <td>-0.067762</td>\n",
              "      <td>?</td>\n",
              "      <td>0.019106</td>\n",
              "      <td>4.8555</td>\n",
              "      <td>0.95181</td>\n",
              "      <td>-0.14128</td>\n",
              "      <td>70.252</td>\n",
              "      <td>5.1956</td>\n",
              "      <td>-0.13435</td>\n",
              "      <td>-0.09995</td>\n",
              "      <td>0.83553</td>\n",
              "      <td>0.23908</td>\n",
              "      <td>0.66118</td>\n",
              "      <td>-0.12934</td>\n",
              "      <td>0.048976</td>\n",
              "      <td>-0.5893</td>\n",
              "      <td>-0.12934</td>\n",
              "      <td>86.348</td>\n",
              "      <td>60.064</td>\n",
              "      <td>-1.9561</td>\n",
              "      <td>0.77157</td>\n",
              "      <td>22.215</td>\n",
              "      <td>-0.1584</td>\n",
              "      <td>-0.20497</td>\n",
              "      <td>0.25733</td>\n",
              "      <td>0.17599</td>\n",
              "      <td>0.19247</td>\n",
              "      <td>0.1153</td>\n",
              "      <td>0.81772</td>\n",
              "      <td>1107.5</td>\n",
              "      <td>-0.1832</td>\n",
              "      <td>-1.1677</td>\n",
              "      <td>1.1832</td>\n",
              "      <td>6.0924</td>\n",
              "      <td>13.886</td>\n",
              "      <td>6.0769</td>\n",
              "      <td>83.122</td>\n",
              "      <td>4.3911</td>\n",
              "      <td>0.95575</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43404</th>\n",
              "      <td>-0.10537</td>\n",
              "      <td>0.53629</td>\n",
              "      <td>-0.045578</td>\n",
              "      <td>0.91478</td>\n",
              "      <td>-56.068</td>\n",
              "      <td>-0.10537</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>0.8646</td>\n",
              "      <td>0.9504</td>\n",
              "      <td>0.46367</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>-0.20557</td>\n",
              "      <td>-0.066747</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>-2055.9</td>\n",
              "      <td>-0.17754</td>\n",
              "      <td>1.8647</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>-0.077072</td>\n",
              "      <td>47.199</td>\n",
              "      <td>0.71351</td>\n",
              "      <td>-0.082947</td>\n",
              "      <td>-0.073868</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>0.46367</td>\n",
              "      <td>-0.16902</td>\n",
              "      <td>?</td>\n",
              "      <td>-0.089234</td>\n",
              "      <td>3.9698</td>\n",
              "      <td>0.37528</td>\n",
              "      <td>-0.077072</td>\n",
              "      <td>130.06</td>\n",
              "      <td>2.8064</td>\n",
              "      <td>-0.15467</td>\n",
              "      <td>-0.082947</td>\n",
              "      <td>1.4481</td>\n",
              "      <td>205.69</td>\n",
              "      <td>0.46515</td>\n",
              "      <td>-0.058149</td>\n",
              "      <td>0.004456</td>\n",
              "      <td>-0.25846</td>\n",
              "      <td>-0.058149</td>\n",
              "      <td>124.57</td>\n",
              "      <td>77.374</td>\n",
              "      <td>-0.57124</td>\n",
              "      <td>0.56987</td>\n",
              "      <td>44.858</td>\n",
              "      <td>-0.097675</td>\n",
              "      <td>-0.068474</td>\n",
              "      <td>0.91225</td>\n",
              "      <td>0.53481</td>\n",
              "      <td>0.35632</td>\n",
              "      <td>0.90779</td>\n",
              "      <td>0.91069</td>\n",
              "      <td>-425.13</td>\n",
              "      <td>-0.052186</td>\n",
              "      <td>-0.22725</td>\n",
              "      <td>1.0522</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>7.7332</td>\n",
              "      <td>4.7174</td>\n",
              "      <td>136.85</td>\n",
              "      <td>2.6672</td>\n",
              "      <td>2.7927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43405 rows × 65 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0        1          2        3   ...      61      62       63 64\n",
              "0       0.20055  0.37951    0.39641   2.0472  ...  82.658  4.4158   7.4277  0\n",
              "1       0.20912  0.49988    0.47225   1.9447  ...  107.35     3.4   60.987  0\n",
              "2       0.24866  0.69592    0.26713   1.5548  ...  134.27  2.7185   5.2078  0\n",
              "3      0.081483  0.30734    0.45879   2.4928  ...  86.435  4.2228   5.5497  0\n",
              "4       0.18732  0.61323     0.2296   1.4063  ...  127.21  2.8692    7.898  0\n",
              "...         ...      ...        ...      ...  ...     ...     ...      ... ..\n",
              "43400  0.012898  0.70621   0.038857   1.1722  ...  49.117  7.4313   2.2799  1\n",
              "43401  -0.57805  0.96702   -0.80085  0.16576  ...   81.22   4.494   5.1305  1\n",
              "43402  -0.17905   1.2553   -0.27599  0.74554  ...  207.87  1.7559   9.9527  1\n",
              "43403  -0.10886  0.74394   0.015449   1.0878  ...  83.122  4.3911  0.95575  1\n",
              "43404  -0.10537  0.53629  -0.045578  0.91478  ...  136.85  2.6672   2.7927  1\n",
              "\n",
              "[43405 rows x 65 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxeKdpKDW9qR"
      },
      "source": [
        "##Βασικές Πληροφορίες"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xUuWwFzYn9S"
      },
      "source": [
        "###Πληροφορίες dataset\n",
        "Το dataset, πρόκειται επομένως για ένα σύνολο **43405 δειγμάτων**, με κάθε δείγμα να έχει **64 χαρακτηριστικά**. Η τελευταία στήλη είναι η κλάση στην οποία ανήκει το δείγμα, δηλαδή δηλώνει αν πτώχευσε (1) ή όχι (0) η συγκεκριμένη εταιρεία.\n",
        "\n",
        "Πιο συγκεκριμένα, το dataset *Polish companies bankruptcy* αποτελεί ένα σύνολο δεδομένων σχετικά με πολωνικές εταιρείες που πτώχευσαν ή όχι παραθέτοντας αρκετά (64) χαρακτηριστικά τους. Τα στοιχεία έχουν συλλεγεί ως 5 διαφορετικά σύνολα που το καθένα αντιστοιχεί σε 5 διαφορετικά έτη. Παρολαυτά στα πλαίσια της παρούσας εργασίας τα 5 σύνολα δεδομένων θα αντιμετωπιστούν ως ένα ενιαίο σύνολο δεδομένων.\n",
        "\n",
        "Παρακάτω παρατίθεται μία σύντομη περιγραφή του καθενός από τα χαρακτηριστικά των δειγμάτων που υπάρχουν στο dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuRmRk3SXd9y"
      },
      "source": [
        "| Attribute | Description                                                                                                         |\n",
        "|-----------|---------------------------------------------------------------------------------------------------------------------|\n",
        "| X1        | net profit / total assets                                                                                           |\n",
        "| X2        | total liabilities / total assets                                                                                    |\n",
        "| X3        | working capital / total assets                                                                                      |\n",
        "| X4        | current assets / short-term liabilities                                                                             |\n",
        "| X5        | [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365 |\n",
        "| X6        | retained earnings / total assets                                                                                    |\n",
        "| X7        | EBIT / total assets                                                                                                 |\n",
        "| X8        | book value of equity / total liabilities                                                                            |\n",
        "| X9        | sales / total assets                                                                                                |\n",
        "| X10       | equity / total assets                                                                                               |\n",
        "| X11       | (gross profit + extraordinary items + financial expenses) / total assets                                            |\n",
        "| X12       | gross profit / short-term liabilities                                                                               |\n",
        "| X13       | (gross profit + depreciation) / sales                                                                               |\n",
        "| X14       | (gross profit + interest) / total assets                                                                            |\n",
        "| X15       | (total liabilities * 365) / (gross profit + depreciation)                                                           |\n",
        "| X16       | (gross profit + depreciation) / total liabilities                                                                   |\n",
        "| X17       | total assets / total liabilities                                                                                    |\n",
        "| X18       | gross profit / total assets                                                                                         |\n",
        "| X19       | gross profit / sales                                                                                                |\n",
        "| X20       | (inventory * 365) / sales                                                                                           |\n",
        "| X21       | sales (n) / sales (n-1)                                                                                             |\n",
        "| X22       | profit on operating activities / total assets                                                                       |\n",
        "| X23       | net profit / sales                                                                                                  |\n",
        "| X24       | gross profit (in 3 years) / total assets                                                                            |\n",
        "| X25       | (equity - share capital) / total assets                                                                             |\n",
        "| X26       | (net profit + depreciation) / total liabilities                                                                     |\n",
        "| X27       | profit on operating activities / financial expenses                                                                 |\n",
        "| X28       | working capital / fixed assets                                                                                      |\n",
        "| X29       | logarithm of total assets                                                                                           |\n",
        "| X30       | (total liabilities - cash) / sales                                                                                  |\n",
        "| X31       | (gross profit + interest) / sales                                                                                   |\n",
        "| X32       | (current liabilities * 365) / cost of products sold                                                                 |\n",
        "| X33       | operating expenses / short-term liabilities                                                                         |\n",
        "| X34       | operating expenses / total liabilities                                                                              |\n",
        "| X35       | profit on sales / total assets                                                                                      |\n",
        "| X36       | total sales / total assets                                                                                          |\n",
        "| X37       | (current assets - inventories) / long-term liabilities                                                              |\n",
        "| X38       | constant capital / total assets                                                                                     |\n",
        "| X39       | profit on sales / sales                                                                                             |\n",
        "| X40       | (current assets - inventory - receivables) / short-term liabilities                                                 |\n",
        "| X41       | total liabilities / ((profit on operating activities + depreciation) * (12/365))                                    |\n",
        "| X42       | profit on operating activities / sales                                                                              |\n",
        "| X43       | rotation receivables + inventory turnover in days                                                                   |\n",
        "| X44       | (receivables * 365) / sales                                                                                         |\n",
        "| X45       | net profit / inventory                                                                                              |\n",
        "| X46       | (current assets - inventory) / short-term liabilities                                                               |\n",
        "| X47       | (inventory * 365) / cost of products sold                                                                           |\n",
        "| X48       | EBITDA (profit on operating activities - depreciation) / total assets                                               |\n",
        "| X49       | EBITDA (profit on operating activities - depreciation) / sales                                                      |\n",
        "| X50       | current assets / total liabilities                                                                                  |\n",
        "| X51       | short-term liabilities / total assets                                                                               |\n",
        "| X52       | (short-term liabilities * 365) / cost of products sold)                                                             |\n",
        "| X53       | equity / fixed assets                                                                                               |\n",
        "| X54       | constant capital / fixed assets                                                                                     |\n",
        "| X55       | working capital                                                                                                     |\n",
        "| X56       | (sales - cost of products sold) / sales                                                                             |\n",
        "| X57       | (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)                       |\n",
        "| X58       | total costs /total sales                                                                                            |\n",
        "| X59       | long-term liabilities / equity                                                                                      |\n",
        "| X60       | sales / inventory                                                                                                   |\n",
        "| X61       | sales / receivables                                                                                                 |\n",
        "| X62       | (short-term liabilities *365) / sales                                                                               |\n",
        "| X63       | sales / short-term liabilities                                                                                      |\n",
        "| X64       | sales / fixed assets                                                                                                |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPGd-9K_F3QC"
      },
      "source": [
        "###Περιγραφή χαρακτηριστικών του dataset\n",
        "\n",
        "Όπως είδαμε και προηγουμένως το σύνολο περιλαμβάνει **43405 δείγματα**, με κάθε δείγμα να έχει **64 χαρακτηριστικά**. **Όλα τα χαρακτηριστικά παίρνουν αριθμητικές, μη διατεταγμένες τιμές**.\n",
        "\n",
        "Επίσης, το dataset **δεν** περιλαμβάνει επικεφαλίδες και αρίθμηση γραμμών.\n",
        "\n",
        "Οι ετικέτες των κλάσεων, χρεωκοπεία ή όχι, **αναπαριστόνται με τιμές 1 και 0 αντίστοιχα και βρίσκονται στην τελευταία στήλη**.\n",
        "\n",
        "Οι μοναδικές αλλαγές των αρχικών αρχείων .arff που χρειάστηκε να γίνουν είναι η μετατροπή τους σε αρχεία .csv, που έγινε με όπως περιγράφηκε παραπάνω. Τέλος, τα δεδομένα από τα 5 συνολικά αρχεία συγκεντρώθηκαν σε ένα μόνο αρχείο, το **data.csv**, όπως περιγράφηκε παραπάνω."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgoZJWICOWVY"
      },
      "source": [
        "###Εντοπισμός απουσιάζουσων τιμών χαρακτηριστικών\n",
        "\n",
        "Στη συνέχεια, θα εντοπίσουμε τις απουσιάζουσες τιμές. Αυτές δηλώνονται στο dataset με τον χαρακτήρα \"?\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93epkQkOaVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585b01fe-b523-428d-b5be-491528f09b38"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from collections import defaultdict\n",
        "\n",
        "# replace \"?\" with np.NaN\n",
        "big_df.replace('?',np.NaN,inplace=True)\n",
        "\n",
        "# calculate the number of samples with at least one missing attribute\n",
        "# big_df.isna() is the mask of big_df where each element is True if is NaN\n",
        "# num_of_incomplete_samples_big is the length of the list of samples that have at least one True(NaN)\n",
        "num_of_incomplete_samples_big = len([i for i in np.array(big_df.isna()) if True in i])\n",
        "\n",
        "print(\"The samples of the dataset that have at least one missing attribute are \", num_of_incomplete_samples_big)\n",
        "print(\"Which means that the \", num_of_incomplete_samples_big*100/big_df.shape[0], \"% of the samples have missing values.\", sep=\"\")"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The samples of the dataset that have at least one missing attribute are  23438\n",
            "Which means that the 53.99838728257113% of the samples have missing values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UxusBvHPVMq"
      },
      "source": [
        "Σύμφωνα με τα αποτελέσματα, το **53.99% των δειγμάτων έχουν απουσιάζουσες τιμές**.\n",
        "\n",
        "Βλέπουμε, λοιπόν ότι ένα πολύ μεγάλο ποσοστό των δειγμάτων έχουν τουλάχιστον μία απουσιάζουσα τιμή, επομένως η διαγραφή των δειγμάτων με απουσιάζουσες τιμές είναι απαγορευτική.\n",
        "\n",
        "Στη συνέχεια, θα ελέγξουμε πόσες απουσιάζουσες τιμές έχει το κάθε χαρακτηριστικό:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1zBGJGSPz7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6b1662-20a3-4cee-d202-3cbaf08c63ea"
      },
      "source": [
        "# the list of the number of missing values for each attribute occurs by \n",
        "# summing the elements of the inverse of df, without df's last column.\n",
        "# df's last column is the class attribute and it is alwasy present.\n",
        "incomplete_attrs_big = [sum(i) for i in np.array(big_df.isna())[:,:big_df.shape[1]-1].T]\n",
        "print(\"For each attribute of the dataset, the number of the missing values is\")\n",
        "print(incomplete_attrs_big)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For each attribute of the dataset, the number of the missing values is\n",
            "[8, 8, 8, 134, 89, 8, 8, 94, 9, 8, 44, 134, 127, 8, 36, 95, 94, 8, 128, 127, 5854, 8, 127, 922, 8, 95, 2764, 812, 8, 127, 127, 368, 134, 94, 8, 8, 18984, 8, 127, 134, 754, 127, 127, 127, 2147, 135, 297, 9, 127, 94, 8, 301, 812, 812, 1, 127, 7, 84, 7, 2152, 102, 127, 134, 812]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFJ_U_bQNMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72b0d85-b11a-470a-c142-d55bad13deee"
      },
      "source": [
        "# list of all attributes with more than 30% of their values missing\n",
        "incomplete_attributes = [i for i, x in enumerate(incomplete_attrs_big) if x/big_df.shape[0] > 0.3]\n",
        "print(incomplete_attributes)\n",
        "\n",
        "for x in incomplete_attributes:\n",
        "    print(incomplete_attrs_big[x]*100/big_df.shape[0], \"%\")\n",
        "# print(incomplete_attrs_big[incomplete_attribute]*100/big_df.shape[0], \"%\")"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[36]\n",
            "43.73689667089045 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ulSghZPQe_-"
      },
      "source": [
        "Παρατηρούμε ότι το 43.7% των τιμών του χαρακτηριστικού 37ου (η αρίθμηση ξεκινάει από το 0) απουσιάζει. Με βάση αυτήν την παρατήρηση θα ήταν μαλλον καλύτερο να διαγραφεί εντελώς αυτή η στήλη ώστε να μην επηρεάσει αρνητικά.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KghVrIMSdXV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "b1704dde-fc0c-47a2-b3fd-d3c6c82c12ac"
      },
      "source": [
        "big_df = big_df.drop(big_df.columns[[incomplete_attributes[0]]], axis=1)\n",
        "big_df"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>50</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.20055</td>\n",
              "      <td>0.37951</td>\n",
              "      <td>0.39641</td>\n",
              "      <td>2.0472</td>\n",
              "      <td>32.351</td>\n",
              "      <td>0.38825</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>1.3305</td>\n",
              "      <td>1.1389</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>0.6598</td>\n",
              "      <td>0.1666</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>497.42</td>\n",
              "      <td>0.73378</td>\n",
              "      <td>2.6349</td>\n",
              "      <td>0.24976</td>\n",
              "      <td>0.14942</td>\n",
              "      <td>43.37</td>\n",
              "      <td>1.2479</td>\n",
              "      <td>0.21402</td>\n",
              "      <td>0.11998</td>\n",
              "      <td>0.47706</td>\n",
              "      <td>0.50494</td>\n",
              "      <td>0.60411</td>\n",
              "      <td>1.4582</td>\n",
              "      <td>1.7615</td>\n",
              "      <td>5.9443</td>\n",
              "      <td>0.11788</td>\n",
              "      <td>0.14942</td>\n",
              "      <td>94.14</td>\n",
              "      <td>3.8772</td>\n",
              "      <td>0.56393</td>\n",
              "      <td>0.21402</td>\n",
              "      <td>1.741</td>\n",
              "      <td>0.50591</td>\n",
              "      <td>0.12804</td>\n",
              "      <td>0.66295</td>\n",
              "      <td>0.051402</td>\n",
              "      <td>0.12804</td>\n",
              "      <td>114.42</td>\n",
              "      <td>71.05</td>\n",
              "      <td>1.0097</td>\n",
              "      <td>1.5225</td>\n",
              "      <td>49.394</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>0.11085</td>\n",
              "      <td>2.042</td>\n",
              "      <td>0.37854</td>\n",
              "      <td>0.25792</td>\n",
              "      <td>2.2437</td>\n",
              "      <td>2.248</td>\n",
              "      <td>348690</td>\n",
              "      <td>0.12196</td>\n",
              "      <td>0.39718</td>\n",
              "      <td>0.87804</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>8.416</td>\n",
              "      <td>5.1372</td>\n",
              "      <td>82.658</td>\n",
              "      <td>4.4158</td>\n",
              "      <td>7.4277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.20912</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.47225</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>14.786</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25834</td>\n",
              "      <td>0.99601</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>0.26114</td>\n",
              "      <td>0.5168</td>\n",
              "      <td>0.15835</td>\n",
              "      <td>0.25834</td>\n",
              "      <td>677.96</td>\n",
              "      <td>0.53838</td>\n",
              "      <td>2.0005</td>\n",
              "      <td>0.25834</td>\n",
              "      <td>0.152</td>\n",
              "      <td>87.981</td>\n",
              "      <td>1.4293</td>\n",
              "      <td>0.24806</td>\n",
              "      <td>0.12304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.39542</td>\n",
              "      <td>0.43992</td>\n",
              "      <td>88.444</td>\n",
              "      <td>16.946</td>\n",
              "      <td>3.6884</td>\n",
              "      <td>0.26969</td>\n",
              "      <td>0.152</td>\n",
              "      <td>122.17</td>\n",
              "      <td>2.9876</td>\n",
              "      <td>2.9876</td>\n",
              "      <td>0.20616</td>\n",
              "      <td>1.6996</td>\n",
              "      <td>0.49788</td>\n",
              "      <td>0.1213</td>\n",
              "      <td>0.086422</td>\n",
              "      <td>0.064371</td>\n",
              "      <td>0.14595</td>\n",
              "      <td>199.49</td>\n",
              "      <td>111.51</td>\n",
              "      <td>0.51045</td>\n",
              "      <td>1.1252</td>\n",
              "      <td>100.13</td>\n",
              "      <td>0.23727</td>\n",
              "      <td>0.13961</td>\n",
              "      <td>1.9447</td>\n",
              "      <td>0.49988</td>\n",
              "      <td>0.33472</td>\n",
              "      <td>17.866</td>\n",
              "      <td>17.866</td>\n",
              "      <td>2304.6</td>\n",
              "      <td>0.1213</td>\n",
              "      <td>0.42002</td>\n",
              "      <td>0.853</td>\n",
              "      <td>0</td>\n",
              "      <td>4.1486</td>\n",
              "      <td>3.2732</td>\n",
              "      <td>107.35</td>\n",
              "      <td>3.4</td>\n",
              "      <td>60.987</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.24866</td>\n",
              "      <td>0.69592</td>\n",
              "      <td>0.26713</td>\n",
              "      <td>1.5548</td>\n",
              "      <td>-1.1523</td>\n",
              "      <td>0</td>\n",
              "      <td>0.30906</td>\n",
              "      <td>0.43695</td>\n",
              "      <td>1.309</td>\n",
              "      <td>0.30408</td>\n",
              "      <td>0.31258</td>\n",
              "      <td>0.64184</td>\n",
              "      <td>0.24435</td>\n",
              "      <td>0.30906</td>\n",
              "      <td>794.16</td>\n",
              "      <td>0.45961</td>\n",
              "      <td>1.4369</td>\n",
              "      <td>0.30906</td>\n",
              "      <td>0.2361</td>\n",
              "      <td>73.133</td>\n",
              "      <td>1.4283</td>\n",
              "      <td>0.3026</td>\n",
              "      <td>0.18996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.28932</td>\n",
              "      <td>0.37282</td>\n",
              "      <td>86.011</td>\n",
              "      <td>1.0627</td>\n",
              "      <td>4.3749</td>\n",
              "      <td>0.41929</td>\n",
              "      <td>0.23815</td>\n",
              "      <td>176.93</td>\n",
              "      <td>2.063</td>\n",
              "      <td>1.4274</td>\n",
              "      <td>0.31565</td>\n",
              "      <td>1.309</td>\n",
              "      <td>0.51537</td>\n",
              "      <td>0.24114</td>\n",
              "      <td>0.32202</td>\n",
              "      <td>0.07402</td>\n",
              "      <td>0.23117</td>\n",
              "      <td>165.51</td>\n",
              "      <td>92.381</td>\n",
              "      <td>0.94807</td>\n",
              "      <td>1.0101</td>\n",
              "      <td>96.372</td>\n",
              "      <td>0.29181</td>\n",
              "      <td>0.22293</td>\n",
              "      <td>1.0758</td>\n",
              "      <td>0.48152</td>\n",
              "      <td>0.48474</td>\n",
              "      <td>1.2098</td>\n",
              "      <td>2.0504</td>\n",
              "      <td>6332.7</td>\n",
              "      <td>0.24114</td>\n",
              "      <td>0.81774</td>\n",
              "      <td>0.76599</td>\n",
              "      <td>0.69484</td>\n",
              "      <td>4.9909</td>\n",
              "      <td>3.951</td>\n",
              "      <td>134.27</td>\n",
              "      <td>2.7185</td>\n",
              "      <td>5.2078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.081483</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.45879</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>51.952</td>\n",
              "      <td>0.14988</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>1.8661</td>\n",
              "      <td>1.0571</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>0.30163</td>\n",
              "      <td>0.094257</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>917.01</td>\n",
              "      <td>0.39803</td>\n",
              "      <td>3.2537</td>\n",
              "      <td>0.092704</td>\n",
              "      <td>0.071428</td>\n",
              "      <td>79.788</td>\n",
              "      <td>1.5069</td>\n",
              "      <td>0.1155</td>\n",
              "      <td>0.062782</td>\n",
              "      <td>0.17193</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.36152</td>\n",
              "      <td>0.94076</td>\n",
              "      <td>1.9618</td>\n",
              "      <td>4.6511</td>\n",
              "      <td>0.14343</td>\n",
              "      <td>0.071428</td>\n",
              "      <td>91.37</td>\n",
              "      <td>3.9948</td>\n",
              "      <td>0.37581</td>\n",
              "      <td>0.1155</td>\n",
              "      <td>1.3562</td>\n",
              "      <td>0.57353</td>\n",
              "      <td>0.088995</td>\n",
              "      <td>0.40139</td>\n",
              "      <td>0.069622</td>\n",
              "      <td>0.088995</td>\n",
              "      <td>180.77</td>\n",
              "      <td>100.98</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>1.5696</td>\n",
              "      <td>84.344</td>\n",
              "      <td>0.085874</td>\n",
              "      <td>0.066165</td>\n",
              "      <td>2.4928</td>\n",
              "      <td>0.30734</td>\n",
              "      <td>0.25033</td>\n",
              "      <td>2.4524</td>\n",
              "      <td>2.4524</td>\n",
              "      <td>20545</td>\n",
              "      <td>0.054015</td>\n",
              "      <td>0.14207</td>\n",
              "      <td>0.94598</td>\n",
              "      <td>0</td>\n",
              "      <td>4.5746</td>\n",
              "      <td>3.6147</td>\n",
              "      <td>86.435</td>\n",
              "      <td>4.2228</td>\n",
              "      <td>5.5497</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.61323</td>\n",
              "      <td>0.2296</td>\n",
              "      <td>1.4063</td>\n",
              "      <td>-7.3128</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.6307</td>\n",
              "      <td>1.1559</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.33147</td>\n",
              "      <td>0.12182</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>1133.2</td>\n",
              "      <td>0.32211</td>\n",
              "      <td>1.6307</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.11553</td>\n",
              "      <td>57.045</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.19832</td>\n",
              "      <td>0.11553</td>\n",
              "      <td>0.18732</td>\n",
              "      <td>0.38677</td>\n",
              "      <td>0.32211</td>\n",
              "      <td>1.4138</td>\n",
              "      <td>1.1184</td>\n",
              "      <td>4.1424</td>\n",
              "      <td>0.27884</td>\n",
              "      <td>0.11553</td>\n",
              "      <td>147.04</td>\n",
              "      <td>2.4823</td>\n",
              "      <td>0.3234</td>\n",
              "      <td>0.19832</td>\n",
              "      <td>1.6278</td>\n",
              "      <td>0.43489</td>\n",
              "      <td>0.12231</td>\n",
              "      <td>0.29304</td>\n",
              "      <td>0.09668</td>\n",
              "      <td>0.12231</td>\n",
              "      <td>141.62</td>\n",
              "      <td>84.574</td>\n",
              "      <td>0.73919</td>\n",
              "      <td>0.95787</td>\n",
              "      <td>65.936</td>\n",
              "      <td>0.18811</td>\n",
              "      <td>0.11601</td>\n",
              "      <td>1.2959</td>\n",
              "      <td>0.56511</td>\n",
              "      <td>0.40285</td>\n",
              "      <td>1.8839</td>\n",
              "      <td>2.1184</td>\n",
              "      <td>3186.6</td>\n",
              "      <td>0.13485</td>\n",
              "      <td>0.48431</td>\n",
              "      <td>0.86515</td>\n",
              "      <td>0.12444</td>\n",
              "      <td>6.3985</td>\n",
              "      <td>4.3158</td>\n",
              "      <td>127.21</td>\n",
              "      <td>2.8692</td>\n",
              "      <td>7.898</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43400</th>\n",
              "      <td>0.012898</td>\n",
              "      <td>0.70621</td>\n",
              "      <td>0.038857</td>\n",
              "      <td>1.1722</td>\n",
              "      <td>-18.907</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>0.416</td>\n",
              "      <td>1.6768</td>\n",
              "      <td>0.29379</td>\n",
              "      <td>0.041583</td>\n",
              "      <td>0.061959</td>\n",
              "      <td>0.023622</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>6507.6</td>\n",
              "      <td>0.056089</td>\n",
              "      <td>1.416</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>0.008338</td>\n",
              "      <td>27.092</td>\n",
              "      <td>1.033</td>\n",
              "      <td>0.040401</td>\n",
              "      <td>0.007692</td>\n",
              "      <td>0.90184</td>\n",
              "      <td>0.083706</td>\n",
              "      <td>0.054556</td>\n",
              "      <td>1.4637</td>\n",
              "      <td>0.052831</td>\n",
              "      <td>4.9667</td>\n",
              "      <td>0.41853</td>\n",
              "      <td>0.024762</td>\n",
              "      <td>50.128</td>\n",
              "      <td>7.4</td>\n",
              "      <td>2.3644</td>\n",
              "      <td>0.033819</td>\n",
              "      <td>1.6768</td>\n",
              "      <td>0.66377</td>\n",
              "      <td>0.020169</td>\n",
              "      <td>0.022858</td>\n",
              "      <td>0.35651</td>\n",
              "      <td>0.024093</td>\n",
              "      <td>56.452</td>\n",
              "      <td>29.36</td>\n",
              "      <td>0.10363</td>\n",
              "      <td>0.62061</td>\n",
              "      <td>27.207</td>\n",
              "      <td>0.014771</td>\n",
              "      <td>0.008809</td>\n",
              "      <td>0.37454</td>\n",
              "      <td>0.22564</td>\n",
              "      <td>0.13514</td>\n",
              "      <td>0.39944</td>\n",
              "      <td>0.90248</td>\n",
              "      <td>3599.1</td>\n",
              "      <td>0.020169</td>\n",
              "      <td>0.043904</td>\n",
              "      <td>1.0122</td>\n",
              "      <td>1.2594</td>\n",
              "      <td>13.472</td>\n",
              "      <td>12.432</td>\n",
              "      <td>49.117</td>\n",
              "      <td>7.4313</td>\n",
              "      <td>2.2799</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43401</th>\n",
              "      <td>-0.57805</td>\n",
              "      <td>0.96702</td>\n",
              "      <td>-0.80085</td>\n",
              "      <td>0.16576</td>\n",
              "      <td>-67.365</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.40334</td>\n",
              "      <td>0.93979</td>\n",
              "      <td>-0.39004</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.60216</td>\n",
              "      <td>-0.11022</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-742.28</td>\n",
              "      <td>-0.49173</td>\n",
              "      <td>1.0341</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.13399</td>\n",
              "      <td>3.2965</td>\n",
              "      <td>0.6477</td>\n",
              "      <td>-0.53492</td>\n",
              "      <td>-0.13399</td>\n",
              "      <td>-0.57805</td>\n",
              "      <td>-0.39004</td>\n",
              "      <td>-0.49173</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.9524</td>\n",
              "      <td>4.0622</td>\n",
              "      <td>0.21864</td>\n",
              "      <td>-0.13399</td>\n",
              "      <td>76.33</td>\n",
              "      <td>4.7819</td>\n",
              "      <td>-0.55316</td>\n",
              "      <td>-0.53492</td>\n",
              "      <td>4.3912</td>\n",
              "      <td>-0.38299</td>\n",
              "      <td>-0.12399</td>\n",
              "      <td>0.024771</td>\n",
              "      <td>-0.073529</td>\n",
              "      <td>-0.12399</td>\n",
              "      <td>11.451</td>\n",
              "      <td>8.1548</td>\n",
              "      <td>-14.836</td>\n",
              "      <td>0.12517</td>\n",
              "      <td>3.098</td>\n",
              "      <td>-0.63746</td>\n",
              "      <td>-0.14776</td>\n",
              "      <td>0.16455</td>\n",
              "      <td>0.95997</td>\n",
              "      <td>0.20912</td>\n",
              "      <td>-0.46385</td>\n",
              "      <td>-0.45546</td>\n",
              "      <td>-9242.1</td>\n",
              "      <td>-0.064073</td>\n",
              "      <td>1.482</td>\n",
              "      <td>1.0641</td>\n",
              "      <td>-0.018084</td>\n",
              "      <td>110.72</td>\n",
              "      <td>44.759</td>\n",
              "      <td>81.22</td>\n",
              "      <td>4.494</td>\n",
              "      <td>5.1305</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43402</th>\n",
              "      <td>-0.17905</td>\n",
              "      <td>1.2553</td>\n",
              "      <td>-0.27599</td>\n",
              "      <td>0.74554</td>\n",
              "      <td>-120.44</td>\n",
              "      <td>-0.17905</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.26018</td>\n",
              "      <td>1.1749</td>\n",
              "      <td>-0.32659</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.14284</td>\n",
              "      <td>-0.07294</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-3298.2</td>\n",
              "      <td>-0.11067</td>\n",
              "      <td>0.79665</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.08135</td>\n",
              "      <td>37.046</td>\n",
              "      <td>0.83104</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>-0.094015</td>\n",
              "      <td>-0.15493</td>\n",
              "      <td>-0.32659</td>\n",
              "      <td>-0.12988</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.4423</td>\n",
              "      <td>5.3244</td>\n",
              "      <td>0.65813</td>\n",
              "      <td>-0.08135</td>\n",
              "      <td>244.23</td>\n",
              "      <td>1.4945</td>\n",
              "      <td>0.14077</td>\n",
              "      <td>0.1767</td>\n",
              "      <td>1.9515</td>\n",
              "      <td>-0.15597</td>\n",
              "      <td>0.09278</td>\n",
              "      <td>0.064095</td>\n",
              "      <td>0.21414</td>\n",
              "      <td>0.09278</td>\n",
              "      <td>141.65</td>\n",
              "      <td>104.61</td>\n",
              "      <td>-0.9263</td>\n",
              "      <td>0.56733</td>\n",
              "      <td>43.526</td>\n",
              "      <td>0.16068</td>\n",
              "      <td>0.08437</td>\n",
              "      <td>0.64421</td>\n",
              "      <td>1.0846</td>\n",
              "      <td>0.66913</td>\n",
              "      <td>-1.7067</td>\n",
              "      <td>-0.81508</td>\n",
              "      <td>-58253</td>\n",
              "      <td>0.14888</td>\n",
              "      <td>0.54824</td>\n",
              "      <td>0.85112</td>\n",
              "      <td>-0.52243</td>\n",
              "      <td>9.8526</td>\n",
              "      <td>3.4892</td>\n",
              "      <td>207.87</td>\n",
              "      <td>1.7559</td>\n",
              "      <td>9.9527</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43403</th>\n",
              "      <td>-0.10886</td>\n",
              "      <td>0.74394</td>\n",
              "      <td>0.015449</td>\n",
              "      <td>1.0878</td>\n",
              "      <td>-17.003</td>\n",
              "      <td>-0.10886</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>0.12531</td>\n",
              "      <td>0.84516</td>\n",
              "      <td>0.093224</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>-0.62038</td>\n",
              "      <td>-0.065652</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>-5352.1</td>\n",
              "      <td>-0.068197</td>\n",
              "      <td>1.3442</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>-0.14128</td>\n",
              "      <td>26.285</td>\n",
              "      <td>1.121</td>\n",
              "      <td>-0.09995</td>\n",
              "      <td>-0.14086</td>\n",
              "      <td>-0.10918</td>\n",
              "      <td>0.093224</td>\n",
              "      <td>-0.067762</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.019106</td>\n",
              "      <td>4.8555</td>\n",
              "      <td>0.95181</td>\n",
              "      <td>-0.14128</td>\n",
              "      <td>70.252</td>\n",
              "      <td>5.1956</td>\n",
              "      <td>-0.13435</td>\n",
              "      <td>-0.09995</td>\n",
              "      <td>0.83553</td>\n",
              "      <td>0.66118</td>\n",
              "      <td>-0.12934</td>\n",
              "      <td>0.048976</td>\n",
              "      <td>-0.5893</td>\n",
              "      <td>-0.12934</td>\n",
              "      <td>86.348</td>\n",
              "      <td>60.064</td>\n",
              "      <td>-1.9561</td>\n",
              "      <td>0.77157</td>\n",
              "      <td>22.215</td>\n",
              "      <td>-0.1584</td>\n",
              "      <td>-0.20497</td>\n",
              "      <td>0.25733</td>\n",
              "      <td>0.17599</td>\n",
              "      <td>0.19247</td>\n",
              "      <td>0.1153</td>\n",
              "      <td>0.81772</td>\n",
              "      <td>1107.5</td>\n",
              "      <td>-0.1832</td>\n",
              "      <td>-1.1677</td>\n",
              "      <td>1.1832</td>\n",
              "      <td>6.0924</td>\n",
              "      <td>13.886</td>\n",
              "      <td>6.0769</td>\n",
              "      <td>83.122</td>\n",
              "      <td>4.3911</td>\n",
              "      <td>0.95575</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43404</th>\n",
              "      <td>-0.10537</td>\n",
              "      <td>0.53629</td>\n",
              "      <td>-0.045578</td>\n",
              "      <td>0.91478</td>\n",
              "      <td>-56.068</td>\n",
              "      <td>-0.10537</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>0.8646</td>\n",
              "      <td>0.9504</td>\n",
              "      <td>0.46367</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>-0.20557</td>\n",
              "      <td>-0.066747</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>-2055.9</td>\n",
              "      <td>-0.17754</td>\n",
              "      <td>1.8647</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>-0.077072</td>\n",
              "      <td>47.199</td>\n",
              "      <td>0.71351</td>\n",
              "      <td>-0.082947</td>\n",
              "      <td>-0.073868</td>\n",
              "      <td>-0.10994</td>\n",
              "      <td>0.46367</td>\n",
              "      <td>-0.16902</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.089234</td>\n",
              "      <td>3.9698</td>\n",
              "      <td>0.37528</td>\n",
              "      <td>-0.077072</td>\n",
              "      <td>130.06</td>\n",
              "      <td>2.8064</td>\n",
              "      <td>-0.15467</td>\n",
              "      <td>-0.082947</td>\n",
              "      <td>1.4481</td>\n",
              "      <td>0.46515</td>\n",
              "      <td>-0.058149</td>\n",
              "      <td>0.004456</td>\n",
              "      <td>-0.25846</td>\n",
              "      <td>-0.058149</td>\n",
              "      <td>124.57</td>\n",
              "      <td>77.374</td>\n",
              "      <td>-0.57124</td>\n",
              "      <td>0.56987</td>\n",
              "      <td>44.858</td>\n",
              "      <td>-0.097675</td>\n",
              "      <td>-0.068474</td>\n",
              "      <td>0.91225</td>\n",
              "      <td>0.53481</td>\n",
              "      <td>0.35632</td>\n",
              "      <td>0.90779</td>\n",
              "      <td>0.91069</td>\n",
              "      <td>-425.13</td>\n",
              "      <td>-0.052186</td>\n",
              "      <td>-0.22725</td>\n",
              "      <td>1.0522</td>\n",
              "      <td>0.003196</td>\n",
              "      <td>7.7332</td>\n",
              "      <td>4.7174</td>\n",
              "      <td>136.85</td>\n",
              "      <td>2.6672</td>\n",
              "      <td>2.7927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>43405 rows × 64 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0        1          2        3   ...      61      62       63 64\n",
              "0       0.20055  0.37951    0.39641   2.0472  ...  82.658  4.4158   7.4277  0\n",
              "1       0.20912  0.49988    0.47225   1.9447  ...  107.35     3.4   60.987  0\n",
              "2       0.24866  0.69592    0.26713   1.5548  ...  134.27  2.7185   5.2078  0\n",
              "3      0.081483  0.30734    0.45879   2.4928  ...  86.435  4.2228   5.5497  0\n",
              "4       0.18732  0.61323     0.2296   1.4063  ...  127.21  2.8692    7.898  0\n",
              "...         ...      ...        ...      ...  ...     ...     ...      ... ..\n",
              "43400  0.012898  0.70621   0.038857   1.1722  ...  49.117  7.4313   2.2799  1\n",
              "43401  -0.57805  0.96702   -0.80085  0.16576  ...   81.22   4.494   5.1305  1\n",
              "43402  -0.17905   1.2553   -0.27599  0.74554  ...  207.87  1.7559   9.9527  1\n",
              "43403  -0.10886  0.74394   0.015449   1.0878  ...  83.122  4.3911  0.95575  1\n",
              "43404  -0.10537  0.53629  -0.045578  0.91478  ...  136.85  2.6672   2.7927  1\n",
              "\n",
              "[43405 rows x 64 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8QLm3_xVMIM"
      },
      "source": [
        "Για τις υπόλοιπες τιμές, θα αντικαταστήσουμε κάθε απουσιάζουσα τιμή χαρακτηριστικού με τη μέση τιμή. Αυτό θα γίνει μετά τον διαχωρισμό του dataset σε train και test και πριν την έναρξη του Cross Validation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL5TGc3BXKkL"
      },
      "source": [
        "###Κατανομή των κλάσεων\n",
        "\n",
        "Στη συνέχεια, θα εξετάσουμε τι κατανομή έχουν οι δύο κλάσεις στα δεδομένα:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRcFckz5Yvky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5077ea27-ea92-4fa2-857b-fd3a853cfa80"
      },
      "source": [
        "num_of_rows = big_df.shape[0]\n",
        "num_of_attrs = big_df.shape[1] - 1 #remove one element because of the class attribute\n",
        "\n",
        "# get labesl and features\n",
        "labels_df = big_df.iloc[:, [num_of_attrs]] # τα labels είναι στην τελευταία κολώνα\n",
        "features_df = big_df.iloc[:, 0:num_of_attrs]  # τα features είναι όλες οι προηγούμενες κολώνες\n",
        "\n",
        "labels = labels_df.values.reshape(num_of_rows,)\n",
        "features = features_df.values\n",
        "# convert to int\n",
        "labels.astype(int)\n",
        "labels = np.array(labels, dtype='int64')\n",
        "\n",
        "\n",
        "# find how many of each class\n",
        "bin_count = np.bincount(labels)\n",
        "print (\"bincount:\", bin_count)\n",
        "print(sum(bin_count))\n",
        "print(\"The percentage of 0's in data: \", bin_count[0]*100/sum(bin_count), \"%.\")\n",
        "print(\"The percentage of 1's in data: \", bin_count[1]*100/sum(bin_count), \"%.\")"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bincount: [41314  2091]\n",
            "43405\n",
            "The percentage of 0's in data:  95.18258265176823 %.\n",
            "The percentage of 1's in data:  4.81741734823177 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jayK-hD4aYUM"
      },
      "source": [
        "Παρατηρούμε ότι το **95%** των δειγμάτων ανήκουν στην κλάση **0**, ενώ μόλις το **4.81%** στην κλάση **1**. Επομένως, **το dataset είναι εντελώς ανισόρροπο**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2dKrxCuWiI6"
      },
      "source": [
        "###Διαχωρισμός του dataset\n",
        "Διαχωρίζουμε το dataset σε train και test set, χρησιμοποιώντας το 70% των δεδομένων για το training και το 30% για το testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo_kT2rvd3rc"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train, test, big_train_labels, big_test_labels = train_test_split(features, labels, test_size=0.3)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oYFXJiPd6gP"
      },
      "source": [
        "train_pd = pd.DataFrame(data=train[:,:],    # values\n",
        "                 index=train[:,0])    # 1st column as index\n",
        "                  \n",
        "test_pd = pd.DataFrame(data=test[:,:],    # values\n",
        "                 index=test[:,0])    # 1st column as index"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4YX9wBleC_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6ff367-58f7-400d-998b-95992b689e14"
      },
      "source": [
        "print(train.shape)\n",
        "print(train_pd.shape)\n",
        "\n",
        "print(test.shape)\n",
        "print(test_pd.shape)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30383, 63)\n",
            "(30383, 63)\n",
            "(13022, 63)\n",
            "(13022, 63)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_L1wklKeT4r"
      },
      "source": [
        "##Ταξινόμηση"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQnP7OCAosAV"
      },
      "source": [
        "Θα χρησιμποιηθούν οι ίδιες συναρτήσεις που χρησιμοποιήθηκαν στο μικρό Dataset, αφού το μόνο που αρκεί είναι η κλήση τους με τις κατάλληλες παραμέτρους.\n",
        "\n",
        "Αρχικά, όμως θα αντικαταστήσουμε τις απουσιάζουσες με τον μέσο όρο των τιμών στο αντίστοιχο χαρακτηριστικό:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2qWZ_rEqdVl"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# create imputer that will replace NaN with the most frequent value\n",
        "imp=SimpleImputer(missing_values=np.NaN,strategy=\"mean\")\n",
        "# fit and transform train data by replacing NaN with the most frequent value of the attribute\n",
        "big_train=pd.DataFrame(imp.fit_transform(train_pd))\n",
        "big_train.columns=train_pd.columns\n",
        "big_train.index=train_pd.index\n",
        "\n",
        "# transform the test data using the same model\n",
        "big_test = imp.transform(test_pd.values)"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D69o3iBxqzsd"
      },
      "source": [
        "Κατηγορικές μεταβλητές δεν υπάρχουν στο dataset, επομένως μπορούμε να εισάγουμε τα δεδομένα στο Pipeline και να δοκιμάσουμε τους διάφορους ταξινομητές που προκύπτουν."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u28JfWCHpG8E"
      },
      "source": [
        "###Baseline Classification - Ταξινόμηση χωρίς προεπεξεργασία"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OyciSQ7fvKcl",
        "outputId": "66dd8d93-aac8-4d4e-fc0c-3809ebcee6e2"
      },
      "source": [
        "classifiers = {\n",
        "    'dummy': dummy,\n",
        "    'gnb': gnb,\n",
        "    'kNN': knn,\n",
        "    'mlp': mlp,\n",
        "    'svm': svc\n",
        "\n",
        "}\n",
        "\n",
        "big_scores_default = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                                  my_transformers={}, my_classifiers=classifiers, \n",
        "                                  est_values_mapper={}, cv=None, showResults=True)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average of the dummy classifier is:  0.906926739364153\n",
            "The average f1-macro average of the dummy classifier is:  0.5013525661221901\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.95      0.95      0.95     12383\n",
            "     granted       0.05      0.05      0.05       639\n",
            "\n",
            "    accuracy                           0.91     13022\n",
            "   macro avg       0.50      0.50      0.50     13022\n",
            "weighted avg       0.91      0.91      0.91     13022\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "The average f1-micro average of the gnb classifier is:  0.072185532176317\n",
            "The average f1-macro average of the gnb classifier is:  0.0716993872212357\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.94      0.03      0.05     12383\n",
            "     granted       0.05      0.97      0.09       639\n",
            "\n",
            "    accuracy                           0.07     13022\n",
            "   macro avg       0.50      0.50      0.07     13022\n",
            "weighted avg       0.90      0.07      0.05     13022\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "The average f1-micro average of the kNN classifier is:  0.9508524036246352\n",
            "The average f1-macro average of the kNN classifier is:  0.5560859320753012\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.95      1.00      0.97     12383\n",
            "     granted       0.50      0.08      0.14       639\n",
            "\n",
            "    accuracy                           0.95     13022\n",
            "   macro avg       0.72      0.54      0.56     13022\n",
            "weighted avg       0.93      0.95      0.93     13022\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "The average f1-micro average of the mlp classifier is:  0.9263553985562893\n",
            "The average f1-macro average of the mlp classifier is:  0.5807837449568476\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.96      0.96      0.96     12383\n",
            "     granted       0.21      0.19      0.20       639\n",
            "\n",
            "    accuracy                           0.93     13022\n",
            "   macro avg       0.59      0.58      0.58     13022\n",
            "weighted avg       0.92      0.93      0.92     13022\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "The average f1-micro average of the svm classifier is:  0.9510059898633082\n",
            "The average f1-macro average of the svm classifier is:  0.48900542237442923\n",
            "The classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    rejected       0.95      1.00      0.97     12383\n",
            "     granted       1.00      0.00      0.00       639\n",
            "\n",
            "    accuracy                           0.95     13022\n",
            "   macro avg       0.98      0.50      0.49     13022\n",
            "weighted avg       0.95      0.95      0.93     13022\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGwCeySQCfoq"
      },
      "source": [
        "####Σχολιασμός αποτελεσμάτων"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7CEP3CS9UoF"
      },
      "source": [
        "Για την μελέτη των αποτελεσμάτων έχουν τυπωθεί οι τιμές f1-micro average και f1-macro average, τα classification reports και οι πίνακες σύγχυσης.\n",
        "Η εξήγηση των παραπάνω έχει γίνει στην μελέτη του μικρού dataset, οπότε ακολουθεί η ερμηνεία τους.\n",
        "\n",
        "Μελετώντας τα παραπάνω classification reports μπορούμε να βγάλουμε ορισμένα συμπεράσματα, αλλά και να καταλήξουμε αν τα αποτελέσματα από το train των classifiers με τις default τους τιμές είναι αναμενόμενο.\n",
        "\n",
        "* Για τον **Dummy Classifier**: Έχει χρησιμοποιηθεί η deafult στρατηγική του, δηλαδή η *stratified*, η οποία ταξινομεί το κάθε δείγμα ανεξάρτητα από τα χαρακτηριστικά του, λαμβάνοντας μόνον υπόψιν να διατηρείται σταθερή η κατανομή των κλάσεων και να είναι ίδια με αυτή στα train data. Όπως ήταν αναμενόμενο, και όπως φαίνεται και από τους πίνακες σύγχυσης, ο ταξινομητής έχει ταξινομήσει στην κλάση 0 (μη πτώχευση) 12415 δείγματα, δηλαδή το 95.3% των συνολικών δειγμάτων, ακριβώς όσο ήταν και η κατανομή 0 και 1 στο training data. Ακριβώς επειδή έχουν ταξινομηθεί τα περισσότερα δείγματα στην κλάση 0 και επειδή όντως τα περισσότερα ανήκαν σε αυτήν οι τιμές των **Precision** (κατά πόσο ήταν θετικά αυτά που το μοντέλο δήλωσε ως θετικά), **Recall** (ποσοστό από τα positives για την κάθε κλάση προβλέψαμε σωστά) και **f1 score** (ποσοστό των θετικών προβλέψεων που ήταν σωστά) είναι πολύ κοντά στη μονάδα. Παρόλα αυτά το ίδια δεν ισχύει καθόλου για τις παραπάνω τιμές της κλάσης 1.\n",
        "\n",
        "* Για τον **Gaussian Naive Bayes Classifier**: Παρατηρούμε ότι ταξινομεί τη συντριπτική πλειοψηφία των δειγμάτων στην κλάση 1.\n",
        "\n",
        "* Για τον **k_Nearest Neighbors Classifier**, όπου η default τιμή για την υπερπαράμετρο k είναι k=5, παρατηρούμε"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsPVeetFzNJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "781f6a02-c2f3-445c-cf29-0dd4df5a72cc"
      },
      "source": [
        "# plot for f1-macro average\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "clfs = f1_scores_default['preds'].keys()\n",
        "big_f1_macro = [f1_score(big_test_labels, pred, average='macro') for pred in big_scores_default['preds'].values()]\n",
        "ax.bar(clfs,big_f1_macro, color='cyan', width=0.3)\n",
        "plt.title(\"F1 Macro Average\")\n",
        "plt.xlabel(\"Classifiers\")\n",
        "plt.ylabel(\"F1 Macro Score\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# plot for f1-micro average\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "clfs = f1_scores_default['preds'].keys()\n",
        "big_f1_micro = [f1_score(big_test_labels, pred, average='micro') for pred in big_scores_default['preds'].values()]\n",
        "ax.bar(clfs,big_f1_micro, color='b', width=0.3)\n",
        "plt.title(\"F1 Micro Average\")\n",
        "plt.xlabel(\"Classifiers\")\n",
        "plt.ylabel(\"F1 Micro Score\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WosDKWA7CubW"
      },
      "source": [
        "##Βελτιστοποίηση ταξινομητών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tNVM0Z73x5-"
      },
      "source": [
        "Εκτελούμε τις παρακάτω εντολές για να βρούμε τη διακύμανση στις τιμές των διαφόρων χαρακτηριστικών:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZUXF8pHpiHE"
      },
      "source": [
        "# train_variance = i_train.var(axis=0)\n",
        "# print(train_variance)\n",
        "# print(np.max(train_variance))\n",
        "# print(train_variance.shape)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99g2ZY4rGdbL"
      },
      "source": [
        "###Μετρική απόδοσης f1-macro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pnEG1f9Gk5c"
      },
      "source": [
        "####Dummy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Amlu73NMLB"
      },
      "source": [
        "# dict that maps the transformer/classifier with the values of its arguments\n",
        "est_values_mapper = {\n",
        "    'selector': [0, 5, 10],\n",
        "    'pca': [5, 10, 20, 30],\n",
        "    'dummy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'],\n",
        "    'kNN': [2, 5, 7, 9, 11]\n",
        "}"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ASf_9N4rH8aS",
        "outputId": "3ac990df-0a8b-477d-ff9b-d98772f8faf2"
      },
      "source": [
        "transformers = {\n",
        "    'selector': selector,\n",
        "    'scaler': scaler,\n",
        "    'min_max_scaler': min_max_scaler,\n",
        "    'ros': ros,\n",
        "    'rus': rus,\n",
        "    'pca': pca\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_dummy = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                                 my_transformers=transformers, my_classifiers={'dummy':dummy}, \n",
        "                                 est_values_mapper=est_values_mapper, cv=5, scoring='f1_macro')\n",
        "\n",
        "\n",
        "# compute f1-macro\n",
        "dummy_macro_big = {k: f1_score(big_test_labels, v, average='macro') for k,v in big_scores_dummy['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_dummy_macro = max(dummy_macro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_dummy, opt_dummy_macro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0660s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0798s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0657s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0780s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0715s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0791s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0655s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0792s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0693s.) Setting batch_size=2.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0907s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0660s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0987s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1874s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done  27 out of  30 | elapsed:    2.4s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1853s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    2.0s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    2.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1935s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1993s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1864s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1873s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1930s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.1s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    1.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 15 candidates, totalling 30 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    2.5s\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    3.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('scaler', StandardScaler()),\n",
            "                ('dummy', DummyClassifier(strategy='stratified'))])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.506679494866576\n",
            "The average f1-macro average is:  0.9097680847796037\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     solvent       0.95      0.95      0.95     12383\n",
            "    bankrupt       0.06      0.06      0.06       639\n",
            "\n",
            "    accuracy                           0.91     13022\n",
            "   macro avg       0.51      0.51      0.51     13022\n",
            "weighted avg       0.91      0.91      0.91     13022\n",
            "\n",
            "Fit time:  1.205425500869751\n",
            "Predict time:  0.0051059722900390625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRwpQk80Gz2A"
      },
      "source": [
        "####Gaussian Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gABsZQUjLQ1R",
        "outputId": "6c8db2ec-b95b-4d94-957d-53f10985c0e9"
      },
      "source": [
        "big_scores_gnb = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                               my_transformers=transformers, my_classifiers={'gnb':gnb}, \n",
        "                               est_values_mapper=est_values_mapper, cv=5, scoring='f1_macro')\n",
        "\n",
        "\n",
        "\n",
        "# compute f1-macro\n",
        "gnb_macro_big = {k: f1_score(big_test_labels, v, average='macro') for k,v in big_scores_gnb['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_gnb_macro = max(gnb_macro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_gnb, opt_gnb_macro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1122s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1060s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1028s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1157s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1025s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1050s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1042s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.2s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.9s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.5s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.7s remaining:    0.4s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.7s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    1.0s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 out of   6 | elapsed:    0.6s remaining:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s remaining:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Done   6 out of   6 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "\n",
            "=========================================================================\n",
            "RESULTS\n",
            "Best estimator is:  Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold(threshold=5)),\n",
            "                ('scaler', StandardScaler()), ('rus', RandomUnderSampler()),\n",
            "                ('gnb', GaussianNB())])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The average f1-micro average is:  0.5470606395737935\n",
            "The average f1-macro average is:  0.9158347412071879\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     solvent       0.96      0.96      0.96     12383\n",
            "    bankrupt       0.14      0.14      0.14       639\n",
            "\n",
            "    accuracy                           0.92     13022\n",
            "   macro avg       0.55      0.55      0.55     13022\n",
            "weighted avg       0.92      0.92      0.92     13022\n",
            "\n",
            "Fit time:  1.2320890426635742\n",
            "Predict time:  0.01522064208984375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gnM4tABG3tn"
      },
      "source": [
        "####k_Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Deuql4dhOsQm"
      },
      "source": [
        "# big_scores_knn = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "#                                my_transformers=transformers, my_classifiers={'kNN':knn}, \n",
        "#                                est_values_mapper=est_values_mapper, cv=5, scoring='f1_macro')\n",
        "# macros = [(k,v) for k, v in sorted(big_scores_knn['macro'].items(), key=lambda item: item[1], reverse=True)]\n",
        "# print(macros)\n",
        "# getResults(big_scores_knn, macros, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYwa0OuauCn8"
      },
      "source": [
        "Βλέπουμε ότι ο καλύτερος ταξινομητής προέκυψυε με κανονικοποιήση Min-Max, RandomOverSampling και παράμετρο k του ταξινομητή kNN k=2. Ωστόσο, η παράμετρος αυτή ήταν η ελάχιστη που έχουμε θέσει στο σύνολο των τιμών της παράμετρου k για δοκιμή στο Cross Validation. Επομένως, θα ξανατρέξουμε τη συνάρτηση για τις τιμές: k = [1,2,3,4]. \n",
        "\n",
        "Αυτό θα μας κοστίσει χρονικά, ωστόσο θα επιλέξουμε με σιγουριά την καλύτερη δυνατή τιμή για το k."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "hJEOo6rJu7v7",
        "outputId": "db334789-75a1-460e-ea08-f6ffa3bd253a"
      },
      "source": [
        "optimize_knn_macro = {\n",
        "    'selector': [0, 5, 10],\n",
        "    'pca': [5, 10, 20, 30],\n",
        "    'kNN': {\n",
        "        \"kNN\":[i for i in range(1, 51, 2)]\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_knn = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                               my_transformers=transformers, my_classifiers={'kNN':knn}, \n",
        "                               est_values_mapper=optimize_knn_macro, cv=5, scoring='f1_macro')\n",
        "\n",
        "\n",
        "# compute f1-macro\n",
        "knn_macro_big = {k: f1_score(big_test_labels, v, average='macro') for k,v in big_scores_knn['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_knn_macro = max(knn_macro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_knn, opt_knn_macro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-202-57e1582dbb6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m big_scores_knn = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n\u001b[1;32m      9\u001b[0m                                \u001b[0mmy_transformers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_classifiers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'kNN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                est_values_mapper=optimize_knn_macro, cv=5, scoring='f1_macro')\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-176-49022bee57ca>\u001b[0m in \u001b[0;36mrunEstimators\u001b[0;34m(train, test, train_labels, test_labels, my_transformers, my_classifiers, est_values_mapper, cv, scoring, showResults)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0;31m# create gridsearch parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                 \u001b[0mestimator_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetEstDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mest_values_mapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# create Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-176-49022bee57ca>\u001b[0m in \u001b[0;36mgetEstDict\u001b[0;34m(steps, est_values_mapper)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mest_values_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mest_mapper_keys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest_values_mapper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaNus8uYG_7j"
      },
      "source": [
        "####Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YDM-RqL0tuI"
      },
      "source": [
        "est_values_mapper = {\n",
        "    'selector': [0, 5, 10],\n",
        "    'pca': [5, 10, 20, 30],\n",
        "    'dummy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'],\n",
        "    'mlp': {\n",
        "        'hidden_layer_sizes': [(5, ), (10, ), (15, )],\n",
        "        'activation': [\"tanh\", \"relu\"],\n",
        "        'solver': [\"lbfgs\", \"sgd\"],\n",
        "        'max_iter': [40, 80, 120],\n",
        "        'alpha': [0.00001, 0.0001, 0.001],\n",
        "        'learning_rate': [\"constant\", \"invscaling\"]\n",
        "    }\n",
        "}\n",
        "transformers = {\n",
        "    'selector': selector,\n",
        "    'scaler': scaler,\n",
        "    'min_max_scaler': min_max_scaler,\n",
        "    'ros': ros,\n",
        "    'rus': rus,\n",
        "    'pca': pca\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_mlp = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                                 my_transformers=transformers, my_classifiers={'mlpc':mlp}, \n",
        "                                 est_values_mapper=est_values_mapper, cv=5, scoring='f1_macro')\n",
        "\n",
        "\n",
        "# compute f1-macro\n",
        "mlp_macro_big = {k: f1_score(big_test_labels, v, average='macro') for k,v in big_scores_mlp['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_mlp_macro = max(mlp_macro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_mlp, opt_mlp_macro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOX_BgDSE1hh"
      },
      "source": [
        "macros = [(k,v) for k, v in sorted(big_scores_mlp['macro'].items(), key=lambda item: item[1], reverse=True)]\n",
        "print(macros)\n",
        "getResults(big_scores_mlp, macros, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiK526cUHGO3"
      },
      "source": [
        "####Support vector machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhUEjpi71MdC"
      },
      "source": [
        "#####Linear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUu2zuhO8oXS"
      },
      "source": [
        "# est_values_mapper = {\n",
        "#     'selector': [0, 5, 10],\n",
        "#     'pca': [5, 10, 20, 30],\n",
        "#     'svc': {\n",
        "#             'svc__kernel': ['linear', 'rbf', 'poly'],\n",
        "#             'svc__C': [1, 5, 10, 50],\n",
        "#             'svc__gamma': [0.0001, 0.0005, 0.001, 0.005],\n",
        "#             'svc__tol': [1e-3, 1e-4],\n",
        "#             'svc__loss': [\"hinge\", \"squared_hinge\"],\n",
        "#             'svc__degree': [2,3,4]\n",
        "#             }\n",
        "# }\n",
        "# transformers = {\n",
        "#     'selector': selector,\n",
        "#     'scaler': scaler,\n",
        "#     'min_max_scaler': min_max_scaler,\n",
        "#     'ros': ros,\n",
        "#     'rus': rus,\n",
        "#     'pca': pca\n",
        "# }\n",
        "\n",
        "\n",
        "# big_scores_svm = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "#                                  my_transformers=transformers, my_classifiers={'svc':svc}, \n",
        "#                                  est_values_mapper=est_values_mapper, cv=5, scoring='f1_macro')\n",
        "\n",
        "# macros = [(k,v) for k, v in sorted(big_scores_svm['micro'].items(), key=lambda item: item[1], reverse=True)]\n",
        "# print(macros)\n",
        "# getResults(big_scores_svm, macros, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6k5iCvmGh04"
      },
      "source": [
        "###Μετρική απόδοσης f1-micro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tief2c4aHUVh"
      },
      "source": [
        "####Dummy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfiA2tROLy7N"
      },
      "source": [
        "transformers = {\n",
        "    'selector': selector,\n",
        "    'scaler': scaler,\n",
        "    'min_max_scaler': min_max_scaler,\n",
        "    'ros': ros,\n",
        "    'rus': rus,\n",
        "    'pca': pca\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_dummy_micro = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                                       my_transformers=transformers, my_classifiers={'dummy':dummy}, \n",
        "                                       est_values_mapper=est_values_mapper, cv=5, scoring='f1_micro')\n",
        "\n",
        "\n",
        "# compute f1-micro\n",
        "dummy_micro_big = {k: f1_score(big_test_labels, v, average='micro') for k,v in big_scores_dummy_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-macro\n",
        "opt_dummy_micro = max(dummy_micro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_dummy_micro, opt_dummy_micro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC0ByZ51HVc0"
      },
      "source": [
        "####Gaussian Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxWiAsaUL_5z"
      },
      "source": [
        "big_scores_gnb_micro = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                               my_transformers=transformers, my_classifiers={'gnb':gnb}, \n",
        "                               est_values_mapper=est_values_mapper, cv=5, scoring='f1_micro')\n",
        "\n",
        "\n",
        "# compute f1-micro\n",
        "gnb_micro_big = {k: f1_score(big_test_labels, v, average='micro') for k,v in big_scores_gnb_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-micro\n",
        "opt_gnb_micro = max(gnb_micro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_gnb_micro, opt_gnb_micro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7c6jKT5HZA4"
      },
      "source": [
        "####k_Nearest Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRQOQhdxOT6G"
      },
      "source": [
        "optimize_knn_micro = {\n",
        "    'selector': [0, 5, 10],\n",
        "    'pca': [5, 10, 20, 30],\n",
        "    'kNN': {\n",
        "        \"kNN\":[i for i in range(1, 51, 2)]\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_knn_micro = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                               my_transformers=transformers, my_classifiers={'kNN':knn}, \n",
        "                               est_values_mapper=optimize_knn_micro, cv=5, scoring='f1_micro')\n",
        "\n",
        "\n",
        "# compute f1-micro\n",
        "knn_micro_big = {k: f1_score(big_test_labels, v, average='micro') for k,v in big_scores_knn_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-micro\n",
        "opt_knn_micro = max(knn_micro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_knn_micro, opt_knn_micro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oYJqKek7m6f"
      },
      "source": [
        "optimize_knn_micro = {\n",
        "    'selector': [0, 5, 10],\n",
        "    'pca': [5, 10, 20, 30],\n",
        "    'kNN': [5, 7, 9, 11]\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_knn_micro_2 = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                               my_transformers=transformers, my_classifiers={'kNN':knn}, \n",
        "                               est_values_mapper=optimize_knn_micro, cv=5, scoring='f1_micro')\n",
        "micros = [(k,v) for k, v in sorted(big_scores_knn_micro_2['micro'].items(), key=lambda item: item[1], reverse=True)]\n",
        "print(micros)\n",
        "getResults(big_scores_knn_micro_2, micros, big_test, big_test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTalQEFHHbl2"
      },
      "source": [
        "####Multilayer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxyX_40-8TcO"
      },
      "source": [
        "est_values_mapper = {\n",
        "    'selector': [0, 5, 10],\n",
        "    'pca': [5, 10, 20, 30],\n",
        "    'dummy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'],\n",
        "    'mlp': {\n",
        "        'hidden_layer_sizes': [(5, ), (10, ), (15, )],\n",
        "        'activation': [\"tanh\", \"relu\"],\n",
        "        'solver': [\"lbfgs\", \"sgd\"],\n",
        "        'max_iter': [40, 80, 120],\n",
        "        'alpha': [0.00001, 0.0001, 0.001],\n",
        "        'learning_rate': [\"constant\", \"invscaling\"]\n",
        "    }\n",
        "}\n",
        "transformers = {\n",
        "    'selector': selector,\n",
        "    'scaler': scaler,\n",
        "    'min_max_scaler': min_max_scaler,\n",
        "    'ros': ros,\n",
        "    'rus': rus,\n",
        "    'pca': pca\n",
        "}\n",
        "\n",
        "\n",
        "big_scores_mlp_micro = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "                                 my_transformers=transformers, my_classifiers={'mlpc':mlp}, \n",
        "                                 est_values_mapper=est_values_mapper, cv=5, scoring='f1_micro')\n",
        "\n",
        "\n",
        "\n",
        "# compute f1-micro\n",
        "mlp_micro_big = {k: f1_score(big_test_labels, v, average='micro') for k,v in big_scores_mlp_micro['preds'].items()}\n",
        "# get the estimator with the maximum f1-micro\n",
        "opt_mlp_micro = max(mlp_micro_big.items(), key=operator.itemgetter(1))[0]\n",
        "\n",
        "getResults(big_scores_mlp_micro, opt_mlp_micro, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk7BOHRwHcp9"
      },
      "source": [
        "####Support vector machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chhxSLESBnl4"
      },
      "source": [
        "# est_values_mapper = {\n",
        "#     'selector': [0, 5, 10],\n",
        "#     'pca': [5, 10, 20, 30],\n",
        "#     'dummy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'],\n",
        "#     'svc': {'pca__n_components': [100, 150, 200],\n",
        "#               'svc__kernel': ['linear', 'rbf', 'poly'],\n",
        "#               'svc__C': [1, 5, 10, 50],\n",
        "#               'svc__gamma': [0.0001, 0.0005, 0.001, 0.005],\n",
        "#               'svc__tol': [1e-3, 1e-4],\n",
        "#               'svc__loss': [\"hinge\", \"squared_hinge\"],\n",
        "#               'svc__degree': [2,3,4]\n",
        "#             }\n",
        "# }\n",
        "# transformers = {\n",
        "#     'selector': selector,\n",
        "#     'scaler': scaler,\n",
        "#     'min_max_scaler': min_max_scaler,\n",
        "#     'ros': ros,\n",
        "#     'rus': rus,\n",
        "#     'pca': pca\n",
        "# }\n",
        "\n",
        "\n",
        "# big_scores_svm_micro = runEstimators(big_train, big_test, big_train_labels, big_test_labels, \n",
        "#                                  my_transformers=transformers, my_classifiers={'svc':svc}, \n",
        "#                                  est_values_mapper=est_values_mapper, cv=5, scoring='f1_micro')\n",
        "\n",
        "# micros = [(k,v) for k, v in sorted(big_scores_svm_micro['micro'].items(), key=lambda item: item[1], reverse=True)]\n",
        "# print(micros)\n",
        "# getResults(big_scores_svm_micro, micros, big_test, big_test_labels, \"solvent\", \"bankrupt\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}