{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Lab_1.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgM-C62wlQTm"
      },
      "source": [
        "---\n",
        "#Άσκηση 1. Επιβλεπόμενη Μάθηση: Ταξινόμηση\n",
        "---\n",
        "\n",
        "Συνεργάτες:\n",
        "Δούλης Κωνσταντίνος 03116175\n",
        "\n",
        "Καλογερόπουλος Ιωάννης 03116117\n",
        "\n",
        "Κατσίκας Μουρούτσος Γεώργιος 03116132\n",
        "\n",
        "---\n",
        "\n",
        "Mικρό Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik7SPquAmwND"
      },
      "source": [
        "Αρχικά, ενημερώνουμε τις βιβλιοθήκες που θα χρησιμοποιηθούν (έχει προστεθεί στην αρχή του κελιού η magic command %%capture ώστε να μην εμφανίζονται στο stdouput οι πληροφορίες των εγκαταστάσεων, για να είναι πιο ευανάγνωστο):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7_jP0HklpR1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e8e4b81a-8df1-4f13-912a-9f30d534c59e"
      },
      "source": [
        "!pip install --upgrade pip #upgrade pip package installer\n",
        "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
        "!pip install numpy --upgrade #upgrade numpy package\n",
        "!pip install pandas --upgrade #--upgrade #upgrade pandas package\n",
        "!pip install -U tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.2.4)\n",
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (2.1.0)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.19.4-cp36-cp36m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "tensorflow 2.3.1 requires numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.4 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.19.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.19.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.35.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.1)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "  Using cached numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.33.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow) (50.3.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.7.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.6)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.1.1)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.11.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
            "\n",
            "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
            "\n",
            "datascience 0.10.6 requires folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.18.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUYHWBBvjb9w"
      },
      "source": [
        "import warnings \n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9L1ZXDKncGu"
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def download(url, file):\n",
        "    if not os.path.isfile(file):\n",
        "        urlretrieve(url,file)\n",
        "        print(\"File downloaded\")\n",
        "\n",
        "download('http://archive.ics.uci.edu/ml/machine-learning-databases/credit-screening/crx.data', 'crx.data')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuojFZSVqK3y"
      },
      "source": [
        "#Japanese Credit Screening\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8q2QlhnxrYXY"
      },
      "source": [
        "##Πληροφορίες dataset\n",
        "\n",
        "Το dataset που εξετάζουμε παρέχει πληροφορίες σχετικά με άτομα στα οποία χορηγήθηκε ή όχι πίστωση από Ιαπωνική εταιρεία. Τα δεδομένα παράχθηκαν ύστερα από σχετικές ερωτήσεις στους πελάτες τις εταιρείας."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAMbop8Pr0B8"
      },
      "source": [
        "##Περιγραφή χαρακτηριστικών του dataset\n",
        "\n",
        "To dataset διαθέτει <b>690 δείγματα</b>, με το καθένα από αυτά να διαθέτει <b>15 χαρακτηριστικά συν 1 που είναι η κλάση</b>.\n",
        "\n",
        "Το κάθε δείγμα αντιστοιχεί σε μία γραμμή του αρχείου, ενώ η κάθε στήλη σε ένα χαρακτηριστικό του. <b>Η τελευταία στήλη δηλώνει την κλάση που ανήκει το δείγμα</b>. Συγκεκριμένα, το σύμβολο <b>\"+\"</b> δηλώνει ότι η πίστωση <b>εγκρίθηκε</b>, ενώ το σύμβολο <b>\"-\"</b> δηλώνει ότι <b>δεν εγκρίθηκε</b>.\n",
        "Επομένως, η δομή του αρχείου είναι κατάλληλη για να ξεκινήσουμε την προεπεξεργασία του dataset.\n",
        "\n",
        "Για λόγους απορήτου τα attribute names και values έχουν αντικατασταθεί με τυχαία σύμβολα, που δεν παρέχουν κάποια σχετική πληροφορία σχετικά με το τι περιγράφουν.\n",
        "\n",
        "Το είδος των χαρακτηριστικών φαίνεται παρακάτω:\n",
        "\n",
        "| Attribute | Type of Data                                 | Description    |\n",
        "|-----------|----------------------------------------------|----------------|\n",
        "| A1        | b, a.                                        | Male           |\n",
        "| A2        | continuous.                                  | Age            |\n",
        "| A3        | continuous.                                  | Debt           |\n",
        "| A4        | u, y, l, t.                                  | Married        |\n",
        "| A5        | g, p, gg.                                    | BankCustomer   |\n",
        "| A6        | c, d, cc, i, j, k, m, r, q, w, x, e, aa, ff. | EducationLevel |\n",
        "| A7        | v, h, bb, j, n, z, dd, ff, o.                | Ethnicity      |\n",
        "| A8        | continuous.                                  | YearsEmployed  |\n",
        "| A9        | t, f.                                        | PriorDefault   |\n",
        "| A10       | t, f.                                        | Employed       |\n",
        "| A11       | continuous.                                  | CreditScore    |\n",
        "| A12       | t, f.                                        | DriversLicense |\n",
        "| A13       | g, p, s.                                     | Citizen        |\n",
        "| A14       | continuous.                                  | ZipCode        |\n",
        "| A15       | continuous.                                  | Income         |\n",
        "| A16       | +,-                                          | Approved (CLASS ATTRIBUTE)       |\n",
        "\n",
        "\n",
        "\n",
        "* Τα χαρακτηριστικά που έχουν continuous τιμές αποτελουν <b>διατεταγμένα </b>χαρακτηριστικά, ενώ αυτά που έχουν διακριτές τιμές, δηλαδή σύμβολα, <b>μη διατεταγμένα</b>.\n",
        "\n",
        "* Στο dataset <b>δεν</b> υπάρχουν επικεφαλίδες, καθώς ούτε και αρίθμηση γραμμών.\n",
        "\n",
        "* Οι ετικέτες και οι σημασίες τους είναι:\n",
        "    * \"+\": Εγκρίθηκε η πίστωση\n",
        "    * \"-\": Απορρίφθηκε η πίστωση\n",
        "\n",
        "    Οι ετικέτες αυτές βρίσκονται στην τελευταία στήλη, ενώ οι τιμές τους θα πρέπει να μετατραπούν όπως φαίνεται παρακάτω:\n",
        "    * \"+\" -> 1\n",
        "    * \"-\" -> 0\n",
        "\n",
        "* <b>Υπάρχουν απουσιάζουσες τιμές</b>. Συγκεκριμένα, 37 δείγματα (5%) του συνολικού αριθμού δειγμάτων παρουσιάζουν μία ή παραπάνω απώλειες δεδομένων. \n",
        "\n",
        "Όλα τα παραπάνω φαίνονται παρακάτω:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW4faeHk8TKM"
      },
      "source": [
        "##Προεπεξεργασία των δεδομένων\n",
        "Aρχικά διαβάζουμε το αρχείο <b>crx.data</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNOetXVa77M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e49b727-e0c9-449c-8616-76f271bc7d2f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"crx.data\", header=None)\n",
        "# print the five first samples\n",
        "print(df[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14 15\n",
            "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0  +\n",
            "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560  +\n",
            "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824  +\n",
            "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3  +\n",
            "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0  +\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdZtApI_9Fab"
      },
      "source": [
        "###Αντιστοίχιση κλάσεων\n",
        "Παρατηρούμε, όπως ειπώθηκε και παραπάνω, ότι οι κλάσεις δηλώνονται στην τελευταία στήλη με τα σύμβολα +/-. \n",
        "\n",
        "Μετατρέπουμε τα \"+\" σε 1 και τα \"-\" σε 0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3M1H7ST9O9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e6870a-d9f7-40d2-92a9-1dd5cf967f49"
      },
      "source": [
        "# create mapper for each symbol\n",
        "class_mapper = {\"+\": 1, \"-\": 0}\n",
        "# since these symbols occur only on the last column we dont specify the column\n",
        "df = df.replace(class_mapper)\n",
        "print(df[:5])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0      1      2  3  4  5  6     7  8  9   10 11 12     13   14  15\n",
            "0  b  30.83  0.000  u  g  w  v  1.25  t  t   1  f  g  00202    0   1\n",
            "1  a  58.67  4.460  u  g  q  h  3.04  t  t   6  f  g  00043  560   1\n",
            "2  a  24.50  0.500  u  g  q  h  1.50  t  f   0  f  g  00280  824   1\n",
            "3  b  27.83  1.540  u  g  w  v  3.75  t  t   5  t  g  00100    3   1\n",
            "4  b  20.17  5.625  u  g  w  v  1.71  t  f   0  f  s  00120    0   1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p35rb4qAuRYR"
      },
      "source": [
        "###Χειρισμός απουσιάζουσων τιμών χαρακτηριστικών\n",
        "\n",
        "Στη συνέχεια, θα εντοπίσουμε τις απουσιάζουσες τιμές. Αυτές δηλώνονται στο dataset με τον χαρακτήρα \"?\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4snaGwf-KV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e0e9a6-58b0-4c8b-b3b1-b0c932afc9ba"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# replace \"?\" with np.NaN\n",
        "df.replace('?',np.NaN,inplace=True)\n",
        "\n",
        "# calculate the number of samples with at least one missing attribute\n",
        "# df.isna() is the mask of df where each element is True if is NaN\n",
        "# s is the length of the list of samples that have at least one True(NaN)\n",
        "num_of_incomplete_samples = len([i for i in np.array(df.isna()) if True in i])\n",
        "print(\"The samples of the dataset that have at least one missing attribute are \", num_of_incomplete_samples)\n",
        "print(\"Which means that the \", num_of_incomplete_samples*100/df.shape[0], \"% of the samples have missing values.\", sep=\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The samples of the dataset that have at least one missing attribute are  37\n",
            "Which means that the 5.36231884057971% of the samples have missing values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdHVwDC30eRv"
      },
      "source": [
        "Από τα παραπάνω βλέπουμε ότι αν θέλαμε να αγνοήσουμε τα δείγματα που έχουν missing values θα έπρεπε να \"πετάξουμε\" το 5% των δειγμάτων, αριθμός που <b>θα επηρέαζε αρνητικά τα αποτελέσματα</b>.\n",
        "\n",
        "Προκειμένου να εξετάσουμε αν οι περισσότερες τιμές που λείπουν προέρχονται απο συγκεκριμένα (λίγα) χαρακτηριστικά (και αν αυτά έχουν ίσως και μηδενική διακύμανση, δηλαδή  χαρακτηριστικά με σταθερές τιμές), οπότε θα μπορούσαμε να τα αγνοήσουμε, εκτελούμε:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FunpidqDDNRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986e24ea-d5a8-4da1-8ad8-37529bd1f0c6"
      },
      "source": [
        "print(df.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(690, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkPRNBdi32T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666c3d85-92a5-4d02-aff5-ac099b33e53b"
      },
      "source": [
        "# the list of the number of missing values for each attribute occurs by \n",
        "# summing the elements of the inverse of df, without df's last column.\n",
        "# df's last column is the class attribute and it is alwasy present.\n",
        "incomplete_attrs = [sum(i) for i in np.array(df.isna())[:,:df.shape[1]-1].T]\n",
        "print(\"For each attribute of the dataset, the number of the missing values is\")\n",
        "print(incomplete_attrs)\n",
        "# print(sum(incomplete_attrs))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For each attribute of the dataset, the number of the missing values is\n",
            "[12, 12, 0, 6, 6, 9, 9, 0, 0, 0, 0, 0, 0, 13, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fXm2-b_32zj"
      },
      "source": [
        "Βλέπουμε, επομένως, ότι από τα 690 δείγματα το πολύ σε 13 από αυτά ένα χαρακτηριστικό δεν έχει τιμές. Επομένως, δεν έχει νόημα να αγνοήσουμε το χαρακτηριστικό αυτό, ακόμα και αν είναι αυτό με τις περισσότερες ελλείψεις, αφού αυτές είναι πολύ λίγες και θα χάναμε πολύ πληροφορία.\n",
        "\n",
        "Τελικά η πιο συμφέρουσα λύση είναι να αντικαταστήσουμε τα NaN με τιμές που προκύπτουν με βάση τις τιμές των χαρακτηριστικών σε προηγούμενα δείγματα. <u>Συγκεκριμένα, αντικαθιστούμε τα NaN με την τιμή του χαρακτηριστικού που εμφανίζεται πιο συχνά</u>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VncSjkCO0FZv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f72fd1-040c-4d20-e771-ac768fe849a1"
      },
      "source": [
        "# create imputer that will replace Nan with the most frequent value\n",
        "imp=SimpleImputer(missing_values=np.NaN,strategy=\"most_frequent\")\n",
        "idf=pd.DataFrame(imp.fit_transform(df))\n",
        "idf.columns=df.columns\n",
        "idf.index=df.index\n",
        "print(idf[:5])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0      1      2  3  4  5  6     7  8  9  10 11 12     13   14 15\n",
            "0  b  30.83      0  u  g  w  v  1.25  t  t  1  f  g  00202    0  1\n",
            "1  a  58.67   4.46  u  g  q  h  3.04  t  t  6  f  g  00043  560  1\n",
            "2  a  24.50    0.5  u  g  q  h   1.5  t  f  0  f  g  00280  824  1\n",
            "3  b  27.83   1.54  u  g  w  v  3.75  t  t  5  t  g  00100    3  1\n",
            "4  b  20.17  5.625  u  g  w  v  1.71  t  f  0  f  s  00120    0  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iIfeNp-F20h"
      },
      "source": [
        "Οι κλάσεις βρίσκονται στην τελευταία στήλη του συνόλου δεδομένων. Οπότε για να βρούμε το πλήθος τους και τα ποσοστά δειγμάτων τους επί του συνόλου:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc32MgrVGpPE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc29fac8-24a6-47ff-c25f-6d48f695ba9f"
      },
      "source": [
        "num_of_rows = idf.shape[0]\n",
        "num_of_attrs = idf.shape[1] - 1 #remove one element because of the class attribute\n",
        "\n",
        "# get labesl and features\n",
        "labels_df = idf.iloc[:, [num_of_attrs]] # τα labels είναι στην τελευταία κολώνα\n",
        "features_df = idf.iloc[:, 0:num_of_attrs]  # τα features είναι όλες οι προηγούμενες κολώνες\n",
        "\n",
        "labels = labels_df.values.reshape(num_of_rows,)\n",
        "features = features_df.values\n",
        "# convert to int\n",
        "labels.astype(int)\n",
        "labels = np.array(labels, dtype='int64')\n",
        "# print(labels.shape)\n",
        "\n",
        "# find how many of each class\n",
        "bin_count = np.bincount(labels)\n",
        "print (\"frequencies:\", bin_count)\n",
        "print(\"The percentage of 0's in data: \", bin_count[0]*100/sum(bin_count), \"%.\")\n",
        "print(\"The percentage of 1's in data: \", bin_count[1]*100/sum(bin_count), \"%.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequencies: [383 307]\n",
            "The percentage of 0's in data:  55.507246376811594 %.\n",
            "The percentage of 1's in data:  44.492753623188406 %.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gW0hDxy-LS28"
      },
      "source": [
        "Καταλήγουμε, λοιπόν, ότι τα ποσοστά είναι περίπου 55.5% για την κλάση 0 και 44.5% για την κλάση 1. Επομένως, το dataset είναι <b>ισορροπημένο</b>."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqMTLEANH4ST",
        "outputId": "afd89cd9-8997-4c96-b799-e998088f42f4"
      },
      "source": [
        "# print(labels[:5])\n",
        "print(features.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(690, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe7knthjExus"
      },
      "source": [
        "###Χειρισμός κατηγορικών χαρακτηριστικών\n",
        "Το τελευταίο βήμα πριν τον διαχωρισμό του dataset είναι να μετατρέψουμε τα μη διατεταγμένα χαρακτηριστικά  με m τιμές σε m binary χαρακτηριστικά από τα οποία μόνο ένα είναι ενεργό κάθε φορά:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg0Co3aQHerv",
        "outputId": "8587f500-e9af-4607-f796-412bad3f25e0"
      },
      "source": [
        "# μετατρέπουμε σε dataframe και τυπώνουμε\n",
        "mtdf = pd.DataFrame(features)\n",
        "\n",
        "# οι κολόνες 1 και 4 έχουν κατηγορικές μεταβλητές. \n",
        "# Με την \"get_dummies\" κάνουμε τη μετατροπή σε binary χαρακτηριστικά που περιγράψαμε\n",
        "dummies = pd.get_dummies(mtdf, columns=[0,3,4,5,6,8,9,11,12])\n",
        "# print(dummies)\n",
        "\n",
        "# Μετατρέπουμε σε αριθμητικές τιμές (pd.to_numeric) και σε numpy array (.values)\n",
        "all_data = dummies.apply(pd.to_numeric).values\n",
        "print(all_data.shape)\n",
        "# print(all_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(690, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYmrUc66NnUJ"
      },
      "source": [
        "Βλέπουμε, όπως αναμενόταν, ότι το πλήθος των χαρακτηριστικών φαίνεται έχει πλέον αυξηθεί.\n",
        "Στην πραγματικότητα παραμένουν τα ίδια χαρακτηριστικά, ωστόσο για κάθε κατηγορικό χαρακτηριστικό Κ, δημιουργούμε το χαρακτηριστικό έχειΚ_V για κάθε δυνατή τιμή του K, V, το οποίο έχει τιμή 1 μόνο αν το συγκεκριμένο δείγμα έχει την τιμή V για το χαρακτηριστικό αυτό."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yni1P1F6D-89"
      },
      "source": [
        "##Διαχωρισμός του dataset\n",
        "Διαχωρίζουμε το dataset σε train και test set, χρησιμοποιώντας το 80% των δεδομένων για το training και το 20% για το testing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hze8obkLEg0K"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "train, test, train_labels, test_labels = train_test_split(all_data, labels, test_size=0.2, random_state=78)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo0VGdmqlTjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5b28d6b-ac53-4fcd-895a-a02174d87892"
      },
      "source": [
        "from collections import defaultdict\n",
        "# just for checking...\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "check = defaultdict(int)\n",
        "for i in range(0,len(train_labels)):\n",
        "    check['pos_train'] += train_labels[i] == 1\n",
        "    check['neg_train'] += train_labels[i] == 0\n",
        "    \n",
        "\n",
        "# for i in range(0,len(test_labels)):\n",
        "#     check['pos_test'] += test_labels[i] == 1\n",
        "#     check['neg_test'] += test_labels[i] == 0\n",
        "    \n",
        "# print(check)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(552, 46)\n",
            "(138, 46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6hs-A0Q5a1j"
      },
      "source": [
        "##Ορισμός μετασχηματιστών"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5QAIBec92x_"
      },
      "source": [
        "###Variance Threshold\n",
        "\n",
        "Παρακάτω υλοποιείται η συνάρτηση που αρχικοποιεί selector Variance Threshold, με κατόφλι που δίνεται από το όρισμα threshold"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV9JVV6X68pn"
      },
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "def Variance_Threshold(data, threshold=0):\n",
        "    # αρχικοποιούμε έναν selector\n",
        "    train, test, train_labels, test_labels = data\n",
        "    selector = VarianceThreshold(threshold = threshold)\n",
        "    train_reduced = selector.fit_transform(train)\n",
        "    test_reduced = selector.transform(test)\n",
        "\n",
        "    return (train_reduced, test_reduced, train_labels, test_labels)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug166UU_88B1"
      },
      "source": [
        "###PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHoEFrk689m2"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def PCA_selector(data, n):\n",
        "    \"\"\"\n",
        "    Function that creates a PCA selector that learns the train data\n",
        "    and transforms train and test data.\n",
        "    \"\"\"\n",
        "    train, test, train_labels, test_labels = data\n",
        "    # αρχικοποιούμε τον selector\n",
        "    pca = PCA(n_components=n)\n",
        "    trainPCA = pca.fit_transform(train)\n",
        "    testPCA = pca.transform(test)\n",
        "\n",
        "    return (trainPCA, testPCA, train_labels, test_labels)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2gtTLCt9zko"
      },
      "source": [
        "###Κανονικοποίηση"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIz6YOlw-KEu"
      },
      "source": [
        "from scipy import stats as st\n",
        "\n",
        "def StandarizerTransformer(data, method):\n",
        "    \"\"\"\n",
        "    Function that standarizes the data using two different methods.\n",
        "    minmax and zscore.    \n",
        "    \"\"\"\n",
        "    train, test, train_labels, test_labels = data\n",
        "    if method==\"zscore\":\n",
        "        std_train = st.zscore(train)\n",
        "    elif method==\"minmax\":\n",
        "        std_train = (train - np.min(train) )/ (np.max(train) - np.min(train))\n",
        "    else:\n",
        "        std_train = train\n",
        "    return (std_train, test, train_labels, test_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1qXIMpk_x--"
      },
      "source": [
        "###Εξισορρόπηση dataset - Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QaC5aRuVZlL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f7a7de6-613b-4b74-dfe8-9efd92b7674c"
      },
      "source": [
        "!pip install six"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLjaejVoANn9"
      },
      "source": [
        "# from sklearn.externals import six\n",
        "# from imblearn.over_sampling import RandomOverSampler\n",
        "# from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "def sampling(data, method):\n",
        "    train, test, train_labels, test_labels = data\n",
        "    if method == \"over\":\n",
        "        ros = RandomOverSampler()\n",
        "        # mlb = MultiLabelBinarizer().fit(['0', '1', '2', '3', '4'])\n",
        "        # tmplabels = np.asarray(mlb.inverse_transform(C_trainDataTargets)).flatten()\n",
        "        train_resampled, train_labels_resampled = ros.fit_sample(train,train_labels)\n",
        "        trainTargets_resampled = mlb.transform(trainTargets_resampled)\n",
        "    elif method == 'under':\n",
        "        ros = RandomUnderSampler()\n",
        "        # mlb = MultiLabelBinarizer().fit(['0', '1', '2', '3', '4'])\n",
        "        # tmplabels = np.asarray(mlb.inverse_transform(C_trainDataTargets)).flatten()\n",
        "        train_resampled, train_labels_resampled = ros.fit_sample(train,train_labels)\n",
        "        trainTargets_resampled = mlb.transform(trainTargets_resampled)\n",
        "    \n",
        "    return (train_resampled, test, train_labels_resampled, test_labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvnXfmKlVr06"
      },
      "source": [
        "##Ορισμός ταξινομητών"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIZND57tVwK0"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "def createClassifier(classifier, argument=5):\n",
        "\n",
        "    if classifier == 'dummy':\n",
        "        clf = DummyClassifier(strategy=argument)\n",
        "    elif classifier == 'gnb':\n",
        "        clf = GaussianNB()\n",
        "    elif classifier == 'knn':\n",
        "        clf = KNeighborsClassifier(n_neighbors=argument)\n",
        "    \n",
        "    return clf"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aZdMfMTZGUE"
      },
      "source": [
        "##Ορισμός Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCPJcKB9ZJm0"
      },
      "source": [
        "def Pipeline (data, steps):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        * data: (train, train_labels, test, test_labels)\n",
        "        * steps: list of tuples, where each tuple's 1st el \n",
        "        is the transformer/classifier and the 2nd el\n",
        "        is the arguments of the function for the\n",
        "        transformer/classifier\n",
        "    \"\"\"\n",
        "\n",
        "    mapper = {\n",
        "        'selector': Variance_Threshold,\n",
        "        'scaler': StandarizerTransformer,\n",
        "        'sampler': sampling,\n",
        "        'pca': PCA_selector,\n",
        "        'kNN': createClassifier,\n",
        "        'dummy': createClassifier\n",
        "    }\n",
        "\n",
        "    classifiers = set(['kNN', 'uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'])\n",
        "\n",
        "    for step in steps:\n",
        "        if step[0] not in classifiers:\n",
        "            # update data\n",
        "            data = mapper[step[0]](step[1])\n",
        "\n",
        "        else:\n",
        "            # return model\n",
        "            return (data, createClassifier(step[0], step[1]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgcYh1tPj6HE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41dd4d9-5069-4a2f-a227-74ac08053afd"
      },
      "source": [
        "!pip install --upgrade imbalanced-learn"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.23.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.17.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZUXF8pHpiHE",
        "outputId": "86711de2-6f3a-4b7e-f5a6-c33b95227cb4"
      },
      "source": [
        "train_variance = train.var(axis=0)\n",
        "print(train_variance)\n",
        "print(np.max(train_variance))\n",
        "print(train_variance.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.37390925e+02 2.50808996e+01 1.13895028e+01 2.54195514e+01\n",
            " 3.14871660e+04 1.31891623e+07 2.09564036e-01 2.09564036e-01\n",
            " 1.80831233e-03 1.76157845e-01 1.75170001e-01 1.76157845e-01\n",
            " 1.80831233e-03 1.75170001e-01 7.18303665e-02 1.69105099e-01\n",
            " 5.46103760e-02 3.99305556e-02 3.65961720e-02 6.56604442e-02\n",
            " 8.08883375e-02 1.60385161e-02 6.72127704e-02 5.62086484e-02\n",
            " 9.54598561e-02 3.61006091e-03 8.23750263e-02 5.62086484e-02\n",
            " 8.08883375e-02 1.07514178e-02 7.33564377e-02 1.61730729e-01\n",
            " 1.25203476e-02 5.40524575e-03 1.80831233e-03 2.42438563e-01\n",
            " 1.07514178e-02 2.49051539e-01 2.49051539e-01 2.45746692e-01\n",
            " 2.45746692e-01 2.47948829e-01 2.47948829e-01 8.53287125e-02\n",
            " 8.97592418e-03 7.78952689e-02]\n",
            "13189162.332936361\n",
            "(46,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY-rUXmmqO6t",
        "outputId": "eb3b42b1-5fa5-481a-9ad5-07a210c95fb9"
      },
      "source": [
        "for sample in train:\n",
        "    print(sample[5])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n",
            "9.0\n",
            "0.0\n",
            "500.0\n",
            "1000.0\n",
            "0.0\n",
            "6.0\n",
            "1.0\n",
            "18.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "2079.0\n",
            "15.0\n",
            "108.0\n",
            "0.0\n",
            "15.0\n",
            "0.0\n",
            "126.0\n",
            "19.0\n",
            "7.0\n",
            "2.0\n",
            "1210.0\n",
            "27.0\n",
            "0.0\n",
            "0.0\n",
            "38.0\n",
            "20.0\n",
            "0.0\n",
            "0.0\n",
            "173.0\n",
            "0.0\n",
            "316.0\n",
            "2197.0\n",
            "3000.0\n",
            "0.0\n",
            "21.0\n",
            "0.0\n",
            "18.0\n",
            "2000.0\n",
            "0.0\n",
            "9800.0\n",
            "0.0\n",
            "1.0\n",
            "500.0\n",
            "0.0\n",
            "0.0\n",
            "196.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "50.0\n",
            "0.0\n",
            "456.0\n",
            "0.0\n",
            "1200.0\n",
            "3.0\n",
            "500.0\n",
            "67.0\n",
            "475.0\n",
            "0.0\n",
            "16.0\n",
            "283.0\n",
            "300.0\n",
            "0.0\n",
            "98.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1000.0\n",
            "500.0\n",
            "0.0\n",
            "1210.0\n",
            "0.0\n",
            "1000.0\n",
            "0.0\n",
            "400.0\n",
            "540.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "50.0\n",
            "28.0\n",
            "1.0\n",
            "0.0\n",
            "3.0\n",
            "540.0\n",
            "0.0\n",
            "200.0\n",
            "108.0\n",
            "610.0\n",
            "1.0\n",
            "300.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "1430.0\n",
            "0.0\n",
            "1187.0\n",
            "1300.0\n",
            "0.0\n",
            "200.0\n",
            "809.0\n",
            "0.0\n",
            "251.0\n",
            "321.0\n",
            "2.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "23.0\n",
            "2.0\n",
            "0.0\n",
            "0.0\n",
            "100.0\n",
            "2100.0\n",
            "109.0\n",
            "0.0\n",
            "40.0\n",
            "600.0\n",
            "237.0\n",
            "300.0\n",
            "6.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "2279.0\n",
            "0.0\n",
            "120.0\n",
            "20.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "350.0\n",
            "0.0\n",
            "50000.0\n",
            "154.0\n",
            "150.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1260.0\n",
            "4.0\n",
            "300.0\n",
            "687.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "1249.0\n",
            "50.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "51100.0\n",
            "5.0\n",
            "17.0\n",
            "1000.0\n",
            "0.0\n",
            "3000.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "246.0\n",
            "228.0\n",
            "1.0\n",
            "99.0\n",
            "4.0\n",
            "14.0\n",
            "800.0\n",
            "560.0\n",
            "13.0\n",
            "0.0\n",
            "247.0\n",
            "12.0\n",
            "948.0\n",
            "1.0\n",
            "204.0\n",
            "4.0\n",
            "22.0\n",
            "32.0\n",
            "0.0\n",
            "824.0\n",
            "0.0\n",
            "0.0\n",
            "1391.0\n",
            "100.0\n",
            "0.0\n",
            "6.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "5860.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "2184.0\n",
            "0.0\n",
            "0.0\n",
            "3000.0\n",
            "18027.0\n",
            "55.0\n",
            "0.0\n",
            "1058.0\n",
            "0.0\n",
            "0.0\n",
            "18.0\n",
            "837.0\n",
            "857.0\n",
            "17.0\n",
            "284.0\n",
            "0.0\n",
            "25.0\n",
            "537.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "2.0\n",
            "0.0\n",
            "0.0\n",
            "2283.0\n",
            "0.0\n",
            "1004.0\n",
            "500.0\n",
            "0.0\n",
            "0.0\n",
            "1000.0\n",
            "20.0\n",
            "347.0\n",
            "4.0\n",
            "500.0\n",
            "0.0\n",
            "0.0\n",
            "87.0\n",
            "0.0\n",
            "179.0\n",
            "4071.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "5.0\n",
            "200.0\n",
            "351.0\n",
            "4000.0\n",
            "1.0\n",
            "27.0\n",
            "6.0\n",
            "960.0\n",
            "0.0\n",
            "99.0\n",
            "639.0\n",
            "7059.0\n",
            "0.0\n",
            "1097.0\n",
            "560.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "26726.0\n",
            "350.0\n",
            "587.0\n",
            "551.0\n",
            "3000.0\n",
            "278.0\n",
            "0.0\n",
            "0.0\n",
            "8000.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "204.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "340.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "300.0\n",
            "8.0\n",
            "690.0\n",
            "44.0\n",
            "0.0\n",
            "6.0\n",
            "1.0\n",
            "0.0\n",
            "375.0\n",
            "1655.0\n",
            "0.0\n",
            "200.0\n",
            "0.0\n",
            "918.0\n",
            "0.0\n",
            "0.0\n",
            "1110.0\n",
            "53.0\n",
            "0.0\n",
            "0.0\n",
            "769.0\n",
            "134.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "678.0\n",
            "58.0\n",
            "0.0\n",
            "11202.0\n",
            "245.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "300.0\n",
            "4500.0\n",
            "2690.0\n",
            "750.0\n",
            "1.0\n",
            "1270.0\n",
            "3552.0\n",
            "35.0\n",
            "60.0\n",
            "258.0\n",
            "0.0\n",
            "21.0\n",
            "6590.0\n",
            "286.0\n",
            "730.0\n",
            "0.0\n",
            "0.0\n",
            "1212.0\n",
            "0.0\n",
            "1000.0\n",
            "67.0\n",
            "70.0\n",
            "0.0\n",
            "3.0\n",
            "0.0\n",
            "1065.0\n",
            "0.0\n",
            "68.0\n",
            "0.0\n",
            "0.0\n",
            "7544.0\n",
            "0.0\n",
            "560.0\n",
            "0.0\n",
            "0.0\n",
            "8.0\n",
            "0.0\n",
            "367.0\n",
            "444.0\n",
            "0.0\n",
            "3.0\n",
            "394.0\n",
            "150.0\n",
            "0.0\n",
            "0.0\n",
            "1704.0\n",
            "5298.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "13212.0\n",
            "500.0\n",
            "1400.0\n",
            "0.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "1332.0\n",
            "1.0\n",
            "3065.0\n",
            "827.0\n",
            "150.0\n",
            "0.0\n",
            "90.0\n",
            "0.0\n",
            "0.0\n",
            "200.0\n",
            "0.0\n",
            "0.0\n",
            "4.0\n",
            "1.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "444.0\n",
            "582.0\n",
            "5800.0\n",
            "16.0\n",
            "0.0\n",
            "1.0\n",
            "5.0\n",
            "0.0\n",
            "28.0\n",
            "105.0\n",
            "1.0\n",
            "0.0\n",
            "500.0\n",
            "4000.0\n",
            "5000.0\n",
            "0.0\n",
            "1.0\n",
            "2.0\n",
            "396.0\n",
            "1062.0\n",
            "5.0\n",
            "0.0\n",
            "140.0\n",
            "742.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "2732.0\n",
            "15000.0\n",
            "0.0\n",
            "1583.0\n",
            "1602.0\n",
            "2206.0\n",
            "1.0\n",
            "2503.0\n",
            "0.0\n",
            "0.0\n",
            "8851.0\n",
            "2200.0\n",
            "600.0\n",
            "501.0\n",
            "1.0\n",
            "59.0\n",
            "456.0\n",
            "0.0\n",
            "892.0\n",
            "10.0\n",
            "0.0\n",
            "0.0\n",
            "314.0\n",
            "0.0\n",
            "0.0\n",
            "10.0\n",
            "2000.0\n",
            "113.0\n",
            "0.0\n",
            "117.0\n",
            "0.0\n",
            "1200.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "10.0\n",
            "0.0\n",
            "0.0\n",
            "1000.0\n",
            "184.0\n",
            "4607.0\n",
            "0.0\n",
            "990.0\n",
            "0.0\n",
            "713.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "567.0\n",
            "0.0\n",
            "2.0\n",
            "100.0\n",
            "6700.0\n",
            "1000.0\n",
            "327.0\n",
            "11.0\n",
            "1.0\n",
            "33.0\n",
            "2000.0\n",
            "5.0\n",
            "0.0\n",
            "10.0\n",
            "158.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "141.0\n",
            "19.0\n",
            "0.0\n",
            "375.0\n",
            "400.0\n",
            "0.0\n",
            "0.0\n",
            "2384.0\n",
            "0.0\n",
            "1465.0\n",
            "0.0\n",
            "4000.0\n",
            "2010.0\n",
            "80.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "484.0\n",
            "6.0\n",
            "0.0\n",
            "1.0\n",
            "2510.0\n",
            "0.0\n",
            "0.0\n",
            "44.0\n",
            "2072.0\n",
            "0.0\n",
            "5552.0\n",
            "0.0\n",
            "0.0\n",
            "1.0\n",
            "150.0\n",
            "5124.0\n",
            "0.0\n",
            "4700.0\n",
            "0.0\n",
            "2.0\n",
            "1000.0\n",
            "2954.0\n",
            "500.0\n",
            "3.0\n",
            "0.0\n",
            "0.0\n",
            "3065.0\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "20.0\n",
            "0.0\n",
            "0.0\n",
            "5.0\n",
            "200.0\n",
            "6.0\n",
            "130.0\n",
            "221.0\n",
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBfz8J6Os_9I",
        "outputId": "064450a1-5535-43e0-89c7-bae169437dad"
      },
      "source": [
        "t = [1,2,3,4,5]\n",
        "for w in range(0,len(t)):\n",
        "    for i in range(0,w):\n",
        "        print(t[i:w])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1]\n",
            "[1, 2]\n",
            "[2]\n",
            "[1, 2, 3]\n",
            "[2, 3]\n",
            "[3]\n",
            "[1, 2, 3, 4]\n",
            "[2, 3, 4]\n",
            "[3, 4]\n",
            "[4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN9eOtFTt3qu",
        "outputId": "6d49bc4a-1392-4c3b-c00c-91e0fc191be7"
      },
      "source": [
        "sel = [True, False]\n",
        "scal = [True, False]\n",
        "_pca = [True, False]\n",
        "for si in sel:\n",
        "    for scali in scal:\n",
        "        for pcai in _pca:\n",
        "            if si: print(\"si\", end=\"\\t\")\n",
        "            if scali: print(\"scali\", end=\"\\t\")\n",
        "            if pcai: print(\"pcai\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "si\tscali\tpcai\n",
            "si\tscali\tsi\tpcai\n",
            "si\tscali\tpcai\n",
            "scali\tpcai\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmD18iivv6_8",
        "outputId": "e25a70be-6f97-46e5-9481-ca1368ac79ce"
      },
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def get_transformations(my_list):\n",
        "    sublist = []\n",
        "    for i in range(0, len(my_list)+1):\n",
        "        temp = [list(x) for x in combinations(my_list, i)]  #get the combinations with i elements\n",
        "        if not (('scaler' in temp and 'min_max_scaler') or ('ros' in temp and 'rus' in temp)):\n",
        "            sublist.extend(temp)    #and add to initial list\n",
        "    return sublist\n",
        "\n",
        "\n",
        "\n",
        "trans = ['selector', 'scaler', 'sampler', 'pca']\n",
        "print(get_transformations(trans))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[], ['selector'], ['scaler'], ['sampler'], ['pca'], ['selector', 'scaler'], ['selector', 'sampler'], ['selector', 'pca'], ['scaler', 'sampler'], ['scaler', 'pca'], ['sampler', 'pca'], ['selector', 'scaler', 'sampler'], ['selector', 'scaler', 'pca'], ['selector', 'sampler', 'pca'], ['scaler', 'sampler', 'pca'], ['selector', 'scaler', 'sampler', 'pca']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgGZHP5rzSuA",
        "outputId": "c96aac15-a66d-4442-cef4-65d00a16b9d7"
      },
      "source": [
        "a = {1:11, 2:22}\n",
        "if 1 in a: print(a.keys())\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys([1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5l4kqHEiVaf"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import neighbors\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.preprocessing import StandardScaler # φέρνουμε τον StandarScaler ως transformer που έχει .transform kai ΄όχι ως scale()\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import preprocessing\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "\n",
        "\n",
        "selector = VarianceThreshold()\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "scaler = StandardScaler()\n",
        "ros = RandomOverSampler()\n",
        "rus = RandomUnderSampler()\n",
        "pca = PCA()\n",
        "dummy = DummyClassifier()\n",
        "gnb = GaussianNB()\n",
        "knn = neighbors.KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = 1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή\n",
        "\n",
        "\n",
        "vthresholds = [0, 1000, 10000, 1000000] #προσαρμόζουμε τις τιμές μας στο variance που παρατηρήσαμε\n",
        "scalers = [None, min_max_scaler, scaler]\n",
        "samplers = [None, ros, rus]\n",
        "num_n_components = [10, 20, 30, 40, 50, 60]\n",
        "\n",
        "k = [1, 6] # η υπερπαράμετρος του ταξινομητή\n",
        "scoring = ['f1_macro', 'f1_micro']\n",
        "\n",
        "transformers = {'selector': selector,\n",
        "         'scaler': scaler,\n",
        "         'min_max_scaler': min_max_scaler,\n",
        "         'ros': ros,\n",
        "         'rus': rus,\n",
        "         'pca': pca\n",
        "        }\n",
        "\n",
        "classifiers = {\n",
        "    'dummy': dummy,\n",
        "    'gnb': gnb,\n",
        "    'knn': knn\n",
        "\n",
        "}\n",
        "\n",
        "est_mapper_keys = {\n",
        "    'selector': 'selector__threshold',\n",
        "    'pca': 'pca__n_components',\n",
        "    'dummy': 'dummy__strategy',\n",
        "    'knn': 'kNN__n_neighbors'\n",
        "}\n",
        "\n",
        "\n",
        "est_values_mapper = {\n",
        "    'selector': [0, 1000, 10000, 1000000],\n",
        "    'pca': [10, 20, 30, 40, 50, 60],\n",
        "    'dummy': ['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified'],\n",
        "    'knn': [1, 6]\n",
        "}\n",
        "\n",
        "def getEstDict():\n",
        "    dict = {}\n",
        "    for step in steps:\n",
        "        if step[0] in est_mapper_keys:\n",
        "            dict[est_mapper_keys[step[0]]] = est_values_mapper[step[0]]\n",
        "    return dict\n",
        "\n",
        "\n",
        "for sequence in get_transformations(transformers.keys()):\n",
        "    # add trasformers\n",
        "    steps = [(trans, transformers[trans]) for trans in sequence]\n",
        "    # add classifier\n",
        "    for classifier in classifiers.keys():\n",
        "        if len(steps): steps.pop()  #delete previous classifier\n",
        "        steps.append((classifier, classifiers[classifier])) #add new classifier\n",
        "        # create Pipe\n",
        "        pipe = Pipeline(steps=steps, memory = 'tmp')\n",
        "        estimator_dict = getEstDict()\n",
        "        # print(estimator_dict)\n",
        "        # break\n",
        "        estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components, dummy__strategy=['uniform', 'constant_0', 'constant_1', 'most_frequent', 'stratified']), cv=10, scoring='f1_macro', n_jobs=-1)\n",
        "    # break\n",
        "\n",
        "\n",
        "# import time\n",
        "# start_time = time.time()\n",
        "# estimator.fit(train, train_labels)\n",
        "# preds = estimator.predict(test)\n",
        "# print(\"Συνολικός χρόνος fit και predict: %s seconds\" % (time.time() - start_time))\n",
        "# print(classification_report(test_labels, preds))"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkpJu5odkVO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26342681-d724-46e8-8b8e-91b49df792e6"
      },
      "source": [
        "print(estimator.best_estimator_)\n",
        "print(estimator.best_params_)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pipeline(memory='tmp',\n",
            "         steps=[('selector', VarianceThreshold(threshold=0)),\n",
            "                ('scaler', StandardScaler()), ('sampler', RandomOverSampler()),\n",
            "                ('pca', PCA(n_components=10)),\n",
            "                ('dummy', DummyClassifier(strategy='stratified'))])\n",
            "{'dummy__strategy': 'stratified', 'pca__n_components': 10, 'selector__threshold': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}